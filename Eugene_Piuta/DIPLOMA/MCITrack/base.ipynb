{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "429c4397",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\envs\\p310\\lib\\site-packages\\timm\\models\\layers\\__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers\n",
      "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.layers\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import yaml\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils import checkpoint\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "import cv2\n",
    "import sys\n",
    "import numpy as np\n",
    "import fastitpn as fastitpn_module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4bde567b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderBase(nn.Module):\n",
    "\n",
    "    def __init__(self, encoder: nn.Module, train_encoder: bool, open_layers: list, num_channels: int):\n",
    "        super().__init__()\n",
    "        open_blocks = open_layers[2:]\n",
    "        open_items = open_layers[0:2]\n",
    "        for name, parameter in encoder.named_parameters():\n",
    "\n",
    "            if not train_encoder:\n",
    "                freeze = True\n",
    "                for open_block in open_blocks:\n",
    "                    if open_block in name:\n",
    "                        freeze = False\n",
    "                if name in open_items:\n",
    "                    freeze = False\n",
    "                if freeze == True:\n",
    "                    parameter.requires_grad_(False)  # here should allow users to specify which layers to freeze !\n",
    "\n",
    "        self.body = encoder\n",
    "        self.num_channels = num_channels\n",
    "\n",
    "    def forward(self, template_list, search_list, template_anno_list):\n",
    "        xs = self.body(template_list, search_list, template_anno_list)\n",
    "        return xs\n",
    "\n",
    "\n",
    "#fast_itpn_tiny_1600e_1k\n",
    "\n",
    "class Encoder(EncoderBase):\n",
    "    \"\"\"FastITPN encoder.\"\"\"\n",
    "    def __init__(self, name: str,\n",
    "                 train_encoder: bool,\n",
    "                 pretrain_type: str,\n",
    "                 search_size: int,\n",
    "                 search_number: int,\n",
    "                 template_size: int,\n",
    "                 template_number: int,\n",
    "                 open_layers: list,\n",
    "                 cfg=None):\n",
    "        if \"fastitpn\" in name.lower():\n",
    "            encoder = getattr(fastitpn_module, name)(\n",
    "                pretrained=True,\n",
    "                search_size=search_size,\n",
    "                template_size=template_size,\n",
    "                drop_rate=0.0,\n",
    "                drop_path_rate=0.1,\n",
    "                attn_drop_rate=0.0,\n",
    "                init_values=0.1,\n",
    "                drop_block_rate=None,\n",
    "                use_mean_pooling=True,\n",
    "                grad_ckpt=cfg[\"MODEL\"][\"ENCODER\"][\"GRAD_CKPT\"],\n",
    "                pos_type=cfg[\"MODEL\"][\"ENCODER\"][\"POS_TYPE\"],\n",
    "                token_type_indicate=cfg[\"MODEL\"][\"ENCODER\"][\"TOKEN_TYPE_INDICATE\"],\n",
    "                pretrain_type = cfg[\"MODEL\"][\"ENCODER\"][\"PRETRAIN_TYPE\"],\n",
    "            )\n",
    "            if \"itpnb\" in name:\n",
    "                num_channels = 512\n",
    "            elif \"itpnl\" in name:\n",
    "                num_channels = 768\n",
    "            elif \"itpnt\" in name:\n",
    "                num_channels = 384\n",
    "            elif \"itpns\" in name:\n",
    "                num_channels = 384\n",
    "            else:\n",
    "                num_channels = 512\n",
    "        else:\n",
    "            raise ValueError()\n",
    "        super().__init__(encoder, train_encoder, open_layers, num_channels)\n",
    "\n",
    "def build_encoder(cfg):\n",
    "    train_encoder = (cfg[\"TRAIN\"][\"ENCODER_MULTIPLIER\"] > 0) and (cfg[\"TRAIN\"][\"FREEZE_ENCODER\"] == False)\n",
    "    encoder = Encoder(cfg[\"MODEL\"][\"ENCODER\"][\"TYPE\"], train_encoder,\n",
    "                      cfg[\"MODEL\"][\"ENCODER\"][\"PRETRAIN_TYPE\"],\n",
    "                      cfg[\"DATA\"][\"SEARCH\"][\"SIZE\"], cfg[\"DATA\"][\"SEARCH\"][\"NUMBER\"],\n",
    "                      cfg[\"DATA\"][\"TEMPLATE\"][\"SIZE\"], cfg[\"DATA\"][\"TEMPLATE\"][\"NUMBER\"],\n",
    "                      cfg[\"TRAIN\"][\"ENCODER_OPEN\"], cfg)\n",
    "    return encoder\n",
    "\n",
    "class MambaBlock(nn.Module):\n",
    "    def __init__(self,dt_scale, d_model,d_inner,dt_rank,d_state,bias,d_conv,conv_bias,dt_init,dt_max,dt_min,dt_init_floor):\n",
    "        super().__init__()\n",
    "        #  projects block input from D to 2*ED (two branches)\n",
    "        self.dt_scale = dt_scale\n",
    "        self.d_model = d_model\n",
    "        self.d_inner = d_inner\n",
    "        self.dt_rank = dt_rank\n",
    "        self.d_state = d_state\n",
    "        self.in_proj = nn.Linear(self.d_model, 2 * self.d_inner, bias=bias)\n",
    "\n",
    "        self.conv1d = nn.Conv1d(in_channels=self.d_inner, out_channels=self.d_inner,\n",
    "                                kernel_size=d_conv, bias=conv_bias,\n",
    "                                groups=self.d_inner,\n",
    "                                padding=(d_conv - 1)//2)\n",
    "\n",
    "        #  projects x to input-dependent Δ, B, C\n",
    "        self.x_proj = nn.Linear(self.d_inner, self.dt_rank + 2 * self.d_state, bias=False)\n",
    "\n",
    "        #  projects Δ from dt_rank to d_inner\n",
    "        self.dt_proj = nn.Linear(self.dt_rank, self.d_inner, bias=True)\n",
    "\n",
    "        #  dt initialization\n",
    "        #  dt weights\n",
    "        dt_init_std = self.dt_rank ** -0.5 * self.dt_scale\n",
    "        if dt_init == \"constant\":\n",
    "            nn.init.constant_(self.dt_proj.weight, dt_init_std)\n",
    "        elif dt_init == \"random\":\n",
    "            nn.init.uniform_(self.dt_proj.weight, -dt_init_std, dt_init_std)\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "\n",
    "        # dt bias\n",
    "        dt = torch.exp(\n",
    "            torch.rand(self.d_inner) * (math.log(dt_max) - math.log(dt_min)) + math.log(dt_min)\n",
    "        ).clamp(min=dt_init_floor)\n",
    "        inv_dt = dt + torch.log(\n",
    "            -torch.expm1(-dt))  #  inverse of softplus: https://github.com/pytorch/pytorch/issues/72759\n",
    "        with torch.no_grad():\n",
    "            self.dt_proj.bias.copy_(inv_dt)\n",
    "        # self.dt_proj.bias._no_reinit = True # initialization would set all Linear.bias to zero, need to mark this one as _no_reinit\n",
    "        #  todo : explain why removed\n",
    "\n",
    "        # S4D real initialization\n",
    "        A = torch.arange(1, self.d_state + 1, dtype=torch.float32).repeat(self.d_inner, 1)\n",
    "        self.A_log = nn.Parameter(\n",
    "            torch.log(A))  # why store A in log ? to keep A < 0 (cf -torch.exp(...)) ? for gradient stability ?\n",
    "        self.D = nn.Parameter(torch.ones(self.d_inner))\n",
    "\n",
    "        #  projects block output from ED back to D\n",
    "        self.out_proj = nn.Linear(self.d_inner, self.d_model, bias=bias)\n",
    "    def forward(self, x, h):\n",
    "        #  x : (B,L, D)\n",
    "        # h : (B,L, ED, N)\n",
    "\n",
    "        #  y : (B, L, D)\n",
    "\n",
    "\n",
    "        xz = self.in_proj(x)  # (B, L,2*ED)\n",
    "        x, z = xz.chunk(2, dim=-1)  #  (B,L, ED), (B,L, ED)\n",
    "        x_cache = x.permute(0,2,1)#(B, ED,L)\n",
    "\n",
    "        #  x branch\n",
    "        x = self.conv1d( x_cache).permute(0,2,1) #  (B,L , ED)\n",
    "\n",
    "        x = F.silu(x)\n",
    "        y, h = self.ssm_step(x, h)\n",
    "        #y->B,L,ED;h->B,L,ED,N\n",
    "\n",
    "        #  z branch\n",
    "        z = F.silu(z)\n",
    "\n",
    "        output = y * z\n",
    "        output = self.out_proj(output)  #  (B, L, D)\n",
    "\n",
    "        return output, h\n",
    "\n",
    "    def ssm_step(self, x, h):\n",
    "        #  x : (B, L, ED)\n",
    "        #  h : (B, L, ED, N)\n",
    "\n",
    "        A = -torch.exp(\n",
    "            self.A_log.float())  # (ED, N) # todo : ne pas le faire tout le temps, puisque c'est indépendant de la timestep\n",
    "        D = self.D.float()\n",
    "        #  TODO remove .float()\n",
    "\n",
    "        deltaBC = self.x_proj(x)  #  (B, L, dt_rank+2*N)\n",
    "\n",
    "        delta, B, C = torch.split(deltaBC, [self.dt_rank, self.d_state, self.d_state],\n",
    "                                  dim=-1)  #  (B, L,dt_rank), (B, L, N), (B, L, N)\n",
    "        delta = F.softplus(self.dt_proj(delta))  #  (B, L, ED)\n",
    "\n",
    "        deltaA = torch.exp(delta.unsqueeze(-1) * A)  #  (B,L, ED, N)\n",
    "        deltaB = delta.unsqueeze(-1) * B.unsqueeze(2)  #  (B,L, ED, N)\n",
    "\n",
    "        BX = deltaB * (x.unsqueeze(-1))  #  (B, L,ED, N)\n",
    "\n",
    "        if h is None:\n",
    "            h = torch.zeros(x.size(0), x.size(1), self.d_inner, self.d_state, device=deltaA.device)  #  (B, L, ED, N)\n",
    "\n",
    "        h = deltaA * h + BX  #  (B, L, ED, N)\n",
    "\n",
    "        y = (h @ C.unsqueeze(-1)).squeeze(3)  #  (B, L, ED, N) @ (B, L, N, 1) -> (B, L, ED, 1)\n",
    "\n",
    "        y = y + D * x#B,L,ED\n",
    "\n",
    "        #  todo : pq h.squeeze(1) ??\n",
    "        return y, h\n",
    "    \n",
    "class DWConv(nn.Module):\n",
    "    def __init__(self, dim=768):\n",
    "        super().__init__()\n",
    "        self.dwconv = nn.Conv2d(dim, dim, 3, 1, 1, bias=True, groups=dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.permute(1,0,2)\n",
    "        B, N, C = x.shape\n",
    "        x = x.transpose(1,2).view(B,C,int(N**0.5),int(N**0.5)).contiguous()\n",
    "        x = self.dwconv(x).flatten(2).transpose(1, 2)#B,N,C\n",
    "        x = x.permute(1,0,2)\n",
    "        return x\n",
    "class ConvFFN(nn.Module):\n",
    "    def __init__(self, in_features, hidden_features=None, out_features=None,\n",
    "                 act_layer=nn.GELU, drop=0.):\n",
    "        super().__init__()\n",
    "        out_features = out_features or in_features\n",
    "        hidden_features = hidden_features or in_features\n",
    "        self.fc1 = nn.Linear(in_features, hidden_features)\n",
    "        self.dwconv = DWConv(hidden_features)\n",
    "        self.act = act_layer()\n",
    "        self.fc2 = nn.Linear(hidden_features, out_features)\n",
    "        self.drop = nn.Dropout(drop)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.dwconv(x)\n",
    "        x = self.act(x)\n",
    "        x = self.drop(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.drop(x)\n",
    "        return x\n",
    "    \n",
    "class ConvFFN(nn.Module):\n",
    "    def __init__(self, in_features, hidden_features=None, out_features=None,\n",
    "                 act_layer=nn.GELU, drop=0.):\n",
    "        super().__init__()\n",
    "        out_features = out_features or in_features\n",
    "        hidden_features = hidden_features or in_features\n",
    "        self.fc1 = nn.Linear(in_features, hidden_features)\n",
    "        self.dwconv = DWConv(hidden_features)\n",
    "        self.act = act_layer()\n",
    "        self.fc2 = nn.Linear(hidden_features, out_features)\n",
    "        self.drop = nn.Dropout(drop)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.dwconv(x)\n",
    "        x = self.act(x)\n",
    "        x = self.drop(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.drop(x)\n",
    "        return x\n",
    "\n",
    "def drop_path(x, drop_prob: float = 0., training: bool = False, scale_by_keep: bool = True):\n",
    "\n",
    "    if drop_prob == 0. or not training:\n",
    "        return x\n",
    "    keep_prob = 1 - drop_prob\n",
    "    shape = (x.shape[0],) + (1,) * (x.ndim - 1)  # work with diff dim tensors, not just 2D ConvNets\n",
    "    random_tensor = x.new_empty(shape).bernoulli_(keep_prob)\n",
    "    if keep_prob > 0.0 and scale_by_keep:\n",
    "        random_tensor.div_(keep_prob)\n",
    "    return x * random_tensor\n",
    "\n",
    "class DropPath(nn.Module):\n",
    "   \n",
    "    def __init__(self, drop_prob: float = 0., scale_by_keep: bool = True):\n",
    "        super(DropPath, self).__init__()\n",
    "        self.drop_prob = drop_prob\n",
    "        self.scale_by_keep = scale_by_keep\n",
    "\n",
    "    def forward(self, x):\n",
    "        return drop_path(x, self.drop_prob, self.training, self.scale_by_keep)\n",
    "\n",
    "    def extra_repr(self):\n",
    "        return f'drop_prob={round(self.drop_prob,3):0.3f}'\n",
    "    \n",
    "\n",
    "class Extractor(nn.Module):\n",
    "    def __init__(self, d_model, num_heads=8, dropout=0.1, drop_path=0.1,\n",
    "                 norm_layer=lambda x: nn.LayerNorm(x, eps=1e-6)):  # Замена partial на лямбду\n",
    "        super().__init__()\n",
    "        self.query_norm = norm_layer(d_model)\n",
    "        self.feat_norm = norm_layer(d_model)\n",
    "        self.attn = nn.MultiheadAttention(d_model, num_heads, dropout=dropout)\n",
    "        # convffn\n",
    "        self.ffn = ConvFFN(in_features=d_model, hidden_features=int(d_model * 0.25), drop=0.)\n",
    "        self.ffn_norm = norm_layer(d_model)\n",
    "        self.drop_path = DropPath(drop_path) if drop_path > 0. else nn.Identity()\n",
    "\n",
    "    def forward(self, query, feat):\n",
    "\n",
    "        def _inner_forward(query, feat):\n",
    "            # query:l,b,d;feat:l,b,d\n",
    "            attn = self.attn(self.query_norm(query),\n",
    "                             self.feat_norm(feat), self.feat_norm(feat))[0]\n",
    "            query = query + attn\n",
    "\n",
    "            query = query + self.drop_path(self.ffn(self.ffn_norm(query)))\n",
    "            return query\n",
    "\n",
    "        query = _inner_forward(query, feat)\n",
    "\n",
    "        return query\n",
    " \n",
    "class Injector(nn.Module):\n",
    "    def __init__(self, d_model, n_heads=8, norm_layer=lambda x: nn.LayerNorm(x, eps=1e-6), dropout=0.1, init_values=0.):\n",
    "        super().__init__()\n",
    "        self.query_norm = norm_layer(d_model)\n",
    "        self.feat_norm = norm_layer(d_model)\n",
    "        self.attn = nn.MultiheadAttention(d_model, n_heads, dropout=dropout)\n",
    "        self.gamma = nn.Parameter(init_values * torch.ones((d_model)), requires_grad=True)\n",
    "        \n",
    "    def forward(self, query,feat):\n",
    "            #query:l,b,d;feat:l,b,d\n",
    "        def _inner_forward(query, feat):\n",
    "\n",
    "            attn = self.attn(self.query_norm(query),\n",
    "                             self.feat_norm(feat),self.feat_norm(feat))[0]\n",
    "            return query + self.gamma * attn\n",
    "        query = _inner_forward(query, feat)\n",
    "        return query    \n",
    "    \n",
    "    \n",
    "\n",
    "class InteractionBlock(nn.Module):\n",
    "    def __init__(self, d_model, extra_extractor, grad_ckpt):\n",
    "        super().__init__()\n",
    "        self.grad_ckpt = grad_ckpt\n",
    "        self.injector = Injector(d_model=d_model)\n",
    "        self.extractor = Extractor(d_model=d_model)\n",
    "        if extra_extractor:\n",
    "            self.extra_extractors = nn.Sequential(*[\n",
    "                Extractor(d_model=d_model)\n",
    "                for _ in range(2)])\n",
    "        else:\n",
    "            self.extra_extractors = None\n",
    "\n",
    "    def forward(self,x,xs,blocks):\n",
    "        x = self.injector(x.permute(1,0,2),xs.permute(1,0,2)).permute(1,0,2)\n",
    "        for idx,blk in enumerate(blocks):\n",
    "            x = checkpoint.checkpoint(blk, x, None,use_reentrant=False) if self.grad_ckpt else blk(x,None)\n",
    "        xs = checkpoint.checkpoint(self.extractor, xs.permute(1,0,2),x.permute(1,0,2),use_reentrant=False).permute(1,0,2) \\\n",
    "            if self.grad_ckpt else self.extractor(xs.permute(1, 0, 2), x.permute(1, 0, 2)).permute(1, 0, 2)  # b,n,c\n",
    "        # xs = self.extractor(xs.permute(1,0,2),x.permute(1,0,2)).permute(1,0,2)#b,n,c\n",
    "        if self.extra_extractors is not None:\n",
    "            for extractor in self.extra_extractors:\n",
    "                xs = checkpoint.checkpoint(extractor, xs.permute(1, 0, 2), x.permute(1, 0, 2), use_reentrant=False).permute(1, 0, 2) \\\n",
    "                    if self.grad_ckpt else extractor(xs.permute(1, 0, 2), x.permute(1, 0, 2)).permute(1, 0,2)  # b,n,c\n",
    "                # xs = extractor(xs.permute(1,0,2),x.permute(1,0,2)).permute(1,0,2)\n",
    "        return x,xs\n",
    "class RMSNorm(nn.Module):\n",
    "    def __init__(self, d_model: int, eps: float = 1e-5):\n",
    "        super().__init__()\n",
    "\n",
    "        self.eps = eps\n",
    "        self.weight = nn.Parameter(torch.ones(d_model))\n",
    "\n",
    "    def forward(self, x):\n",
    "        output = x * torch.rsqrt(x.pow(2).mean(-1, keepdim=True) + self.eps) * self.weight\n",
    "\n",
    "        return output\n",
    "    \n",
    "\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self,dt_scale, d_model,d_inner,dt_rank,d_state,bias,d_conv,conv_bias,dt_init,dt_max,dt_min,dt_init_floor,grad_ckpt):\n",
    "        super().__init__()\n",
    "\n",
    "        self.grad_ckpt = grad_ckpt\n",
    "        self.mixer = MambaBlock(dt_scale,d_model,d_inner,dt_rank,d_state,bias,d_conv,conv_bias,dt_init,dt_max,dt_min,dt_init_floor)\n",
    "        self.norm = RMSNorm(d_model)\n",
    "\n",
    "    def forward(self, x, h):\n",
    "        #  x : (B, L, D)\n",
    "        # h : (B, L, ED, N)\n",
    "        #  output : (B,L, D)\n",
    "\n",
    "        x = self.norm(x)\n",
    "        output, h = checkpoint.checkpoint(self.mixer,x,h,use_reentrant=False) if self.grad_ckpt else self.mixer(x, h)\n",
    "        output = output + x\n",
    "        return output, h\n",
    "    \n",
    "class Mamba_Neck(nn.Module):\n",
    "    def __init__(self, in_channel=512,d_model=512,d_inner=1024,bias=False,n_layers=4,dt_rank=32,d_state=16,d_conv=3,dt_min=0.001,\n",
    "                 dt_max=0.1,dt_init='random',dt_scale=1.0,conv_bias=True,dt_init_floor=0.0001,grad_ckpt=False):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        self.d_inner = d_inner\n",
    "        self.bias = bias\n",
    "        self.dt_rank = dt_rank\n",
    "        self.d_state = d_state\n",
    "        self.dt_scale = dt_scale\n",
    "        self.num_channels = self.d_model\n",
    "        self.layers = nn.ModuleList(\n",
    "            [ResidualBlock(dt_scale,d_model,d_inner,dt_rank,d_state,bias,d_conv,conv_bias,dt_init,dt_max,dt_min,dt_init_floor,grad_ckpt)\n",
    "             for _ in range(n_layers)])\n",
    "        self.interactions = nn.ModuleList([\n",
    "            InteractionBlock(d_model=d_model,extra_extractor=(True if i == n_layers - 1 else False),grad_ckpt=grad_ckpt)\n",
    "            for i in range(n_layers)\n",
    "        ])\n",
    "        # self.norm_f = RMSNorm(config.d_model)\n",
    "\n",
    "    def forward(self, x,xs,h,blocks,interaction_indexes):\n",
    "        #  x : (B, L, D)\n",
    "        #  caches : [cache(layer) for all layers], cache : (h, inputs)\n",
    "\n",
    "        #  y : (B, L, D)\n",
    "        #  caches : [cache(layer) for all layers], cache : (h, inputs)\n",
    "        for i,index in enumerate(interaction_indexes):\n",
    "            xs, h[i] = self.layers[i](xs, h[i])\n",
    "            x,xs = self.interactions[i](x,xs,blocks[index[0]:index[1]])\n",
    "\n",
    "        return x, xs, h\n",
    "def build_neck(cfg,encoder):\n",
    "    in_channel = encoder.num_channels\n",
    "    d_model = cfg[\"MODEL\"][\"NECK\"][\"D_MODEL\"]\n",
    "    n_layers = cfg[\"MODEL\"][\"NECK\"][\"N_LAYERS\"]\n",
    "    d_state = cfg[\"MODEL\"][\"NECK\"][\"D_STATE\"]\n",
    "    grad_ckpt = cfg[\"MODEL\"][\"ENCODER\"][\"GRAD_CKPT\"]\n",
    "    neck = Mamba_Neck(in_channel=in_channel,d_model=d_model,d_inner=2*d_model,n_layers=n_layers,dt_rank=d_model//16,d_state=d_state,grad_ckpt=grad_ckpt)\n",
    "    return neck\n",
    "\n",
    "def box_xyxy_to_cxcywh(x):\n",
    "    x0, y0, x1, y1 = x.unbind(-1)\n",
    "    b = [(x0 + x1) / 2, (y0 + y1) / 2,\n",
    "         (x1 - x0), (y1 - y0)]\n",
    "    return torch.stack(b, dim=-1)\n",
    "\n",
    "class MLPPredictor(nn.Module):\n",
    "    def __init__(self, inplanes=64, channel=256, feat_sz=20, stride=16):\n",
    "        super(MLPPredictor, self).__init__()\n",
    "        self.feat_sz = feat_sz\n",
    "        self.stride = stride\n",
    "        self.img_sz = self.feat_sz * self.stride\n",
    "\n",
    "        self.num_layers = 3\n",
    "        h = [channel] * (self.num_layers - 1)\n",
    "        self.layers_cls = nn.ModuleList(nn.Linear(n, k)\n",
    "                                        for n, k in zip([inplanes] + h, h + [1]))\n",
    "        self.layers_reg = nn.ModuleList(nn.Linear(n, k)\n",
    "                                        for n, k in zip([inplanes] + h, h + [4]))\n",
    "\n",
    "        # for p in self.parameters():\n",
    "        #     if p.dim() > 1:\n",
    "        #         nn.init.xavier_uniform_(p)\n",
    "\n",
    "    def forward(self, x, gt_score_map=None):\n",
    "        \"\"\" Forward pass with input x. \"\"\"\n",
    "        score_map, offset_map = self.get_score_map(x)\n",
    "\n",
    "        # assert gt_score_map is None\n",
    "        if gt_score_map is None:\n",
    "            bbox = self.cal_bbox(score_map, offset_map)\n",
    "        else:\n",
    "            bbox = self.cal_bbox(gt_score_map.unsqueeze(1), offset_map)\n",
    "\n",
    "        return score_map, bbox, offset_map\n",
    "\n",
    "    def cal_bbox(self, score_map, offset_map, return_score=False):\n",
    "        max_score, idx = torch.max(score_map.flatten(1), dim=1, keepdim=True)\n",
    "        idx_y = torch.div(idx, self.feat_sz, rounding_mode='floor')\n",
    "        idx_x = idx % self.feat_sz\n",
    "\n",
    "        idx = idx.unsqueeze(1).expand(idx.shape[0], 4, 1) # torch.Size([32, 4, 1])\n",
    "        offset = offset_map.flatten(2).gather(dim=2, index=idx).squeeze(-1)\n",
    "        # offset: (l,t,r,b)\n",
    "\n",
    "        # x1, y1, x2, y2\n",
    "        bbox = torch.cat([idx_x.to(torch.float) / self.feat_sz - offset[:, :1], # the offset should not divide the self.feat_sz, since I use the sigmoid to limit it in (0,1)\n",
    "                          idx_y.to(torch.float) / self.feat_sz - offset[:, 1:2],\n",
    "                          idx_x.to(torch.float) / self.feat_sz + offset[:, 2:3],\n",
    "                          idx_y.to(torch.float) / self.feat_sz + offset[:, 3:4],\n",
    "                          ], dim=1)\n",
    "        bbox = box_xyxy_to_cxcywh(bbox)\n",
    "        if return_score:\n",
    "            return bbox, max_score\n",
    "        return bbox\n",
    "\n",
    "    def get_score_map(self, x):\n",
    "\n",
    "        def _sigmoid(x):\n",
    "            y = torch.clamp(x.sigmoid_(), min=1e-4, max=1 - 1e-4)\n",
    "            return y\n",
    "\n",
    "        x_cls = x\n",
    "        for i, layer in enumerate(self.layers_cls):\n",
    "            x_cls = F.relu(layer(x_cls)) if i < self.num_layers - 1 else layer(x_cls)\n",
    "        x_cls = x_cls.permute(0,2,1).reshape(-1,1,self.feat_sz,self.feat_sz)\n",
    "\n",
    "        x_reg = x\n",
    "        for i, layer in enumerate(self.layers_reg):\n",
    "            x_reg = F.relu(layer(x_reg)) if i < self.num_layers - 1 else layer(x_reg)\n",
    "        x_reg = x_reg.permute(0, 2, 1).reshape(-1, 4, self.feat_sz, self.feat_sz)\n",
    "\n",
    "        return _sigmoid(x_cls), _sigmoid(x_reg)\n",
    "    \n",
    "class FrozenBatchNorm2d(torch.nn.Module):\n",
    "\n",
    "\n",
    "    def __init__(self, n):\n",
    "        super(FrozenBatchNorm2d, self).__init__()\n",
    "        self.register_buffer(\"weight\", torch.ones(n))\n",
    "        self.register_buffer(\"bias\", torch.zeros(n))\n",
    "        self.register_buffer(\"running_mean\", torch.zeros(n))\n",
    "        self.register_buffer(\"running_var\", torch.ones(n))\n",
    "\n",
    "    def _load_from_state_dict(self, state_dict, prefix, local_metadata, strict,\n",
    "                              missing_keys, unexpected_keys, error_msgs):\n",
    "        num_batches_tracked_key = prefix + 'num_batches_tracked'\n",
    "        if num_batches_tracked_key in state_dict:\n",
    "            del state_dict[num_batches_tracked_key]\n",
    "\n",
    "        super(FrozenBatchNorm2d, self)._load_from_state_dict(\n",
    "            state_dict, prefix, local_metadata, strict,\n",
    "            missing_keys, unexpected_keys, error_msgs)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # move reshapes to the beginning\n",
    "        # to make it fuser-friendly\n",
    "        w = self.weight.reshape(1, -1, 1, 1)\n",
    "        b = self.bias.reshape(1, -1, 1, 1)\n",
    "        rv = self.running_var.reshape(1, -1, 1, 1)\n",
    "        rm = self.running_mean.reshape(1, -1, 1, 1)\n",
    "        eps = 1e-5\n",
    "        scale = w * (rv + eps).rsqrt()  # rsqrt(x): 1/sqrt(x), r: reciprocal\n",
    "        bias = b - rm * scale\n",
    "        return x * scale + bias\n",
    "\n",
    "def conv(in_planes, out_planes, kernel_size=3, stride=1, padding=1, dilation=1,\n",
    "         freeze_bn=False):\n",
    "    if freeze_bn:\n",
    "        return nn.Sequential(\n",
    "            nn.Conv2d(in_planes, out_planes, kernel_size=kernel_size, stride=stride,\n",
    "                      padding=padding, dilation=dilation, bias=True),\n",
    "            FrozenBatchNorm2d(out_planes),\n",
    "            nn.ReLU(inplace=True))\n",
    "    else:\n",
    "        return nn.Sequential(\n",
    "            nn.Conv2d(in_planes, out_planes, kernel_size=kernel_size, stride=stride,\n",
    "                      padding=padding, dilation=dilation, bias=True),\n",
    "            nn.BatchNorm2d(out_planes),\n",
    "            nn.ReLU(inplace=True))\n",
    "    \n",
    "def conv(in_planes, out_planes, kernel_size=3, stride=1, padding=1, dilation=1,\n",
    "         freeze_bn=False):\n",
    "    if freeze_bn:\n",
    "        return nn.Sequential(\n",
    "            nn.Conv2d(in_planes, out_planes, kernel_size=kernel_size, stride=stride,\n",
    "                      padding=padding, dilation=dilation, bias=True),\n",
    "            FrozenBatchNorm2d(out_planes),\n",
    "            nn.ReLU(inplace=True))\n",
    "    else:\n",
    "        return nn.Sequential(\n",
    "            nn.Conv2d(in_planes, out_planes, kernel_size=kernel_size, stride=stride,\n",
    "                      padding=padding, dilation=dilation, bias=True),\n",
    "            nn.BatchNorm2d(out_planes),\n",
    "            nn.ReLU(inplace=True))\n",
    "    \n",
    "class CenterPredictor(nn.Module, ):\n",
    "    def __init__(self, inplanes=64, channel=256, feat_sz=20, stride=16, freeze_bn=False):\n",
    "        super(CenterPredictor, self).__init__()\n",
    "        self.feat_sz = feat_sz\n",
    "        self.stride = stride\n",
    "        self.img_sz = self.feat_sz * self.stride\n",
    "\n",
    "        # corner predict\n",
    "        self.conv1_ctr = conv(inplanes, channel, freeze_bn=freeze_bn)\n",
    "        self.conv2_ctr = conv(channel, channel // 2, freeze_bn=freeze_bn)\n",
    "        self.conv3_ctr = conv(channel // 2, channel // 4, freeze_bn=freeze_bn)\n",
    "        self.conv4_ctr = conv(channel // 4, channel // 8, freeze_bn=freeze_bn)\n",
    "        self.conv5_ctr = nn.Conv2d(channel // 8, 1, kernel_size=1)\n",
    "\n",
    "        # size regress\n",
    "        self.conv1_offset = conv(inplanes, channel, freeze_bn=freeze_bn)\n",
    "        self.conv2_offset = conv(channel, channel // 2, freeze_bn=freeze_bn)\n",
    "        self.conv3_offset = conv(channel // 2, channel // 4, freeze_bn=freeze_bn)\n",
    "        self.conv4_offset = conv(channel // 4, channel // 8, freeze_bn=freeze_bn)\n",
    "        self.conv5_offset = nn.Conv2d(channel // 8, 2, kernel_size=1)\n",
    "\n",
    "        # size regress\n",
    "        self.conv1_size = conv(inplanes, channel, freeze_bn=freeze_bn)\n",
    "        self.conv2_size = conv(channel, channel // 2, freeze_bn=freeze_bn)\n",
    "        self.conv3_size = conv(channel // 2, channel // 4, freeze_bn=freeze_bn)\n",
    "        self.conv4_size = conv(channel // 4, channel // 8, freeze_bn=freeze_bn)\n",
    "        self.conv5_size = nn.Conv2d(channel // 8, 2, kernel_size=1)\n",
    "\n",
    "        for p in self.parameters():\n",
    "            if p.dim() > 1:\n",
    "                nn.init.xavier_uniform_(p)\n",
    "\n",
    "    def forward(self, x, gt_score_map=None):\n",
    "        \"\"\" Forward pass with input x. \"\"\"\n",
    "        score_map_ctr, size_map, offset_map = self.get_score_map(x) # x: torch.Size([b, c, h, w])\n",
    "        # score_map_ctr: torch.Size([32, 1, 16, 16]) size_map: torch.Size([32, 2, 16, 16]) offset_map: torch.Size([32, 2, 16, 16])\n",
    "\n",
    "        # assert gt_score_map is None\n",
    "        if gt_score_map is None:\n",
    "            bbox = self.cal_bbox(score_map_ctr, size_map, offset_map)\n",
    "        else:\n",
    "            bbox = self.cal_bbox(gt_score_map.unsqueeze(1), size_map, offset_map)\n",
    "\n",
    "        return score_map_ctr, bbox, size_map, offset_map\n",
    "\n",
    "    def cal_bbox(self, score_map_ctr, size_map, offset_map, return_score=False):\n",
    "        max_score, idx = torch.max(score_map_ctr.flatten(1), dim=1, keepdim=True) # score_map_ctr.flatten(1): torch.Size([32, 256]) idx: torch.Size([32, 1]) max_score: torch.Size([32, 1])\n",
    "        idx_y = torch.div(idx, self.feat_sz, rounding_mode='floor')\n",
    "        idx_x = idx % self.feat_sz\n",
    "\n",
    "        idx = idx.unsqueeze(1).expand(idx.shape[0], 2, 1)\n",
    "        size = size_map.flatten(2).gather(dim=2, index=idx) # size_map: torch.Size([32, 2, 16, 16])  size_map.flatten(2): torch.Size([32, 2, 256])\n",
    "        offset = offset_map.flatten(2).gather(dim=2, index=idx).squeeze(-1)\n",
    "\n",
    "        # bbox = torch.cat([idx_x - size[:, 0] / 2, idx_y - size[:, 1] / 2,\n",
    "        #                   idx_x + size[:, 0] / 2, idx_y + size[:, 1] / 2], dim=1) / self.feat_sz\n",
    "        # cx, cy, w, h\n",
    "        bbox = torch.cat([(idx_x.to(torch.float) + offset[:, :1]) / self.feat_sz,\n",
    "                          (idx_y.to(torch.float) + offset[:, 1:]) / self.feat_sz,\n",
    "                          size.squeeze(-1)], dim=1)\n",
    "\n",
    "        if return_score:\n",
    "            return bbox, max_score\n",
    "        return bbox\n",
    "\n",
    "    def get_pred(self, score_map_ctr, size_map, offset_map):\n",
    "        max_score, idx = torch.max(score_map_ctr.flatten(1), dim=1, keepdim=True)\n",
    "        idx_y = idx // self.feat_sz\n",
    "        idx_x = idx % self.feat_sz\n",
    "\n",
    "        idx = idx.unsqueeze(1).expand(idx.shape[0], 2, 1)\n",
    "        size = size_map.flatten(2).gather(dim=2, index=idx)\n",
    "        offset = offset_map.flatten(2).gather(dim=2, index=idx).squeeze(-1)\n",
    "\n",
    "        # bbox = torch.cat([idx_x - size[:, 0] / 2, idx_y - size[:, 1] / 2,\n",
    "        #                   idx_x + size[:, 0] / 2, idx_y + size[:, 1] / 2], dim=1) / self.feat_sz\n",
    "        return size * self.feat_sz, offset\n",
    "\n",
    "    def get_score_map(self, x):\n",
    "\n",
    "        def _sigmoid(x):\n",
    "            y = torch.clamp(x.sigmoid_(), min=1e-4, max=1 - 1e-4)\n",
    "            return y\n",
    "\n",
    "        # ctr branch\n",
    "        x_ctr1 = self.conv1_ctr(x)\n",
    "        x_ctr2 = self.conv2_ctr(x_ctr1)\n",
    "        x_ctr3 = self.conv3_ctr(x_ctr2)\n",
    "        x_ctr4 = self.conv4_ctr(x_ctr3)\n",
    "        score_map_ctr = self.conv5_ctr(x_ctr4)\n",
    "\n",
    "        # offset branch\n",
    "        x_offset1 = self.conv1_offset(x)\n",
    "        x_offset2 = self.conv2_offset(x_offset1)\n",
    "        x_offset3 = self.conv3_offset(x_offset2)\n",
    "        x_offset4 = self.conv4_offset(x_offset3)\n",
    "        score_map_offset = self.conv5_offset(x_offset4)\n",
    "\n",
    "        # size branch\n",
    "        x_size1 = self.conv1_size(x)\n",
    "        x_size2 = self.conv2_size(x_size1)\n",
    "        x_size3 = self.conv3_size(x_size2)\n",
    "        x_size4 = self.conv4_size(x_size3)\n",
    "        score_map_size = self.conv5_size(x_size4)\n",
    "        return _sigmoid(score_map_ctr), _sigmoid(score_map_size), score_map_offset\n",
    "    \n",
    "def build_decoder(cfg, encoder):\n",
    "    num_channels_enc = encoder.num_channels\n",
    "    stride = cfg[\"MODEL\"][\"ENCODER\"][\"STRIDE\"]\n",
    "    if cfg[\"MODEL\"][\"DECODER\"][\"TYPE\"] == \"MLP\":\n",
    "        in_channel = num_channels_enc\n",
    "        hidden_dim = cfg[\"MODEL\"][\"DECODER\"][\"NUM_CHANNELS\"]\n",
    "        feat_sz = int(cfg[\"DATA\"][\"SEARCH\"][\"SIZE\"] / stride)\n",
    "        mlp_head = MLPPredictor(inplanes=in_channel, channel=hidden_dim,\n",
    "                                feat_sz=feat_sz, stride=stride)\n",
    "        return mlp_head\n",
    "    elif \"CORNER\" in cfg[\"MODEL\"][\"DECODER\"][\"TYPE\"]:\n",
    "        feat_sz = int(cfg[\"DATA\"][\"SEARCH\"][\"SIZE\"] / stride)\n",
    "        channel = getattr(cfg[\"MODEL\"], \"NUM_CHANNELS\", 256)\n",
    "        print(\"head channel: %d\" % channel)\n",
    "        if cfg[\"MODEL\"][\"HEAD\"][\"TYPE\"] == \"CORNER\":\n",
    "            corner_head = Corner_Predictor(inplanes=cfg[\"MODEL\"][\"HIDDEN_DIM\"], channel=channel,\n",
    "                                           feat_sz=feat_sz, stride=stride)\n",
    "        else:\n",
    "            raise ValueError()\n",
    "        return corner_head\n",
    "    elif cfg[\"MODEL\"][\"DECODER\"][\"TYPE\"] == \"CENTER\":\n",
    "        in_channel = num_channels_enc\n",
    "        out_channel = cfg[\"MODEL\"][\"DECODER\"][\"NUM_CHANNELS\"]\n",
    "        feat_sz = int(cfg[\"DATA\"][\"SEARCH\"][\"SIZE\"] / stride)\n",
    "        center_head = CenterPredictor(inplanes=in_channel, channel=out_channel,\n",
    "                                      feat_sz=feat_sz, stride=stride)\n",
    "        return center_head\n",
    "    else:\n",
    "        raise ValueError(\"HEAD TYPE %s is not supported.\" % cfg[\"MODEL\"][\"HEAD_TYPE\"])\n",
    "    \n",
    "class Corner_Predictor(nn.Module):\n",
    "    \"\"\" Corner Predictor module\"\"\"\n",
    "\n",
    "    def __init__(self, inplanes=64, channel=256, feat_sz=20, stride=16, freeze_bn=False):\n",
    "        super(Corner_Predictor, self).__init__()\n",
    "        self.feat_sz = feat_sz\n",
    "        self.stride = stride\n",
    "        self.img_sz = self.feat_sz * self.stride\n",
    "        '''top-left corner'''\n",
    "        self.conv1_tl = conv(inplanes, channel, freeze_bn=freeze_bn)\n",
    "        self.conv2_tl = conv(channel, channel // 2, freeze_bn=freeze_bn)\n",
    "        self.conv3_tl = conv(channel // 2, channel // 4, freeze_bn=freeze_bn)\n",
    "        self.conv4_tl = conv(channel // 4, channel // 8, freeze_bn=freeze_bn)\n",
    "        self.conv5_tl = nn.Conv2d(channel // 8, 1, kernel_size=1)\n",
    "\n",
    "        '''bottom-right corner'''\n",
    "        self.conv1_br = conv(inplanes, channel, freeze_bn=freeze_bn)\n",
    "        self.conv2_br = conv(channel, channel // 2, freeze_bn=freeze_bn)\n",
    "        self.conv3_br = conv(channel // 2, channel // 4, freeze_bn=freeze_bn)\n",
    "        self.conv4_br = conv(channel // 4, channel // 8, freeze_bn=freeze_bn)\n",
    "        self.conv5_br = nn.Conv2d(channel // 8, 1, kernel_size=1)\n",
    "\n",
    "        '''about coordinates and indexs'''\n",
    "        with torch.no_grad():\n",
    "            self.indice = torch.arange(0, self.feat_sz).view(-1, 1) * self.stride\n",
    "            # generate mesh-grid\n",
    "            self.coord_x = self.indice.repeat((self.feat_sz, 1)) \\\n",
    "                .view((self.feat_sz * self.feat_sz,)).float().cuda()\n",
    "            self.coord_y = self.indice.repeat((1, self.feat_sz)) \\\n",
    "                .view((self.feat_sz * self.feat_sz,)).float().cuda()\n",
    "\n",
    "    def forward(self, x, return_dist=False, softmax=True):\n",
    "        \"\"\" Forward pass with input x. \"\"\"\n",
    "        score_map_tl, score_map_br = self.get_score_map(x)\n",
    "        if return_dist:\n",
    "            coorx_tl, coory_tl, prob_vec_tl = self.soft_argmax(score_map_tl, return_dist=True, softmax=softmax)\n",
    "            coorx_br, coory_br, prob_vec_br = self.soft_argmax(score_map_br, return_dist=True, softmax=softmax)\n",
    "            return torch.stack((coorx_tl, coory_tl, coorx_br, coory_br), dim=1) / self.img_sz, prob_vec_tl, prob_vec_br\n",
    "        else:\n",
    "            coorx_tl, coory_tl = self.soft_argmax(score_map_tl)\n",
    "            coorx_br, coory_br = self.soft_argmax(score_map_br)\n",
    "            return torch.stack((coorx_tl, coory_tl, coorx_br, coory_br), dim=1) / self.img_sz\n",
    "\n",
    "    def get_score_map(self, x):\n",
    "        # top-left branch\n",
    "        x_tl1 = self.conv1_tl(x)\n",
    "        x_tl2 = self.conv2_tl(x_tl1)\n",
    "        x_tl3 = self.conv3_tl(x_tl2)\n",
    "        x_tl4 = self.conv4_tl(x_tl3)\n",
    "        score_map_tl = self.conv5_tl(x_tl4)\n",
    "\n",
    "        # bottom-right branch\n",
    "        x_br1 = self.conv1_br(x)\n",
    "        x_br2 = self.conv2_br(x_br1)\n",
    "        x_br3 = self.conv3_br(x_br2)\n",
    "        x_br4 = self.conv4_br(x_br3)\n",
    "        score_map_br = self.conv5_br(x_br4)\n",
    "        return score_map_tl, score_map_br\n",
    "\n",
    "    def soft_argmax(self, score_map, return_dist=False, softmax=True):\n",
    "        \"\"\" get soft-argmax coordinate for a given heatmap \"\"\"\n",
    "        score_vec = score_map.view((-1, self.feat_sz * self.feat_sz))  # (batch, feat_sz * feat_sz)\n",
    "        prob_vec = nn.functional.softmax(score_vec, dim=1)\n",
    "        exp_x = torch.sum((self.coord_x * prob_vec), dim=1)\n",
    "        exp_y = torch.sum((self.coord_y * prob_vec), dim=1)\n",
    "        if return_dist:\n",
    "            if softmax:\n",
    "                return exp_x, exp_y, prob_vec\n",
    "            else:\n",
    "                return exp_x, exp_y, score_vec\n",
    "        else:\n",
    "            return exp_x, exp_y\n",
    "        \n",
    "class Preprocessor(object):\n",
    "    def __init__(self):\n",
    "        self.mean = torch.tensor([0.485, 0.456, 0.406]).view((1, 3, 1, 1)).cuda()\n",
    "        self.std = torch.tensor([0.229, 0.224, 0.225]).view((1, 3, 1, 1)).cuda()\n",
    "        self.mm_mean = torch.tensor([0.485, 0.456, 0.406, 0.485, 0.456, 0.406]).view((1, 6, 1, 1)).cuda()\n",
    "        self.mm_std = torch.tensor([0.229, 0.224, 0.225, 0.229, 0.224, 0.225]).view((1, 6, 1, 1)).cuda()\n",
    "\n",
    "    def process(self, img_arr: np.ndarray):\n",
    "        if img_arr.shape[-1] == 6:\n",
    "            mean = self.mm_mean\n",
    "            std = self.mm_std\n",
    "        else:\n",
    "            mean = self.mean\n",
    "            std = self.std\n",
    "        # Deal with the image patch\n",
    "        img_tensor = torch.tensor(img_arr).cuda().float().permute((2,0,1)).unsqueeze(dim=0)\n",
    "        # img_tensor = torch.tensor(img_arr).float().permute((2,0,1)).unsqueeze(dim=0)\n",
    "        img_tensor_norm = ((img_tensor / 255.0) - mean) / std  # (1,3,H,W)\n",
    "        return img_tensor_norm\n",
    "    \n",
    "def hann1d(sz: int, centered = True) -> torch.Tensor:\n",
    "    \"\"\"1D cosine window.\"\"\"\n",
    "    if centered:\n",
    "        return 0.5 * (1 - torch.cos((2 * math.pi / (sz + 1)) * torch.arange(1, sz + 1).float()))\n",
    "    w = 0.5 * (1 + torch.cos((2 * math.pi / (sz + 2)) * torch.arange(0, sz//2 + 1).float()))\n",
    "    return torch.cat([w, w[1:sz-sz//2].flip((0,))])\n",
    "    \n",
    "def hann2d(sz: torch.Tensor, centered = True) -> torch.Tensor:\n",
    "    \"\"\"2D cosine window.\"\"\"\n",
    "    return hann1d(sz[0].item(), centered).reshape(1, 1, -1, 1) * hann1d(sz[1].item(), centered).reshape(1, 1, 1, -1)    \n",
    "\n",
    "def sample_target(im, target_bb, search_area_factor, output_sz=None):\n",
    "   \n",
    "    if not isinstance(target_bb, list):\n",
    "        x, y, w, h = target_bb.tolist()\n",
    "    else:\n",
    "        x, y, w, h = target_bb\n",
    "    # Crop image\n",
    "    crop_sz = math.ceil(math.sqrt(w * h) * search_area_factor)\n",
    "\n",
    "    if crop_sz < 1:\n",
    "        raise Exception('Too small bounding box.')\n",
    "\n",
    "    x1 = round(x + 0.5 * w - crop_sz * 0.5)\n",
    "    x2 = x1 + crop_sz\n",
    "\n",
    "    y1 = round(y + 0.5 * h - crop_sz * 0.5)\n",
    "    y2 = y1 + crop_sz\n",
    "\n",
    "    x1_pad = max(0, -x1)\n",
    "    x2_pad = max(x2 - im.shape[1] + 1, 0)\n",
    "\n",
    "    y1_pad = max(0, -y1)\n",
    "    y2_pad = max(y2 - im.shape[0] + 1, 0)\n",
    "\n",
    "    # Crop target\n",
    "    im_crop = im[y1 + y1_pad:y2 - y2_pad, x1 + x1_pad:x2 - x2_pad, :]\n",
    "\n",
    "    # Pad\n",
    "    im_crop_padded = cv2.copyMakeBorder(im_crop, y1_pad, y2_pad, x1_pad, x2_pad, cv2.BORDER_CONSTANT)\n",
    "    # deal with attention mask\n",
    "    H, W, _ = im_crop_padded.shape\n",
    "\n",
    "    if output_sz is not None:\n",
    "        resize_factor = output_sz / crop_sz\n",
    "        im_crop_padded = cv2.resize(im_crop_padded, (output_sz, output_sz))\n",
    "\n",
    "        return im_crop_padded, resize_factor\n",
    "\n",
    "    else:\n",
    "        return im_crop_padded, 1.0\n",
    "def transform_image_to_crop(box_in: torch.Tensor, box_extract: torch.Tensor, resize_factor: float,\n",
    "                            crop_sz: torch.Tensor, normalize=False) -> torch.Tensor:\n",
    "   \n",
    "    box_extract_center = box_extract[0:2] + 0.5 * box_extract[2:4]\n",
    "\n",
    "    box_in_center = box_in[0:2] + 0.5 * box_in[2:4]\n",
    "\n",
    "    box_out_center = (crop_sz - 1) / 2 + (box_in_center - box_extract_center) * resize_factor\n",
    "    box_out_wh = box_in[2:4] * resize_factor\n",
    "\n",
    "    box_out = torch.cat((box_out_center - 0.5 * box_out_wh, box_out_wh))\n",
    "    if normalize:\n",
    "        return box_out / (crop_sz[0]-1)\n",
    "    else:\n",
    "        return box_out\n",
    "def clip_box(box: list, H, W, margin=0):\n",
    "    x1, y1, w, h = box\n",
    "    x2, y2 = x1 + w, y1 + h\n",
    "    x1 = min(max(0, x1), W-margin)\n",
    "    x2 = min(max(margin, x2), W)\n",
    "    y1 = min(max(0, y1), H-margin)\n",
    "    y2 = min(max(margin, y2), H)\n",
    "    w = max(margin, x2-x1)\n",
    "    h = max(margin, y2-y1)\n",
    "    return [x1, y1, w, h]\n",
    "\n",
    "class BaseTracker():\n",
    "    \"\"\"Base class for all trackers.\"\"\"\n",
    "\n",
    "    def __init__(self, params):\n",
    "        self.params = params\n",
    "        self.visdom = None\n",
    "\n",
    "    def predicts_segmentation_mask(self):\n",
    "        return False\n",
    "\n",
    "    def initialize(self, image, info: dict) -> dict:\n",
    "        \"\"\"Overload this function in your tracker. This should initialize the model.\"\"\"\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def track(self, image, info: dict = None) -> dict:\n",
    "        \"\"\"Overload this function in your tracker. This should track in the frame and update the model.\"\"\"\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def visdom_draw_tracking(self, image, box, segmentation=None):\n",
    "        # Упрощенная обработка box без OrderedDict\n",
    "        if isinstance(box, dict):  # Проверяем на обычный dict вместо OrderedDict\n",
    "            box = list(box.values())  # Берем только значения\n",
    "        elif not isinstance(box, (list, tuple)):  # Если не коллекция\n",
    "            box = (box,)  # Превращаем в кортеж\n",
    "        \n",
    "        # Визуализация\n",
    "        if segmentation is None:\n",
    "            self.visdom.register((image, *box), 'Tracking', 1, 'Tracking')\n",
    "        else:\n",
    "            self.visdom.register((image, *box, segmentation), 'Tracking', 1, 'Tracking')\n",
    "\n",
    "\n",
    "class MCITRACK(BaseTracker):\n",
    "    def __init__(self, params):\n",
    "        \n",
    "        super(MCITRACK, self).__init__(params)\n",
    "        network = build_mcitrack(params.cfg)\n",
    "        network.load_state_dict(torch.load(\"MCITRACK_ep0300.pth.tar\", map_location='cpu')['net'], strict=True)\n",
    "        \n",
    "        self.cfg = params.cfg\n",
    "        self.network = network.cuda()\n",
    "        self.network.eval()\n",
    "        self.preprocessor = Preprocessor()\n",
    "        self.state = None\n",
    "\n",
    "        self.fx_sz = self.cfg[\"TEST\"][\"SEARCH_SIZE\"] // self.cfg[\"MODEL\"][\"ENCODER\"][\"STRIDE\"]\n",
    "        if self.cfg[\"TEST\"][\"WINDOW\"] == True:  # for window penalty\n",
    "            self.output_window = hann2d(torch.tensor([self.fx_sz, self.fx_sz]).long(), centered=True).cuda()\n",
    "\n",
    "        self.num_template = self.cfg[\"TEST\"][\"NUM_TEMPLATES\"]\n",
    "\n",
    "   \n",
    "        self.frame_id = 0\n",
    "        # for update\n",
    "        self.h_state = [None] * self.cfg[\"MODEL\"][\"NECK\"][\"N_LAYERS\"]\n",
    "\n",
    "\n",
    "\n",
    "        self.memory_bank = self.cfg[\"TEST\"][\"MB\"][\"DEFAULT\"]\n",
    "        self.update_h_t = self.cfg[\"TEST\"][\"UPH\"][\"DEFAULT\"]\n",
    "        self.update_threshold = self.cfg[\"TEST\"][\"UPT\"][\"DEFAULT\"]\n",
    "        self.update_intervals = self.cfg[\"TEST\"][\"INTER\"][\"DEFAULT\"]\n",
    "        print(\"Update threshold is: \", self.memory_bank)\n",
    "\n",
    "    def initialize(self, image, info: dict):\n",
    "\n",
    "\n",
    "        # get the initial templates\n",
    "        z_patch_arr, resize_factor = sample_target(image, info['init_bbox'], self.params.template_factor,\n",
    "                                                   output_sz=self.params.template_size)\n",
    "        z_patch_arr = z_patch_arr\n",
    "        template = self.preprocessor.process(z_patch_arr)\n",
    "        self.template_list = [template] * self.num_template\n",
    "\n",
    "        self.state = info['init_bbox']\n",
    "        prev_box_crop = transform_image_to_crop(torch.tensor(info['init_bbox']),\n",
    "                                                torch.tensor(info['init_bbox']),\n",
    "                                                resize_factor,\n",
    "                                                torch.Tensor([self.params.template_size, self.params.template_size]),\n",
    "                                                normalize=True)\n",
    "        self.template_anno_list = [prev_box_crop.to(template.device).unsqueeze(0)] * self.num_template\n",
    "        self.frame_id = 0\n",
    "        self.memory_template_list = self.template_list.copy()\n",
    "        self.memory_template_anno_list = self.template_anno_list.copy()\n",
    "\n",
    "\n",
    "    def track(self, image, info: dict = None):\n",
    "        H, W, _ = image.shape\n",
    "        self.frame_id += 1\n",
    "        x_patch_arr, resize_factor = sample_target(image, self.state, self.params.search_factor,\n",
    "                                                   output_sz=self.params.search_size)  # (x1, y1, w, h)\n",
    "        search = self.preprocessor.process(x_patch_arr)\n",
    "        search_list = [search]\n",
    "\n",
    "        # run the encoder\n",
    "\n",
    "        with torch.no_grad():\n",
    "            out_dict = self.network.forward(\n",
    "                template_list=self.template_list,\n",
    "                search_list=search_list,\n",
    "                template_anno_list=self.template_anno_list,\n",
    "                \n",
    "                gt_score_map=None\n",
    "            )\n",
    "\n",
    "        \n",
    "\n",
    "        # add hann windows\n",
    "        pred_score_map = out_dict['score_map']\n",
    "        if self.cfg[\"TEST\"][\"WINDOW\"] == True:  # for window penalty\n",
    "            response = self.output_window * pred_score_map\n",
    "        else:\n",
    "            response = pred_score_map\n",
    "        if 'size_map' in out_dict.keys():\n",
    "            pred_boxes, conf_score = self.network.decoder.cal_bbox(response, out_dict['size_map'],\n",
    "                                                                   out_dict['offset_map'], return_score=True)\n",
    "        else:\n",
    "            pred_boxes, conf_score = self.network.decoder.cal_bbox(response,\n",
    "                                                                   out_dict['offset_map'],\n",
    "                                                                   return_score=True)\n",
    "        pred_boxes = pred_boxes.view(-1, 4)\n",
    "        # Baseline: Take the mean of all pred boxes as the final result\n",
    "        pred_box = (pred_boxes.mean(dim=0) * self.params.search_size / resize_factor).tolist()  # (cx, cy, w, h) [0,1]\n",
    "        # get the final box result\n",
    "        self.state = clip_box(self.map_box_back(pred_box, resize_factor), H, W, margin=10)\n",
    "        # update hiden state\n",
    "        # self.h_state = h\n",
    "        # if conf_score.item() < self.update_h_t:\n",
    "        #     self.h_state = [None] * self.cfg[\"MODEL\"][\"NECK\"][\"N_LAYERS\"]\n",
    "\n",
    "        # update the template\n",
    "        if self.num_template > 1:\n",
    "            if (conf_score > self.update_threshold):\n",
    "                z_patch_arr, resize_factor = sample_target(image, self.state, self.params.template_factor,\n",
    "                                                           output_sz=self.params.template_size)\n",
    "                template = self.preprocessor.process(z_patch_arr)\n",
    "                self.memory_template_list.append(template)\n",
    "                prev_box_crop = transform_image_to_crop(torch.tensor(self.state),\n",
    "                                                        torch.tensor(self.state),\n",
    "                                                        resize_factor,\n",
    "                                                        torch.Tensor(\n",
    "                                                            [self.params.template_size, self.params.template_size]),\n",
    "                                                        normalize=True)\n",
    "                self.memory_template_anno_list.append(prev_box_crop.to(template.device).unsqueeze(0))\n",
    "                if len(self.memory_template_list) > self.memory_bank:\n",
    "                    self.memory_template_list.pop(0)\n",
    "                    self.memory_template_anno_list.pop(0)\n",
    "        if (self.frame_id % self.update_intervals == 0):\n",
    "            assert len(self.memory_template_anno_list) == len(self.memory_template_list)\n",
    "            len_list = len(self.memory_template_anno_list)\n",
    "            interval = len_list // self.num_template\n",
    "            for i in range(1, self.num_template):\n",
    "                idx = interval * i\n",
    "                if idx > len_list:\n",
    "                    idx = len_list\n",
    "                self.template_list.append(self.memory_template_list[idx])\n",
    "                self.template_list.pop(1)\n",
    "                self.template_anno_list.append(self.memory_template_anno_list[idx])\n",
    "                self.template_anno_list.pop(1)\n",
    "        assert len(self.template_list) == self.num_template\n",
    "\n",
    "\n",
    "\n",
    "        return {\"target_bbox\": self.state,\n",
    "                \"best_score\": conf_score}\n",
    "\n",
    "    def map_box_back(self, pred_box: list, resize_factor: float):\n",
    "        cx_prev, cy_prev = self.state[0] + 0.5 * self.state[2], self.state[1] + 0.5 * self.state[3]\n",
    "        cx, cy, w, h = pred_box\n",
    "        half_side = 0.5 * self.params.search_size / resize_factor\n",
    "        cx_real = cx + (cx_prev - half_side)\n",
    "        cy_real = cy + (cy_prev - half_side)\n",
    "        return [cx_real - 0.5 * w, cy_real - 0.5 * h, w, h]\n",
    "\n",
    "    def map_box_back_batch(self, pred_box: torch.Tensor, resize_factor: float):\n",
    "        cx_prev, cy_prev = self.state[0] + 0.5 * self.state[2], self.state[1] + 0.5 * self.state[3]\n",
    "        cx, cy, w, h = pred_box.unbind(-1)  # (N,4) --> (N,)\n",
    "        half_side = 0.5 * self.params.search_size / resize_factor\n",
    "        cx_real = cx + (cx_prev - half_side)\n",
    "        cy_real = cy + (cy_prev - half_side)\n",
    "        return torch.stack([cx_real - 0.5 * w, cy_real - 0.5 * h, w, h], dim=-1)\n",
    "\n",
    "class MCITrack(nn.Module):\n",
    "    \n",
    "    def __init__(self, encoder, decoder, neck, cfg,\n",
    "                 num_frames=1, num_template=1, decoder_type=\"CENTER\"):\n",
    "      \n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder_type = decoder_type\n",
    "        self.neck = neck\n",
    "\n",
    "        self.num_patch_x = self.encoder.body.num_patches_search\n",
    "        self.num_patch_z = self.encoder.body.num_patches_template\n",
    "        self.fx_sz = int(math.sqrt(self.num_patch_x))\n",
    "        self.fz_sz = int(math.sqrt(self.num_patch_z))\n",
    "\n",
    "        self.decoder = decoder\n",
    "\n",
    "        self.num_frames = num_frames\n",
    "        self.num_template = num_template\n",
    "        self.freeze_en = cfg[\"TRAIN\"][\"FREEZE_ENCODER\"]\n",
    "        self.interaction_indexes = cfg[\"MODEL\"][\"ENCODER\"][\"INTERACTION_INDEXES\"]\n",
    "\n",
    "    def forward(self, template_list, search_list, template_anno_list, gt_score_map=None):\n",
    "    \n",
    "        # Step 1: Forward pass through the encoder\n",
    "        \n",
    "        neck_h_state=[None,None,None,None]\n",
    "        \n",
    "        xz = self.encoder(template_list, search_list, template_anno_list)\n",
    "\n",
    "        # Step 2: Forward pass through the neck\n",
    "        xs = xz[:, 0:self.num_patch_x]  # Extract patch embeddings\n",
    "        x, xs, h = self.neck(\n",
    "            xz, xs, neck_h_state, \n",
    "            self.encoder.body.blocks, \n",
    "            self.interaction_indexes\n",
    "        )\n",
    "        x = self.encoder.body.fc_norm(x)\n",
    "        xs = xs + x[:, 0:self.num_patch_x]  # Updated patch embeddings\n",
    "\n",
    "        # Step 3: Forward pass through the decoder\n",
    "        bs, HW, C = xs.size()\n",
    "        if self.decoder_type in ['CORNER', 'CENTER']:\n",
    "            xs = xs.permute((0, 2, 1)).contiguous()\n",
    "            xs = xs.view(bs, C, self.fx_sz, self.fx_sz)\n",
    "\n",
    "        if self.decoder_type == \"CORNER\":\n",
    "            # Run the corner head\n",
    "            pred_box, score_map = self.decoder(xs, True)\n",
    "            outputs_coord = box_xyxy_to_cxcywh(pred_box)\n",
    "            outputs_coord_new = outputs_coord.view(bs, 1, 4)\n",
    "            return {\n",
    "                'pred_boxes': outputs_coord_new,\n",
    "                'score_map': score_map\n",
    "            }\n",
    "\n",
    "        elif self.decoder_type == \"CENTER\":\n",
    "            # Run the center head\n",
    "            score_map_ctr, bbox, size_map, offset_map = self.decoder(xs, gt_score_map)\n",
    "            outputs_coord = bbox\n",
    "            outputs_coord_new = outputs_coord.view(bs, 1, 4)\n",
    "            return {\n",
    "                'pred_boxes': outputs_coord_new,\n",
    "                'score_map': score_map_ctr,\n",
    "                'size_map': size_map,\n",
    "                'offset_map': offset_map\n",
    "            }\n",
    "\n",
    "        elif self.decoder_type == \"MLP\":\n",
    "            # Run the MLP head\n",
    "            score_map, bbox, offset_map = self.decoder(xs, gt_score_map)\n",
    "            outputs_coord = bbox\n",
    "            outputs_coord_new = outputs_coord.view(bs, 1, 4)\n",
    "            return {\n",
    "                'pred_boxes': outputs_coord_new,\n",
    "                'score_map': score_map,\n",
    "                'offset_map': offset_map\n",
    "            }\n",
    "\n",
    "        else:\n",
    "            raise NotImplementedError(f\"Decoder type not supported: {self.decoder_type}\")\n",
    "\n",
    "def build_mcitrack(cfg):\n",
    "    encoder = build_encoder(cfg)\n",
    "    neck = build_neck(cfg,encoder)\n",
    "    decoder = build_decoder(cfg, neck)\n",
    "    model = MCITrack(\n",
    "        encoder,\n",
    "        decoder,\n",
    "        neck,\n",
    "        cfg,\n",
    "        num_frames = cfg[\"DATA\"][\"SEARCH\"][\"NUMBER\"],\n",
    "        num_template = cfg[\"DATA\"][\"TEMPLATE\"][\"NUMBER\"],\n",
    "        decoder_type=cfg[\"MODEL\"][\"DECODER\"][\"TYPE\"],\n",
    "    )\n",
    "    return model\n",
    "\n",
    "def get_tracker_class():\n",
    "    return MCITRACK\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "407a71c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = {}\n",
    "\n",
    "# MODEL\n",
    "cfg[\"MODEL\"] = {}\n",
    "\n",
    "# MODEL.ENCODER\n",
    "cfg[\"MODEL\"][\"ENCODER\"] = {\n",
    "    \"TYPE\": \"dinov2_vitb14\",  # encoder model\n",
    "    \"DROP_PATH\": 0,\n",
    "    \"PRETRAIN_TYPE\": \"mae\",  # mae, default, or scratch. This parameter is not activated for dinov2.\n",
    "    \"USE_CHECKPOINT\": False,  # to save the memory.\n",
    "    \"STRIDE\": 14,\n",
    "    \"POS_TYPE\": 'interpolate',  # type of loading the positional encoding. \"interpolate\" or \"index\".\n",
    "    \"TOKEN_TYPE_INDICATE\": False,  # add a token_type_embedding to indicate the search, template_foreground, template_background\n",
    "    \"INTERACTION_INDEXES\": [[0, 6], [6, 12], [12, 18], [18, 24]],\n",
    "    \"GRAD_CKPT\": False\n",
    "}\n",
    "\n",
    "# MODEL.NECK\n",
    "cfg[\"MODEL\"][\"NECK\"] = {\n",
    "    \"N_LAYERS\": 4,\n",
    "    \"D_MODEL\": 512,\n",
    "    \"D_STATE\": 16  # MAMABA_HIDDEN_STATE\n",
    "}\n",
    "\n",
    "# MODEL.DECODER\n",
    "cfg[\"MODEL\"][\"DECODER\"] = {\n",
    "    \"TYPE\": \"CENTER\",  # MLP, CORNER, CENTER\n",
    "    \"NUM_CHANNELS\": 256\n",
    "}\n",
    "\n",
    "# TRAIN\n",
    "cfg[\"TRAIN\"] = {\n",
    "    \"LR\": 0.0001,\n",
    "    \"WEIGHT_DECAY\": 0.0001,\n",
    "    \"EPOCH\": 500,\n",
    "    \"LR_DROP_EPOCH\": 400,\n",
    "    \"BATCH_SIZE\": 8,\n",
    "    \"NUM_WORKER\": 8,\n",
    "    \"OPTIMIZER\": \"ADAMW\",\n",
    "    \"ENCODER_MULTIPLIER\": 0.1,  # encoder's LR = this factor * LR\n",
    "    \"FREEZE_ENCODER\": False,  # for freezing the parameters of encoder\n",
    "    \"ENCODER_OPEN\": [],  # only for debug, open some layers of encoder when FREEZE_ENCODER is True\n",
    "    \"CE_WEIGHT\": 1.0,  # weight for cross-entropy loss\n",
    "    \"GIOU_WEIGHT\": 2.0,\n",
    "    \"L1_WEIGHT\": 5.0,\n",
    "    \"PRINT_INTERVAL\": 50,  # interval to print the training log\n",
    "    \"GRAD_CLIP_NORM\": 0.1,\n",
    "    \"FIX_BN\": False,\n",
    "    \"ENCODER_W\": \"\",\n",
    "    \"TYPE\": \"normal\",  # normal, peft or fft\n",
    "    \"PRETRAINED_PATH\": None\n",
    "}\n",
    "\n",
    "# TRAIN.SCHEDULER\n",
    "cfg[\"TRAIN\"][\"SCHEDULER\"] = {\n",
    "    \"TYPE\": \"step\",\n",
    "    \"DECAY_RATE\": 0.1\n",
    "}\n",
    "\n",
    "# DATA\n",
    "cfg[\"DATA\"] = {\n",
    "    \"MEAN\": [0.485, 0.456, 0.406],\n",
    "    \"STD\": [0.229, 0.224, 0.225],\n",
    "    \"MAX_SAMPLE_INTERVAL\": 200,\n",
    "    \"SAMPLER_MODE\": \"order\",\n",
    "    \"LOADER\": \"tracking\"\n",
    "}\n",
    "\n",
    "# DATA.TRAIN\n",
    "cfg[\"DATA\"][\"TRAIN\"] = {\n",
    "    \"DATASETS_NAME\": [\"LASOT\", \"GOT10K_vottrain\"],\n",
    "    \"DATASETS_RATIO\": [1, 1],\n",
    "    \"SAMPLE_PER_EPOCH\": 60000\n",
    "}\n",
    "\n",
    "# DATA.SEARCH\n",
    "cfg[\"DATA\"][\"SEARCH\"] = {\n",
    "    \"NUMBER\": 1,  # number of search region, only support 1 for now.\n",
    "    \"SIZE\": 256,\n",
    "    \"FACTOR\": 4.0,\n",
    "    \"CENTER_JITTER\": 3.5,\n",
    "    \"SCALE_JITTER\": 0.5\n",
    "}\n",
    "\n",
    "# DATA.TEMPLATE\n",
    "cfg[\"DATA\"][\"TEMPLATE\"] = {\n",
    "    \"NUMBER\": 1,\n",
    "    \"SIZE\": 128,\n",
    "    \"FACTOR\": 2.0,\n",
    "    \"CENTER_JITTER\": 0,\n",
    "    \"SCALE_JITTER\": 0\n",
    "}\n",
    "\n",
    "# TEST\n",
    "cfg[\"TEST\"] = {\n",
    "    \"TEMPLATE_FACTOR\": 4.0,\n",
    "    \"TEMPLATE_SIZE\": 256,\n",
    "    \"SEARCH_FACTOR\": 2.0,\n",
    "    \"SEARCH_SIZE\": 128,\n",
    "    \"EPOCH\": 500,\n",
    "    \"WINDOW\": False,  # window penalty\n",
    "    \"NUM_TEMPLATES\": 1\n",
    "}\n",
    "\n",
    "# TEST.UPT\n",
    "cfg[\"TEST\"][\"UPT\"] = {\n",
    "    \"DEFAULT\": 1,\n",
    "    \"LASOT\": 0,\n",
    "    \"LASOT_EXTENSION_SUBSET\": 0,\n",
    "    \"TRACKINGNET\": 0,\n",
    "    \"TNL2K\": 0,\n",
    "    \"NFS\": 0,\n",
    "    \"UAV\": 0,\n",
    "    \"VOT20\": 0,\n",
    "    \"GOT10K_TEST\": 0\n",
    "}\n",
    "\n",
    "# TEST.UPH\n",
    "cfg[\"TEST\"][\"UPH\"] = {\n",
    "    \"DEFAULT\": 1,\n",
    "    \"LASOT\": 0,\n",
    "    \"LASOT_EXTENSION_SUBSET\": 0,\n",
    "    \"TRACKINGNET\": 0,\n",
    "    \"TNL2K\": 0,\n",
    "    \"NFS\": 0,\n",
    "    \"UAV\": 0,\n",
    "    \"VOT20\": 0,\n",
    "    \"GOT10K_TEST\": 0\n",
    "}\n",
    "\n",
    "# TEST.INTER\n",
    "cfg[\"TEST\"][\"INTER\"] = {\n",
    "    \"DEFAULT\": 999999,\n",
    "    \"LASOT\": 0,\n",
    "    \"LASOT_EXTENSION_SUBSET\": 0,\n",
    "    \"TRACKINGNET\": 0,\n",
    "    \"TNL2K\": 0,\n",
    "    \"NFS\": 0,\n",
    "    \"UAV\": 0,\n",
    "    \"VOT20\": 0,\n",
    "    \"GOT10K_TEST\": 0\n",
    "}\n",
    "\n",
    "# TEST.MB\n",
    "cfg[\"TEST\"][\"MB\"] = {\n",
    "    \"DEFAULT\": 500,\n",
    "    \"LASOT\": 0,\n",
    "    \"LASOT_EXTENSION_SUBSET\": 0,\n",
    "    \"TRACKINGNET\": 0,\n",
    "    \"TNL2K\": 0,\n",
    "    \"NFS\": 0,\n",
    "    \"UAV\": 0,\n",
    "    \"VOT20\": 0,\n",
    "    \"GOT10K_TEST\": 0\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5f2804bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test config:  {'MODEL': {'ENCODER': {'TYPE': 'fastitpnt', 'DROP_PATH': 0.1, 'PRETRAIN_TYPE': './fast_itpn_tiny_1600e_1k.pt', 'USE_CHECKPOINT': False, 'STRIDE': 16, 'POS_TYPE': 'index', 'TOKEN_TYPE_INDICATE': True, 'INTERACTION_INDEXES': [[4, 7], [7, 10], [10, 13], [13, 16]], 'GRAD_CKPT': False}, 'NECK': {'N_LAYERS': 4, 'D_MODEL': 384, 'D_STATE': 16}, 'DECODER': {'TYPE': 'CENTER', 'NUM_CHANNELS': 256}}, 'TRAIN': {'LR': 0.0004, 'WEIGHT_DECAY': 0.0001, 'EPOCH': 300, 'LR_DROP_EPOCH': 240, 'BATCH_SIZE': 64, 'NUM_WORKER': 10, 'OPTIMIZER': 'ADAMW', 'ENCODER_MULTIPLIER': 0.1, 'FREEZE_ENCODER': False, 'ENCODER_OPEN': [], 'CE_WEIGHT': 1.0, 'GIOU_WEIGHT': 2.0, 'L1_WEIGHT': 5.0, 'PRINT_INTERVAL': 50, 'GRAD_CLIP_NORM': 0.1, 'FIX_BN': False, 'ENCODER_W': '', 'TYPE': 'normal', 'PRETRAINED_PATH': None, 'SCHEDULER': {'TYPE': 'step', 'DECAY_RATE': 0.1}}, 'DATA': {'MEAN': [0.485, 0.456, 0.406], 'STD': [0.229, 0.224, 0.225], 'MAX_SAMPLE_INTERVAL': 400, 'SAMPLER_MODE': 'order', 'LOADER': 'tracking', 'TRAIN': {'DATASETS_NAME': ['LASOT', 'GOT10K_vottrain', 'COCO17', 'TRACKINGNET', 'VASTTRACK'], 'DATASETS_RATIO': [1, 1, 1, 1, 1], 'SAMPLE_PER_EPOCH': 60000}, 'SEARCH': {'NUMBER': 2, 'SIZE': 224, 'FACTOR': 4.0, 'CENTER_JITTER': 3.5, 'SCALE_JITTER': 0.5}, 'TEMPLATE': {'NUMBER': 5, 'SIZE': 112, 'FACTOR': 2.0, 'CENTER_JITTER': 0, 'SCALE_JITTER': 0}}, 'TEST': {'TEMPLATE_FACTOR': 2.0, 'TEMPLATE_SIZE': 112, 'SEARCH_FACTOR': 4.0, 'SEARCH_SIZE': 224, 'EPOCH': 300, 'WINDOW': True, 'NUM_TEMPLATES': 5, 'UPT': {'DEFAULT': 1, 'LASOT': 0.8, 'LASOT_EXTENSION_SUBSET': 0.85, 'TRACKINGNET': 0.5, 'TNL2K': 0.5, 'NFS': 0.8, 'UAV': 0.2, 'VOT20': 0.4, 'GOT10K_TEST': 0}, 'UPH': {'DEFAULT': 1, 'LASOT': 0.88, 'LASOT_EXTENSION_SUBSET': 0.97, 'TRACKINGNET': 0.9, 'TNL2K': 0.9, 'NFS': 0.92, 'UAV': 0.91, 'VOT20': 0.94, 'GOT10K_TEST': 0}, 'INTER': {'DEFAULT': 999999, 'LASOT': 70, 'LASOT_EXTENSION_SUBSET': 50, 'TRACKINGNET': 20, 'TNL2K': 20, 'NFS': 90, 'UAV': 1, 'VOT20': 1, 'GOT10K_TEST': 0}, 'MB': {'DEFAULT': 500, 'LASOT': 500, 'LASOT_EXTENSION_SUBSET': 500, 'TRACKINGNET': 200, 'TNL2K': 500, 'NFS': 500, 'UAV': 400, 'VOT20': 500, 'GOT10K_TEST': 0}}}\n"
     ]
    }
   ],
   "source": [
    "#Params\n",
    "class TrackerParams:\n",
    "    \"\"\"Class for tracker parameters.\"\"\"\n",
    "    def set_default_values(self, default_vals: dict):\n",
    "        for name, val in default_vals.items():\n",
    "            if not hasattr(self, name):\n",
    "                setattr(self, name, val)\n",
    "\n",
    "    def get(self, name: str, *default):\n",
    "        \"\"\"Get a parameter value with the given name. If it does not exists, it return the default value given as a\n",
    "        second argument or returns an error if no default value is given.\"\"\"\n",
    "        if len(default) > 1:\n",
    "            raise ValueError('Can only give one default value.')\n",
    "\n",
    "        if not default:\n",
    "            return getattr(self, name)\n",
    "\n",
    "        return getattr(self, name, default[0])\n",
    "\n",
    "    def has(self, name: str):\n",
    "        \"\"\"Check if there exist a parameter with the given name.\"\"\"\n",
    "        return hasattr(self, name)\n",
    "\n",
    "def _update_config(base_cfg, exp_cfg):\n",
    "    if isinstance(base_cfg, dict) and isinstance(exp_cfg, dict):\n",
    "        for k, v in exp_cfg.items():\n",
    "            if k in base_cfg:\n",
    "                if not isinstance(v, dict):\n",
    "                    base_cfg[k] = v\n",
    "                else:\n",
    "                    _update_config(base_cfg[k], v)\n",
    "            else:\n",
    "                raise ValueError(\"{} not exist in config.py\".format(k))\n",
    "    else:\n",
    "        return\n",
    "\n",
    "def update_config_from_file(filename):\n",
    "    exp_config = None\n",
    "    with open(filename) as f:\n",
    "        exp_config = yaml.safe_load(f)\n",
    "        _update_config(cfg, exp_config)\n",
    "    \n",
    "def parameters(yaml_name: str):\n",
    "    params = TrackerParams()\n",
    "\n",
    "    yaml_file = \"mcitrack_t224.yaml\"\n",
    "    update_config_from_file(yaml_file)\n",
    "    params.cfg = cfg\n",
    "    print(\"test config: \", cfg)\n",
    "\n",
    "    params.yaml_name = yaml_name\n",
    "    # template and search region\n",
    "    params.template_factor = cfg[\"TEST\"][\"TEMPLATE_FACTOR\"]\n",
    "    params.template_size = cfg[\"TEST\"][\"TEMPLATE_SIZE\"]\n",
    "    params.search_factor = cfg[\"TEST\"][\"SEARCH_FACTOR\"]\n",
    "    params.search_size = cfg[\"TEST\"][\"SEARCH_SIZE\"]\n",
    "\n",
    "    # Network checkpoint path\n",
    "    params.checkpoint = \"fast_itpn_tiny_1600e_1k.pt\"\n",
    "    # whether to save boxes from all queries\n",
    "    params.save_all_boxes = False\n",
    "\n",
    "    return params\n",
    "\n",
    "params = parameters(\"./mcitrack_t224.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ae331c67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Update threshold is:  500\n"
     ]
    }
   ],
   "source": [
    "tracker = MCITRACK(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "097a57d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "network = build_mcitrack(params.cfg)\n",
    "network.load_state_dict(torch.load(\"MCITRACK_ep0300.pth.tar\", map_location='cpu')['net'], strict=True)\n",
    "cfg = params.cfg\n",
    "network = network.cuda()\n",
    "network.eval()\n",
    "list1 = [torch.zeros(1, 3, 112, 112).to('cuda') for _ in range(5)]  # 5 тензоров размером [1, 3, 112, 112]\n",
    "list2 = [torch.zeros(1, 3, 224, 224).to('cuda')]                    # 1 тензор размером [1, 3, 224, 224]\n",
    "list3 = [torch.zeros(1, 4).to('cuda') for _ in range(5)]\n",
    "res = network.forward(list1,list2,list3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aa6b8c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_17528\\1057810194.py:196: TracerWarning: Converting a tensor to a Python integer might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  x = x.transpose(1,2).view(B,C,int(N**0.5),int(N**0.5)).contiguous()\n"
     ]
    }
   ],
   "source": [
    "#ModelWrapper jit\n",
    "class ModelWrapper(torch.nn.Module):\n",
    "    def __init__(self, original_model):\n",
    "        super(ModelWrapper, self).__init__()\n",
    "        self.original_model = original_model\n",
    "\n",
    "    def forward(self, template_list, search_list,template_anno_list):\n",
    "        \n",
    "        output_dict = self.original_model(template_list, search_list,template_anno_list)\n",
    "        \n",
    "        \n",
    "        return (output_dict['pred_boxes'],\n",
    "                output_dict['score_map'],\n",
    "                output_dict['size_map'],\n",
    "                output_dict['offset_map'])\n",
    "\n",
    "\n",
    "model = network\n",
    "model.eval()\n",
    "\n",
    "\n",
    "wrapped_model = ModelWrapper(model)\n",
    "\n",
    "\n",
    "template_list = [torch.zeros(1, 3, 112, 112).to('cuda') for _ in range(5)]  # 5 тензоров размером [1, 3, 112, 112]\n",
    "search_list = [torch.zeros(1, 3, 224, 224).to('cuda')]                    # 1 тензор размером [1, 3, 224, 224]\n",
    "template_anno_list = [torch.zeros(1, 4).to('cuda') for _ in range(5)]\n",
    "\n",
    "traced_model = torch.jit.trace(wrapped_model, (template_list, search_list,template_anno_list))\n",
    "\n",
    "\n",
    "optimized_model = torch.jit.optimize_for_inference(traced_model)\n",
    "\n",
    "\n",
    "optimized_model.save(\"MCITrack.pt\")\n",
    "\n",
    "\n",
    "loaded_model = torch.jit.load(\"MCITrack.pt\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = loaded_model(template_list, search_list,template_anno_list)\n",
    "\n",
    "for output in outputs:\n",
    "    print(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "99787837",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_16344\\2631578009.py:196: TracerWarning: Converting a tensor to a Python integer might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  x = x.transpose(1,2).view(B,C,int(N**0.5),int(N**0.5)).contiguous()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model has been exported to MCITrack.onnx\n"
     ]
    }
   ],
   "source": [
    "#ModelWrapper onnx\n",
    "import torch\n",
    "\n",
    "\n",
    "class ModelWrapper(torch.nn.Module):\n",
    "    def __init__(self, original_model):\n",
    "        super(ModelWrapper, self).__init__()\n",
    "        self.original_model = original_model\n",
    "\n",
    "    def forward(self, template_list, search_list,template_anno_list):\n",
    "        \n",
    "        output_dict = self.original_model(template_list, search_list,template_anno_list)\n",
    "        \n",
    "        \n",
    "        return (output_dict['pred_boxes'],\n",
    "                output_dict['score_map'],\n",
    "                output_dict['size_map'],\n",
    "                output_dict['offset_map'])\n",
    "\n",
    "\n",
    "\n",
    "model = network\n",
    "model.eval()\n",
    "\n",
    "\n",
    "wrapped_model = ModelWrapper(model)\n",
    "\n",
    "template_list = [torch.zeros(1, 3, 112, 112).to('cuda') for _ in range(5)]  # 5 тензоров размером [1, 3, 112, 112]\n",
    "search_list = [torch.zeros(1, 3, 224, 224).to('cuda')]                    # 1 тензор размером [1, 3, 224, 224]\n",
    "template_anno_list = [torch.zeros(1, 4).to('cuda') for _ in range(5)]\n",
    "\n",
    "# Важно: для onnx-модели модель должна быть на cpu или cuda, и входы должны быть на том же устройстве.\n",
    "wrapped_model = wrapped_model.to('cuda')\n",
    "wrapped_model.eval()\n",
    "\n",
    "# Указываем пути для сохранения\n",
    "onnx_path = \"MCITrack.onnx\"\n",
    "\n",
    "# Экспортируем модель в ONNX\n",
    "torch.onnx.export(\n",
    "    wrapped_model,                                   # Модель\n",
    "    (template_list, search_list,template_anno_list),                                # Входные данные (tuple)\n",
    "    onnx_path,                                       # Имя файла\n",
    "    export_params=True,                              # Экспортировать параметры (веса)\n",
    "    opset_version=17,                                # Версия ONNX opset\n",
    "    do_constant_folding=True,                        # Оптимизация констант\n",
    "    input_names = ['template_list', 'search_list','template_anno_list'],                        # Имена входов\n",
    "    output_names = ['pred_boxes','score_map','size_map','offset_map'],                   # Имена выходов\n",
    "    #dynamic_axes={'z': {0: 'batch_size'},            # Динамическая ось для батча\n",
    "    #              'x': {0: 'batch_size'},\n",
    "    #              'pred_boxes': {0: 'batch_size'}},\n",
    "    verbose=True                                     # Показывать подробности\n",
    ")\n",
    "\n",
    "print(f'Model has been exported to {onnx_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1666b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TRT\n",
    "import tensorrt as trt\n",
    "#trtexec --onnx=MCITrack.onnx  --saveEngine=MCITrack.trt  --fp16\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1ae7ecd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Трекинг по видео\n",
    "file = \"0516.mp4\"\n",
    "video = cv2.VideoCapture(file)\n",
    "#fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "#fps=video.get(cv2.CAP_PROP_FPS)\n",
    "#video_vriter = cv2.VideoWriter(file.split('.')[0]+\"_\"+\".avi\", fourcc, fps, (1920, 1080))\n",
    "\n",
    "\n",
    "ok, image = video.read()\n",
    "if not video.isOpened():\n",
    "    print(\"Could not open video\")\n",
    "    sys.exit()\n",
    "    \n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "x, y, w, h = cv2.selectROI( image, fromCenter=False)\n",
    "init_state = [x, y, w, h]\n",
    "def _build_init_info(box):\n",
    "            return {'init_bbox': box}\n",
    "tracker.initialize(image, _build_init_info(init_state))\n",
    "counter = 0\n",
    "while True:\n",
    "            ok, image = video.read()\n",
    "            if not ok:\n",
    "                print(\"Can't read frame\")\n",
    "                break\n",
    "\n",
    "            \n",
    "            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "            start = time.time() \n",
    "            out  = tracker.track(image)\n",
    "            state = [int(s) for s in out['target_bbox']]\n",
    "            best_score=out[\"best_score\"].cpu().numpy()[0][0]\n",
    "            end_time = (time.time() - start)\n",
    "            \n",
    "            \n",
    "            org = (50, 50)\n",
    "\n",
    "            # fontScale\n",
    "            fontScale = 1\n",
    "            font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "            # Blue color in BGR\n",
    "            color = (255, 0, 0)\n",
    "            # Line thickness of 2 px\n",
    "            thickness = 2              \n",
    "            # Using cv2.putText() method\n",
    "            image = cv2.putText(image, str(best_score), org, font, \n",
    "                            fontScale, color, thickness, cv2.LINE_AA)\n",
    "            image = cv2.putText(image, str(end_time), (50,100), font, \n",
    "                            fontScale, color, thickness, cv2.LINE_AA)\n",
    "\n",
    "            x, y, w, h = [int(x) for x in state]\n",
    "\n",
    "            color = (0, 0, 255)  # Цвет в формате BGR\n",
    "            cv2.rectangle(image, (x, y), (x + w, y + h), color, 2)\n",
    "\n",
    "\n",
    "            cv2.imshow(\"tracking\", image)\n",
    "            #video_vriter.write(image)\n",
    "\n",
    "\n",
    "            k = cv2.waitKey(1)            \n",
    "            if k == 32:  # SPACE\n",
    "                ok, image = video.read()                             \n",
    "                x, y, w, h = cv2.selectROI( image, fromCenter=False)\n",
    "                init_state = [x, y, w, h]\n",
    "                tracker.initialize(image, _build_init_info(init_state))\n",
    "            if k == 27:  # ESC\n",
    "                break\n",
    "        \n",
    "                \n",
    "                \n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "#video.release()\n",
    "#video_vriter.release()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ab1d032c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Метрики\n",
    "import numpy as np\n",
    "\n",
    "def iou(boxA, boxB):\n",
    "    # boxA, boxB: [x, y, w, h]\n",
    "    xA = max(boxA[0], boxB[0])\n",
    "    yA = max(boxA[1], boxB[1])\n",
    "    xB = min(boxA[0] + boxA[2], boxB[0] + boxB[2])\n",
    "    yB = min(boxA[1] + boxA[3], boxB[1] + boxB[3])\n",
    "\n",
    "    interW = max(0, xB - xA)\n",
    "    interH = max(0, yB - yA)\n",
    "    interArea = interW * interH\n",
    "\n",
    "    boxAArea = boxA[2] * boxA[3]\n",
    "    boxBArea = boxB[2] * boxB[3]\n",
    "    unionArea = boxAArea + boxBArea - interArea\n",
    "\n",
    "    if unionArea == 0:\n",
    "        return 0.0\n",
    "    return interArea / unionArea\n",
    "\n",
    "def precision(boxA, boxB):\n",
    "    # центры bbox\n",
    "    centerA = (boxA[0] + boxA[2]/2, boxA[1] + boxA[3]/2)\n",
    "    centerB = (boxB[0] + boxB[2]/2, boxB[1] + boxB[3]/2)\n",
    "    dist = np.sqrt((centerA[0] - centerB[0])**2 + (centerA[1] - centerB[1])**2)\n",
    "    return dist\n",
    "sr_thresh = 0.5\n",
    "prec_thresh = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c2b0fbe5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FPS: 24.51\n",
      "Average Overlap (AO): 0.96\n",
      "Success Rate (SR@0.5): 1.00\n",
      "Precision @20px: 1.00\n"
     ]
    }
   ],
   "source": [
    "#Трекинг got10k с метриками\n",
    "import glob\n",
    "import time\n",
    "import  os\n",
    "gt_bboxes = []\n",
    "pred_bboxes = []\n",
    "seq_path = \"val/GOT-10k_Val_000002\"\n",
    "txt_files = glob.glob(os.path.join(seq_path, '*.txt'))\n",
    "if not txt_files:\n",
    "    raise FileNotFoundError(f\"No .txt files found in {seq_path}\")\n",
    "\n",
    "img_files = sorted(glob.glob(os.path.join(seq_path, '*.jpg')))\n",
    "with open(txt_files[0], 'r') as f:\n",
    "    gt_bboxes = [list(map(float, line.strip().split(','))) for line in f]\n",
    "\n",
    "# Получаем размер первого изображения\n",
    "sample_img = cv2.imread(img_files[0])\n",
    "if sample_img is None:\n",
    "    raise ValueError(f\"Failed to read sample image: {img_files[0]}\")\n",
    "\n",
    "# height, width = sample_img.shape[:2]\n",
    "# fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "# output_filename = f\"{seq_path.split('/')[-1]}_output.avi\"\n",
    "# video_vriter = cv2.VideoWriter(output_filename, fourcc, 10, (width, height))  \n",
    "\n",
    "assert len(img_files) == len(gt_bboxes), \"Количество кадров и bbox'ов не совпадает\"\n",
    "\n",
    "x, y, w, h = map(int, gt_bboxes[0])\n",
    "init_state = [x, y, w, h]\n",
    "\n",
    "def _build_init_info(box):\n",
    "            return {'init_bbox': box}\n",
    "\n",
    "counter = 0\n",
    "\n",
    "\n",
    "tracker.initialize(sample_img, _build_init_info(init_state))\n",
    "\n",
    "start_time = time.time()  # Начало замера\n",
    "\n",
    "for img_file, bbox in zip(img_files, gt_bboxes):\n",
    "        \n",
    "        # Читаем изображение\n",
    "        img = cv2.imread(img_file)\n",
    "        if img is None:\n",
    "            print(f\"Не удалось загрузить изображение: {img_file}\")\n",
    "            continue\n",
    "        \n",
    "        \n",
    "        out  = tracker.track(img)\n",
    "        state = [int(s) for s in out['target_bbox']]   \n",
    "                           \n",
    "        # Рисуем bounding box        \n",
    "        x, y, w, h = [int(x) for x in state]\n",
    "\n",
    "        cv2.rectangle(img, (x, y), (x + w, y + h), (0, 0, 200), 2)\n",
    "        \n",
    "        x1, y1, w1, h1 = map(int, bbox)\n",
    "        cv2.rectangle(img, (x1, y1), (x1+w1, y1+h1), (0, 200, 0), 2)\n",
    "        bbox_pred = x, y, w, h\n",
    "        \n",
    "        gt_bboxes.append(bbox)\n",
    "        pred_bboxes.append(bbox_pred)\n",
    "\n",
    "        cv2.imshow(seq_path, img)\n",
    "        # video_vriter.write(img)\n",
    "        counter+=1\n",
    "\n",
    "\n",
    "        # Выход по нажатию 'q' или ESC\n",
    "        key = cv2.waitKey(1) & 0xFF\n",
    "        if key == ord('q') or key == 27:\n",
    "            break\n",
    "       \n",
    "        \n",
    "                \n",
    "end_time = time.time()    # Конец замера    \n",
    "total_frames = counter       # Общее количество обработанных кадров\n",
    "total_time = end_time - start_time\n",
    "fps = total_frames / total_time\n",
    "ious = [iou(gt, pred) for gt, pred in zip(gt_bboxes, pred_bboxes)]\n",
    "ao = np.mean(ious)\n",
    "sr = np.mean([1 if val >= sr_thresh else 0 for val in ious])\n",
    "precisions = [precision(gt, pred) for gt, pred in zip(gt_bboxes, pred_bboxes)]\n",
    "prec = np.mean([1 if d <= prec_thresh else 0 for d in precisions])\n",
    "\n",
    "print(f\"FPS: {fps:.2f}\")\n",
    "print(f'Average Overlap (AO): {ao:.2f}')\n",
    "print(f'Success Rate (SR@0.5): {sr:.2f}')\n",
    "print(f'Precision @20px: {prec:.2f}')\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "# video_vriter.release()\n",
    "#print(f\"Video saved as: {output_filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fde457f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA доступна: True\n",
      "Версия CUDA (PyTorch): 12.8\n",
      "PyTorch version: 2.7.1+cu128\n",
      "TensorRT версия: 10.11.0.33\n",
      "ONNX версия: 1.18.0\n",
      "cuDNN включён в PyTorch: True\n",
      "Версия cuDNN (из PyTorch): 90701\n",
      "Версия onnxruntime: 1.20.1\n",
      "Device onnxruntime: GPU\n",
      "tensorflow не установлен\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(f\"CUDA доступна: {torch.cuda.is_available()}\")\n",
    "print(f\"Версия CUDA (PyTorch): {torch.version.cuda}\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")    \n",
    "try:\n",
    "    import tensorrt as trt\n",
    "    print(f\"TensorRT версия: {trt.__version__}\")\n",
    "except:\n",
    "    print(\"TensorRT не установлен\")\n",
    "    \n",
    "try:\n",
    "    import onnx\n",
    "    print(f\"ONNX версия: {onnx.__version__}\")\n",
    "except:\n",
    "    print(\"ONNX не установлен\") \n",
    "print(f\"cuDNN включён в PyTorch: {torch.backends.cudnn.enabled}\")\n",
    "print(f\"Версия cuDNN (из PyTorch): {torch.backends.cudnn.version()}\")\n",
    "try:\n",
    "    import onnxruntime as ort\n",
    "    print(f\"Версия onnxruntime: {ort.__version__}\")\n",
    "    print(f\"Device onnxruntime: {ort.get_device()}\")  # Должно вернуть 'GPU'\n",
    "except:\n",
    "    print(\"onnxruntime не установлен\")\n",
    "try:\n",
    "    import tensorflow as tf\n",
    "    print(f\"Версия tensorflow: {tf.__version__}\")\n",
    "except:\n",
    "    print(\"tensorflow не установлен\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7f63014f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Доступные провайдеры: ['TensorrtExecutionProvider', 'CUDAExecutionProvider', 'CPUExecutionProvider']\n",
      "Используется: ['CPUExecutionProvider']\n"
     ]
    }
   ],
   "source": [
    "import onnxruntime as ort\n",
    "\n",
    "# Проверка провайдеров\n",
    "print(\"Доступные провайдеры:\", ort.get_available_providers())\n",
    "\n",
    "# Создание сессии с TensorRT\n",
    "try:\n",
    "    sess = ort.InferenceSession(\n",
    "        \"MCITrack.onnx\",\n",
    "        providers=['CUDAExecutionProvider'],\n",
    "        provider_options = [{}],\n",
    "        )\n",
    "    print(\"Используется:\", sess.get_providers())\n",
    "except Exception as e:\n",
    "    print(\"Ошибка:\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e6b41ae6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Доступно GPU: 1\n",
      "Название GPU: NVIDIA GeForce RTX 3060 Ti\n",
      "Вычислительная способность: (8, 6)\n",
      "Общая память: 8191.50 МБ\n",
      "Контекст GPU активен: True\n"
     ]
    }
   ],
   "source": [
    "import pycuda.driver as cuda\n",
    "import pycuda.autoinit  # Автоматически инициализирует GPU\n",
    "\n",
    "# Проверка количества устройств\n",
    "print(f\"Доступно GPU: {cuda.Device.count()}\")\n",
    "\n",
    "# Информация о GPU\n",
    "gpu = cuda.Device(0)\n",
    "print(f\"Название GPU: {gpu.name()}\")\n",
    "print(f\"Вычислительная способность: {gpu.compute_capability()}\")\n",
    "print(f\"Общая память: {gpu.total_memory() / 1024**2:.2f} МБ\")\n",
    "\n",
    "# Проверка контекста (должен быть создан pycuda.autoinit)\n",
    "ctx = cuda.Context.get_current()\n",
    "print(f\"Контекст GPU активен: {ctx is not None}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0974c844",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 1/181 [00:02<07:17,  2.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "folder=GOT-10k_Val_000001, fps=25, sr=1.0, ao=0.9323487151739501, prec=0.9833333333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 2/181 [00:05<08:47,  2.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "folder=GOT-10k_Val_000002, fps=30, sr=1.0, ao=0.9596770902568278, prec=1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 3/181 [00:08<08:49,  2.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "folder=GOT-10k_Val_000003, fps=27, sr=1.0, ao=0.882060541757058, prec=0.9375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 4/181 [00:11<08:56,  3.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "folder=GOT-10k_Val_000004, fps=29, sr=1.0, ao=0.8717624446144678, prec=1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 5/181 [00:14<08:56,  3.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "folder=GOT-10k_Val_000005, fps=26, sr=1.0, ao=0.9595124457070126, prec=0.9875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 6/181 [00:17<08:41,  2.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "folder=GOT-10k_Val_000006, fps=28, sr=1.0, ao=0.9230803879430519, prec=0.9875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 7/181 [00:21<09:00,  3.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "folder=GOT-10k_Val_000007, fps=30, sr=1.0, ao=0.9015816415021254, prec=0.94\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 8/181 [00:25<09:48,  3.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "folder=GOT-10k_Val_000008, fps=22, sr=0.8, ao=0.7757633377247889, prec=0.7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▍         | 9/181 [00:29<10:22,  3.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "folder=GOT-10k_Val_000009, fps=25, sr=1.0, ao=0.8882205132210415, prec=0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 10/181 [00:32<10:13,  3.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "folder=GOT-10k_Val_000010, fps=28, sr=1.0, ao=0.9342034624855087, prec=0.8585858585858586\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 11/181 [00:36<10:12,  3.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "folder=GOT-10k_Val_000011, fps=28, sr=0.39, ao=0.35482440032932283, prec=0.12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 12/181 [00:38<09:12,  3.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "folder=GOT-10k_Val_000012, fps=28, sr=1.0, ao=0.8809061988393755, prec=0.4142857142857143\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 13/181 [00:42<09:05,  3.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "folder=GOT-10k_Val_000013, fps=31, sr=1.0, ao=0.8437316539491472, prec=0.94\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 14/181 [00:45<09:05,  3.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "folder=GOT-10k_Val_000014, fps=30, sr=0.85, ao=0.755231576242133, prec=0.85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 15/181 [00:49<09:35,  3.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "folder=GOT-10k_Val_000015, fps=31, sr=1.0, ao=0.9436609266094939, prec=1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 16/181 [00:52<09:27,  3.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "folder=GOT-10k_Val_000016, fps=30, sr=0.93, ao=0.7697472543599921, prec=0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 17/181 [00:56<09:27,  3.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "folder=GOT-10k_Val_000017, fps=29, sr=0.75, ao=0.7461621606857217, prec=0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|▉         | 18/181 [00:59<09:35,  3.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "folder=GOT-10k_Val_000018, fps=27, sr=1.0, ao=0.9200885873635657, prec=1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 19/181 [01:03<09:35,  3.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "folder=GOT-10k_Val_000019, fps=28, sr=1.0, ao=0.8859959762918286, prec=0.77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 20/181 [01:06<09:16,  3.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "folder=GOT-10k_Val_000020, fps=30, sr=0.23469387755102042, ao=0.19962718964284132, prec=0.3163265306122449\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 21/181 [01:10<09:16,  3.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "folder=GOT-10k_Val_000021, fps=31, sr=0.8363636363636363, ao=0.6952650345638729, prec=0.8909090909090909\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 22/181 [01:13<09:03,  3.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "folder=GOT-10k_Val_000022, fps=31, sr=1.0, ao=0.8950336992547417, prec=1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 23/181 [01:16<08:18,  3.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "folder=GOT-10k_Val_000023, fps=32, sr=0.9875, ao=0.8468473623121439, prec=1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 24/181 [01:19<08:43,  3.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "folder=GOT-10k_Val_000024, fps=27, sr=0.97, ao=0.8238922399171109, prec=0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 25/181 [01:23<08:47,  3.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "folder=GOT-10k_Val_000025, fps=32, sr=0.9454545454545454, ao=0.824278973247767, prec=0.9727272727272728\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 26/181 [01:26<08:35,  3.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "folder=GOT-10k_Val_000026, fps=31, sr=1.0, ao=0.8460881832556807, prec=0.98989898989899\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▍        | 27/181 [01:30<09:05,  3.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "folder=GOT-10k_Val_000027, fps=25, sr=0.99, ao=0.7766242839756085, prec=0.14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 28/181 [01:35<10:05,  3.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "folder=GOT-10k_Val_000028, fps=30, sr=0.9866666666666667, ao=0.8862469008844812, prec=0.7866666666666666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 29/181 [01:39<10:11,  4.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "folder=GOT-10k_Val_000029, fps=29, sr=1.0, ao=0.9346526058103307, prec=0.9916666666666667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 30/181 [01:43<09:57,  3.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "folder=GOT-10k_Val_000030, fps=29, sr=0.990909090909091, ao=0.9001926808176087, prec=0.9090909090909091\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 31/181 [01:46<09:21,  3.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "folder=GOT-10k_Val_000031, fps=31, sr=1.0, ao=0.9192734022952933, prec=1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 32/181 [01:50<09:00,  3.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "folder=GOT-10k_Val_000032, fps=30, sr=1.0, ao=0.9467616688510233, prec=1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 33/181 [01:53<08:50,  3.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "folder=GOT-10k_Val_000033, fps=29, sr=0.86, ao=0.6399840247888501, prec=0.84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 34/181 [01:56<08:10,  3.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "folder=GOT-10k_Val_000034, fps=29, sr=0.7125, ao=0.5644741304889758, prec=0.7125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 35/181 [01:58<07:30,  3.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "folder=GOT-10k_Val_000035, fps=28, sr=0.9571428571428572, ao=0.8177980925159639, prec=0.9428571428571428\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|█▉        | 36/181 [02:01<07:20,  3.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "folder=GOT-10k_Val_000036, fps=24, sr=0.9714285714285714, ao=0.8435996000475805, prec=0.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 37/181 [02:04<07:01,  2.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "folder=GOT-10k_Val_000037, fps=30, sr=1.0, ao=0.8989586043889091, prec=0.9625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 38/181 [02:06<06:35,  2.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "folder=GOT-10k_Val_000038, fps=29, sr=1.0, ao=0.9456730242354242, prec=1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 39/181 [02:09<06:46,  2.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "folder=GOT-10k_Val_000039, fps=29, sr=1.0, ao=0.8418069127036408, prec=0.5666666666666667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 40/181 [02:12<06:19,  2.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "folder=GOT-10k_Val_000040, fps=31, sr=1.0, ao=0.7843393133479968, prec=1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 41/181 [02:16<07:30,  3.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "folder=GOT-10k_Val_000041, fps=23, sr=1.0, ao=0.7655369752469393, prec=0.15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 42/181 [02:20<07:33,  3.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "folder=GOT-10k_Val_000042, fps=30, sr=0.98, ao=0.8671214393284318, prec=0.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 43/181 [02:23<07:39,  3.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "folder=GOT-10k_Val_000043, fps=29, sr=1.0, ao=0.9124292357636254, prec=0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 44/181 [02:26<07:26,  3.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "folder=GOT-10k_Val_000044, fps=29, sr=0.9888888888888889, ao=0.8266295134667259, prec=0.5333333333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▍       | 45/181 [02:30<07:29,  3.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "folder=GOT-10k_Val_000045, fps=29, sr=1.0, ao=0.948578834060385, prec=0.99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 46/181 [02:34<07:55,  3.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "folder=GOT-10k_Val_000046, fps=25, sr=0.55, ao=0.47751840284424574, prec=0.06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 47/181 [02:36<07:07,  3.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "folder=GOT-10k_Val_000047, fps=29, sr=1.0, ao=0.945886285517559, prec=0.9571428571428572\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 48/181 [02:39<06:47,  3.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "folder=GOT-10k_Val_000048, fps=29, sr=0.975, ao=0.7369546272640982, prec=0.35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 49/181 [02:42<06:38,  3.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "folder=GOT-10k_Val_000049, fps=28, sr=0.7375, ao=0.6688694621573424, prec=0.575\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 50/181 [02:45<06:31,  2.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "folder=GOT-10k_Val_000050, fps=28, sr=1.0, ao=0.872449902599893, prec=1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 51/181 [02:48<06:36,  3.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "folder=GOT-10k_Val_000051, fps=29, sr=1.0, ao=0.9445331373331004, prec=0.978021978021978\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▊       | 52/181 [02:51<06:54,  3.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "folder=GOT-10k_Val_000052, fps=28, sr=0.9900990099009901, ao=0.909963076615359, prec=0.7326732673267327\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 53/181 [02:55<06:56,  3.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "folder=GOT-10k_Val_000053, fps=30, sr=0.6336633663366337, ao=0.5801509012669407, prec=0.5247524752475248\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|██▉       | 54/181 [02:59<07:35,  3.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "folder=GOT-10k_Val_000054, fps=28, sr=1.0, ao=0.8877315938185781, prec=0.7666666666666667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 55/181 [03:02<06:52,  3.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "folder=GOT-10k_Val_000055, fps=28, sr=0.9859154929577465, ao=0.7331119681939795, prec=0.9014084507042254\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 56/181 [03:04<06:21,  3.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "folder=GOT-10k_Val_000056, fps=25, sr=0.06349206349206349, ao=0.06737182711845058, prec=0.06349206349206349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███▏      | 57/181 [03:06<05:47,  2.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "folder=GOT-10k_Val_000057, fps=29, sr=0.6875, ao=0.6022690010350199, prec=0.671875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 58/181 [03:09<05:49,  2.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "folder=GOT-10k_Val_000058, fps=24, sr=1.0, ao=0.8695210128711466, prec=0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 59/181 [03:13<06:07,  3.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "folder=GOT-10k_Val_000059, fps=28, sr=0.75, ao=0.674161000257452, prec=0.5416666666666666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 60/181 [03:17<06:47,  3.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "folder=GOT-10k_Val_000060, fps=26, sr=0.9818181818181818, ao=0.6580303547365455, prec=0.07272727272727272\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▎      | 61/181 [03:21<07:00,  3.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "folder=GOT-10k_Val_000061, fps=27, sr=1.0, ao=0.9126726750621655, prec=1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 62/181 [03:24<06:52,  3.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "folder=GOT-10k_Val_000062, fps=30, sr=1.0, ao=0.8547691644829198, prec=0.9405940594059405\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▍      | 63/181 [03:28<06:57,  3.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "folder=GOT-10k_Val_000063, fps=22, sr=0.9876543209876543, ao=0.7651169861574866, prec=0.20987654320987653\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 64/181 [03:30<06:22,  3.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "folder=GOT-10k_Val_000064, fps=31, sr=0.9876543209876543, ao=0.8921753336870187, prec=0.9876543209876543\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 65/181 [03:35<07:14,  3.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "folder=GOT-10k_Val_000065, fps=21, sr=1.0, ao=0.7995355209613579, prec=0.3069306930693069\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▋      | 66/181 [03:39<07:24,  3.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "folder=GOT-10k_Val_000066, fps=24, sr=1.0, ao=0.8941896855300565, prec=0.9900990099009901\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 67/181 [03:43<06:52,  3.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "folder=GOT-10k_Val_000067, fps=23, sr=1.0, ao=0.8071428349855191, prec=0.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 68/181 [03:47<07:10,  3.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "folder=GOT-10k_Val_000068, fps=24, sr=1.0, ao=0.9410661772184987, prec=1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 69/181 [03:50<07:01,  3.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "folder=GOT-10k_Val_000069, fps=28, sr=1.0, ao=0.9447293973879745, prec=0.9900990099009901\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▊      | 70/181 [03:54<06:47,  3.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "folder=GOT-10k_Val_000070, fps=26, sr=0.9888888888888889, ao=0.9180357778207916, prec=0.9444444444444444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▉      | 71/181 [03:57<06:18,  3.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "folder=GOT-10k_Val_000071, fps=28, sr=0.8395061728395061, ao=0.7698745700793341, prec=0.8148148148148148\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|███▉      | 72/181 [04:00<06:09,  3.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "folder=GOT-10k_Val_000072, fps=25, sr=0.3950617283950617, ao=0.34505898566609783, prec=0.08641975308641975\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 73/181 [04:03<06:00,  3.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "folder=GOT-10k_Val_000073, fps=28, sr=1.0, ao=0.9135990305680336, prec=0.978021978021978\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████      | 74/181 [04:07<05:54,  3.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "folder=GOT-10k_Val_000074, fps=28, sr=0.8021978021978022, ao=0.699171921510231, prec=0.5384615384615384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████▏     | 75/181 [04:10<06:05,  3.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "folder=GOT-10k_Val_000075, fps=27, sr=1.0, ao=0.856855706738017, prec=0.9306930693069307\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 76/181 [04:13<05:51,  3.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "folder=GOT-10k_Val_000076, fps=29, sr=1.0, ao=0.9195974000946054, prec=1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 77/181 [04:17<05:50,  3.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "folder=GOT-10k_Val_000077, fps=29, sr=0.79, ao=0.7186444460655197, prec=0.51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 78/181 [04:20<05:54,  3.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "folder=GOT-10k_Val_000078, fps=31, sr=0.6636363636363637, ao=0.5305665770592304, prec=0.6363636363636364\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▎     | 79/181 [04:24<05:55,  3.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "folder=GOT-10k_Val_000079, fps=28, sr=1.0, ao=0.8951418899904773, prec=0.98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 80/181 [04:28<05:54,  3.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "folder=GOT-10k_Val_000080, fps=28, sr=0.88, ao=0.7804387672284109, prec=0.7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▍     | 81/181 [04:32<06:28,  3.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "folder=GOT-10k_Val_000081, fps=23, sr=1.0, ao=0.9109881291300749, prec=0.5727272727272728\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 82/181 [04:35<06:00,  3.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "folder=GOT-10k_Val_000082, fps=29, sr=0.9111111111111111, ao=0.7386948792100327, prec=0.8888888888888888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 83/181 [04:39<05:52,  3.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "folder=GOT-10k_Val_000083, fps=29, sr=0.99, ao=0.8944249511556691, prec=0.97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▋     | 84/181 [04:42<05:32,  3.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "folder=GOT-10k_Val_000084, fps=30, sr=1.0, ao=0.9287303846308286, prec=0.9888888888888889\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 85/181 [04:45<05:31,  3.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "folder=GOT-10k_Val_000085, fps=29, sr=1.0, ao=0.9500541786008319, prec=1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 86/181 [04:49<05:18,  3.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "folder=GOT-10k_Val_000086, fps=29, sr=1.0, ao=0.9538842452003747, prec=0.9887640449438202\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 87/181 [04:53<05:34,  3.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "folder=GOT-10k_Val_000087, fps=25, sr=1.0, ao=0.9125023043362581, prec=0.48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▊     | 88/181 [04:56<05:21,  3.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "folder=GOT-10k_Val_000088, fps=31, sr=1.0, ao=0.9107184954135564, prec=1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▉     | 89/181 [05:00<05:30,  3.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "folder=GOT-10k_Val_000089, fps=29, sr=1.0, ao=0.8537830092901677, prec=0.6936936936936937\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|████▉     | 90/181 [05:03<05:19,  3.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "folder=GOT-10k_Val_000090, fps=30, sr=1.0, ao=0.9594607434005564, prec=1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 91/181 [05:06<04:58,  3.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "folder=GOT-10k_Val_000091, fps=28, sr=0.9135802469135802, ao=0.8535474356199232, prec=0.654320987654321\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████     | 92/181 [05:09<05:00,  3.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "folder=GOT-10k_Val_000092, fps=29, sr=0.9801980198019802, ao=0.8868805861057115, prec=0.9108910891089109\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████▏    | 93/181 [05:13<04:51,  3.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "folder=GOT-10k_Val_000093, fps=26, sr=1.0, ao=0.928414637930675, prec=0.7654320987654321\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 94/181 [05:16<05:03,  3.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "folder=GOT-10k_Val_000094, fps=24, sr=1.0, ao=0.9125701425322861, prec=0.6263736263736264\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 95/181 [05:19<04:40,  3.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "folder=GOT-10k_Val_000095, fps=29, sr=1.0, ao=0.9489923786841956, prec=1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 96/181 [05:22<04:16,  3.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "folder=GOT-10k_Val_000096, fps=29, sr=1.0, ao=0.8235053731235448, prec=0.7605633802816901\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▎    | 97/181 [05:24<03:57,  2.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "folder=GOT-10k_Val_000097, fps=29, sr=1.0, ao=0.9596388334991277, prec=1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 98/181 [05:28<04:13,  3.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "folder=GOT-10k_Val_000098, fps=29, sr=1.0, ao=0.9324949212385627, prec=0.9702970297029703\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▍    | 99/181 [05:31<04:23,  3.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "folder=GOT-10k_Val_000099, fps=28, sr=0.3, ao=0.3919381675085076, prec=0.13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 100/181 [05:36<04:55,  3.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "folder=GOT-10k_Val_000100, fps=22, sr=0.9504950495049505, ao=0.8566861240333594, prec=0.5247524752475248\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 101/181 [05:41<05:19,  3.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "folder=GOT-10k_Val_000101, fps=25, sr=1.0, ao=0.9464594851773616, prec=1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▋    | 102/181 [05:44<05:06,  3.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "folder=GOT-10k_Val_000102, fps=28, sr=1.0, ao=0.9056987575793898, prec=0.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 103/181 [05:59<09:15,  7.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "folder=GOT-10k_Val_000103, fps=27, sr=0.9948717948717949, ao=0.8687277643621862, prec=0.9948717948717949\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 104/181 [06:03<07:57,  6.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "folder=GOT-10k_Val_000104, fps=27, sr=0.9727272727272728, ao=0.8707433587687562, prec=0.9727272727272728\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 105/181 [06:06<06:45,  5.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "folder=GOT-10k_Val_000105, fps=24, sr=1.0, ao=0.9688425275739455, prec=1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▊    | 106/181 [06:15<07:44,  6.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "folder=GOT-10k_Val_000106, fps=20, sr=1.0, ao=0.9662045133725509, prec=0.9627329192546584\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▉    | 107/181 [06:17<06:25,  5.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "folder=GOT-10k_Val_000107, fps=31, sr=1.0, ao=0.9106085616471049, prec=1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|█████▉    | 108/181 [06:24<06:50,  5.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "folder=GOT-10k_Val_000108, fps=31, sr=1.0, ao=0.9153556879291794, prec=0.9900497512437811\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 109/181 [06:28<06:00,  5.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "folder=GOT-10k_Val_000109, fps=23, sr=1.0, ao=0.943691259363536, prec=0.7037037037037037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████    | 110/181 [06:47<11:05,  9.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "folder=GOT-10k_Val_000110, fps=24, sr=0.9978768577494692, ao=0.9464508750638639, prec=0.8704883227176221\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████▏   | 111/181 [06:50<08:39,  7.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "folder=GOT-10k_Val_000111, fps=28, sr=1.0, ao=0.9004764157645436, prec=0.9382716049382716\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 112/181 [06:56<08:05,  7.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "folder=GOT-10k_Val_000112, fps=21, sr=1.0, ao=0.9234116775349309, prec=0.8015267175572519\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 113/181 [07:01<07:14,  6.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "folder=GOT-10k_Val_000113, fps=27, sr=1.0, ao=0.8995355905093633, prec=1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 114/181 [07:09<07:45,  6.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "folder=GOT-10k_Val_000114, fps=22, sr=1.0, ao=0.9479490888507582, prec=0.6298342541436464\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▎   | 115/181 [07:12<06:17,  5.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "folder=GOT-10k_Val_000115, fps=28, sr=1.0, ao=0.9524189746658023, prec=0.9876543209876543\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 116/181 [07:24<08:02,  7.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "folder=GOT-10k_Val_000116, fps=26, sr=1.0, ao=0.9568081700351124, prec=0.98989898989899\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▍   | 117/181 [07:27<06:37,  6.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "folder=GOT-10k_Val_000117, fps=30, sr=1.0, ao=0.9243582979833755, prec=1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 118/181 [07:34<06:42,  6.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "folder=GOT-10k_Val_000118, fps=30, sr=1.0, ao=0.8608216781572526, prec=0.8706467661691543\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 119/181 [07:42<07:19,  7.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "folder=GOT-10k_Val_000119, fps=29, sr=1.0, ao=0.9376271901193644, prec=1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▋   | 120/181 [07:45<05:48,  5.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "folder=GOT-10k_Val_000120, fps=28, sr=1.0, ao=0.9448486762712024, prec=1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 121/181 [07:51<05:41,  5.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "folder=GOT-10k_Val_000121, fps=23, sr=1.0, ao=0.9290362743695939, prec=0.7175572519083969\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 122/181 [08:10<09:30,  9.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "folder=GOT-10k_Val_000122, fps=22, sr=1.0, ao=0.9138243156061474, prec=0.6324582338902148\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 123/181 [08:15<08:04,  8.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "folder=GOT-10k_Val_000123, fps=26, sr=1.0, ao=0.9414814482221848, prec=0.8928571428571429\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▊   | 124/181 [08:21<07:23,  7.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "folder=GOT-10k_Val_000124, fps=28, sr=1.0, ao=0.9532906929562674, prec=0.988950276243094\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▉   | 125/181 [08:35<09:02,  9.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "folder=GOT-10k_Val_000125, fps=30, sr=1.0, ao=0.9294205670598434, prec=0.988399071925754\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|██████▉   | 126/181 [08:39<07:11,  7.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "folder=GOT-10k_Val_000126, fps=29, sr=0.7623762376237624, ao=0.6789413321400289, prec=0.5445544554455446\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 127/181 [08:43<06:08,  6.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "folder=GOT-10k_Val_000127, fps=23, sr=1.0, ao=0.9135872450707697, prec=0.594059405940594\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████   | 128/181 [08:47<05:08,  5.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "folder=GOT-10k_Val_000128, fps=29, sr=1.0, ao=0.917815264990154, prec=1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████▏  | 129/181 [08:50<04:26,  5.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "folder=GOT-10k_Val_000129, fps=29, sr=1.0, ao=0.8015649122339163, prec=0.7623762376237624\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 130/181 [08:54<03:52,  4.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "folder=GOT-10k_Val_000130, fps=28, sr=0.34065934065934067, ao=0.3026745747566681, prec=0.34065934065934067\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 131/181 [08:56<03:20,  4.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "folder=GOT-10k_Val_000131, fps=30, sr=0.8641975308641975, ao=0.6868356450381399, prec=0.2716049382716049\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 132/181 [08:59<03:02,  3.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "folder=GOT-10k_Val_000132, fps=30, sr=0.8241758241758241, ao=0.6845955290255283, prec=0.34065934065934067\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 133/181 [09:03<02:53,  3.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "folder=GOT-10k_Val_000133, fps=30, sr=1.0, ao=0.8255390972692399, prec=1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 134/181 [09:06<02:44,  3.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "folder=GOT-10k_Val_000134, fps=31, sr=0.97, ao=0.8025014295485707, prec=0.77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▍  | 135/181 [09:09<02:32,  3.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "folder=GOT-10k_Val_000135, fps=32, sr=1.0, ao=0.7041001722332365, prec=1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 136/181 [09:13<02:44,  3.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "folder=GOT-10k_Val_000136, fps=27, sr=1.0, ao=0.9634241249068812, prec=1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 137/181 [09:23<04:01,  5.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "folder=GOT-10k_Val_000137, fps=31, sr=0.717607973421927, ao=0.6504342388970162, prec=0.7242524916943521\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 138/181 [09:26<03:26,  4.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "folder=GOT-10k_Val_000138, fps=28, sr=0.989010989010989, ao=0.783070790829845, prec=1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 139/181 [09:31<03:20,  4.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "folder=GOT-10k_Val_000139, fps=22, sr=1.0, ao=0.9391507407561956, prec=0.9603960396039604\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 140/181 [09:35<03:06,  4.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "folder=GOT-10k_Val_000140, fps=25, sr=0.9405940594059405, ao=0.8758063727709664, prec=0.6732673267326733\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 141/181 [09:39<02:59,  4.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "folder=GOT-10k_Val_000141, fps=28, sr=1.0, ao=0.9010676832751345, prec=1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 142/181 [09:43<02:46,  4.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "folder=GOT-10k_Val_000142, fps=24, sr=1.0, ao=0.9011020611030696, prec=0.6043956043956044\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████▉  | 143/181 [09:47<02:33,  4.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "folder=GOT-10k_Val_000143, fps=23, sr=1.0, ao=0.9349092113800412, prec=0.9135802469135802\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|███████▉  | 144/181 [09:50<02:19,  3.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "folder=GOT-10k_Val_000144, fps=26, sr=1.0, ao=0.9009049980680874, prec=1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 145/181 [09:53<02:13,  3.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "folder=GOT-10k_Val_000145, fps=29, sr=1.0, ao=0.937554023516368, prec=0.9801980198019802\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████  | 146/181 [09:56<02:03,  3.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "folder=GOT-10k_Val_000146, fps=26, sr=1.0, ao=0.9245958693738423, prec=0.9506172839506173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████  | 147/181 [10:00<01:56,  3.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "folder=GOT-10k_Val_000147, fps=26, sr=1.0, ao=0.9521613123872548, prec=1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 148/181 [10:03<01:48,  3.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "folder=GOT-10k_Val_000148, fps=27, sr=1.0, ao=0.9189385818105497, prec=1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 149/181 [10:05<01:41,  3.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "folder=GOT-10k_Val_000149, fps=28, sr=1.0, ao=0.9338821582645466, prec=1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 150/181 [10:08<01:34,  3.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "folder=GOT-10k_Val_000150, fps=29, sr=1.0, ao=0.9046184160447066, prec=1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 151/181 [10:11<01:26,  2.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "folder=GOT-10k_Val_000151, fps=25, sr=1.0, ao=0.8179512122507026, prec=0.6333333333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 152/181 [10:13<01:19,  2.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "folder=GOT-10k_Val_000152, fps=31, sr=0.6351351351351351, ao=0.5759517717706718, prec=0.1891891891891892\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▍ | 153/181 [10:17<01:24,  3.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "folder=GOT-10k_Val_000153, fps=22, sr=1.0, ao=0.8577044708113237, prec=0.32098765432098764\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 154/181 [10:20<01:23,  3.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "folder=GOT-10k_Val_000154, fps=25, sr=1.0, ao=0.893402561442975, prec=0.7283950617283951\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 155/181 [10:23<01:20,  3.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "folder=GOT-10k_Val_000155, fps=29, sr=0.9888888888888889, ao=0.8575828719766612, prec=0.8666666666666667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 156/181 [10:33<02:07,  5.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "folder=GOT-10k_Val_000156, fps=29, sr=1.0, ao=0.879273040272005, prec=0.398576512455516\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 157/181 [10:36<01:46,  4.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "folder=GOT-10k_Val_000157, fps=28, sr=0.8518518518518519, ao=0.7094130214870317, prec=0.2345679012345679\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 158/181 [10:39<01:31,  3.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "folder=GOT-10k_Val_000158, fps=28, sr=1.0, ao=0.9111433232331251, prec=1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 159/181 [10:42<01:22,  3.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "folder=GOT-10k_Val_000159, fps=24, sr=1.0, ao=0.9280064869639524, prec=0.975\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 160/181 [10:47<01:26,  4.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "folder=GOT-10k_Val_000160, fps=16, sr=1.0, ao=0.8845694159068036, prec=0.5185185185185185\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▉ | 161/181 [10:50<01:15,  3.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "folder=GOT-10k_Val_000161, fps=28, sr=0.6, ao=0.5944112526568824, prec=0.5625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|████████▉ | 162/181 [10:54<01:11,  3.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "folder=GOT-10k_Val_000162, fps=22, sr=0.9876543209876543, ao=0.8465893320346484, prec=0.4444444444444444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 163/181 [10:58<01:08,  3.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "folder=GOT-10k_Val_000163, fps=23, sr=0.9888888888888889, ao=0.8611360533758261, prec=0.4777777777777778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████ | 164/181 [11:00<00:58,  3.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "folder=GOT-10k_Val_000164, fps=30, sr=0.9466666666666667, ao=0.7914514939755096, prec=0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████ | 165/181 [11:04<00:57,  3.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "folder=GOT-10k_Val_000165, fps=25, sr=1.0, ao=0.8524495647244384, prec=0.4752475247524752\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 166/181 [11:08<00:53,  3.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "folder=GOT-10k_Val_000166, fps=29, sr=1.0, ao=0.9690383126361481, prec=1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 167/181 [11:11<00:48,  3.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "folder=GOT-10k_Val_000167, fps=31, sr=0.9702970297029703, ao=0.9089302331216526, prec=0.9702970297029703\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 168/181 [11:14<00:45,  3.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "folder=GOT-10k_Val_000168, fps=27, sr=0.7802197802197802, ao=0.7455381943274045, prec=0.7802197802197802\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 169/181 [11:18<00:40,  3.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "folder=GOT-10k_Val_000169, fps=28, sr=0.989010989010989, ao=0.8527493477219955, prec=0.8351648351648352\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 170/181 [11:21<00:36,  3.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "folder=GOT-10k_Val_000170, fps=30, sr=0.9120879120879121, ao=0.7927278019023424, prec=0.7692307692307693\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 171/181 [11:24<00:32,  3.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "folder=GOT-10k_Val_000171, fps=30, sr=1.0, ao=0.9224004066680507, prec=1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 172/181 [11:31<00:40,  4.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "folder=GOT-10k_Val_000172, fps=28, sr=0.8720379146919431, ao=0.8190406512310247, prec=0.7156398104265402\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 173/181 [11:46<01:01,  7.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "folder=GOT-10k_Val_000173, fps=27, sr=1.0, ao=0.9646558923863321, prec=1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 174/181 [12:02<01:10, 10.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "folder=GOT-10k_Val_000174, fps=25, sr=0.9974424552429667, ao=0.8329045193968047, prec=0.4475703324808184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 175/181 [12:12<00:59,  9.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "folder=GOT-10k_Val_000175, fps=29, sr=0.8708487084870848, ao=0.6718544084832495, prec=0.922509225092251\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 176/181 [12:22<00:50, 10.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "folder=GOT-10k_Val_000176, fps=28, sr=0.8694158075601375, ao=0.790426287909883, prec=0.7972508591065293\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 177/181 [12:32<00:40, 10.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "folder=GOT-10k_Val_000177, fps=18, sr=0.3146067415730337, ao=0.2510312007520833, prec=0.11235955056179775\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 178/181 [12:59<00:45, 15.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "folder=GOT-10k_Val_000178, fps=10, sr=0.9808429118773946, ao=0.890209941725745, prec=0.1724137931034483\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 179/181 [13:14<00:29, 14.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "folder=GOT-10k_Val_000179, fps=29, sr=0.9572446555819477, ao=0.8747144112120678, prec=0.833729216152019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 180/181 [13:21<00:04,  4.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "folder=GOT-10k_Val_000180, fps=14, sr=0.7777777777777778, ao=0.7068247066897859, prec=0.21296296296296297\n",
      "******************** Завершено! ********************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Path</th>\n",
       "      <th>FPS</th>\n",
       "      <th>Success Rate (SR@0.5)</th>\n",
       "      <th>Average Overlap (AO)</th>\n",
       "      <th>Precision @20px</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GOT-10k_Val_000001</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.932349</td>\n",
       "      <td>0.983333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GOT-10k_Val_000002</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.959677</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GOT-10k_Val_000003</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.882061</td>\n",
       "      <td>0.937500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GOT-10k_Val_000004</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.871762</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GOT-10k_Val_000005</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.959512</td>\n",
       "      <td>0.987500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>GOT-10k_Val_000177</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>0.314607</td>\n",
       "      <td>0.251031</td>\n",
       "      <td>0.112360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>GOT-10k_Val_000178</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.980843</td>\n",
       "      <td>0.890210</td>\n",
       "      <td>0.172414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>GOT-10k_Val_000179</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>0.957245</td>\n",
       "      <td>0.874714</td>\n",
       "      <td>0.833729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>GOT-10k_Val_000180</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.706825</td>\n",
       "      <td>0.212963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>Average</td>\n",
       "      <td>27.294444</td>\n",
       "      <td>0.930731</td>\n",
       "      <td>0.831817</td>\n",
       "      <td>0.762651</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>181 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Path        FPS  Success Rate (SR@0.5)  \\\n",
       "0    GOT-10k_Val_000001  25.000000               1.000000   \n",
       "1    GOT-10k_Val_000002  30.000000               1.000000   \n",
       "2    GOT-10k_Val_000003  27.000000               1.000000   \n",
       "3    GOT-10k_Val_000004  29.000000               1.000000   \n",
       "4    GOT-10k_Val_000005  26.000000               1.000000   \n",
       "..                  ...        ...                    ...   \n",
       "176  GOT-10k_Val_000177  18.000000               0.314607   \n",
       "177  GOT-10k_Val_000178  10.000000               0.980843   \n",
       "178  GOT-10k_Val_000179  29.000000               0.957245   \n",
       "179  GOT-10k_Val_000180  14.000000               0.777778   \n",
       "180             Average  27.294444               0.930731   \n",
       "\n",
       "     Average Overlap (AO)  Precision @20px  \n",
       "0                0.932349         0.983333  \n",
       "1                0.959677         1.000000  \n",
       "2                0.882061         0.937500  \n",
       "3                0.871762         1.000000  \n",
       "4                0.959512         0.987500  \n",
       "..                    ...              ...  \n",
       "176              0.251031         0.112360  \n",
       "177              0.890210         0.172414  \n",
       "178              0.874714         0.833729  \n",
       "179              0.706825         0.212963  \n",
       "180              0.831817         0.762651  \n",
       "\n",
       "[181 rows x 5 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Проход по всему got10k\n",
    "import glob\n",
    "import time\n",
    "import  os\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "metrics = pd.DataFrame(columns=['Path', 'FPS', 'Success Rate (SR@0.5)', \"Average Overlap (AO)\", \"Precision @20px\"])\n",
    "base_dir = \"val/\"\n",
    "folders = os.listdir(f'{base_dir}')\n",
    "counter_test = 0\n",
    "for folder in tqdm(folders):\n",
    "    if folder == \"list.txt\":\n",
    "        print(f\"{'*' * 20} Завершено! {'*' * 20}\")\n",
    "        break\n",
    "    gt_bboxes = []\n",
    "    pred_bboxes = []\n",
    "    seq_path = os.path.join(base_dir, folder)\n",
    "    txt_files = glob.glob(os.path.join(seq_path, '*.txt'))\n",
    "    if not txt_files:\n",
    "        raise FileNotFoundError(f\"No .txt files found in {seq_path}\")\n",
    "\n",
    "    img_files = sorted(glob.glob(os.path.join(seq_path, '*.jpg')))\n",
    "    with open(txt_files[0], 'r') as f:\n",
    "        gt_bboxes = [list(map(float, line.strip().split(','))) for line in f]\n",
    "\n",
    "    # Получаем размер первого изображения\n",
    "    sample_img = cv2.imread(img_files[0])\n",
    "    if sample_img is None:\n",
    "        raise ValueError(f\"Failed to read sample image: {img_files[0]}\")  \n",
    "\n",
    "    assert len(img_files) == len(gt_bboxes), \"Количество кадров и bbox'ов не совпадает\"\n",
    "\n",
    "    x, y, w, h = map(int, gt_bboxes[0])\n",
    "    init_state = [x, y, w, h]\n",
    "\n",
    "    def _build_init_info(box):\n",
    "                return {'init_bbox': box}\n",
    "\n",
    "    counter = 0\n",
    "    counter_test += 1\n",
    "\n",
    "\n",
    "    tracker.initialize(sample_img, _build_init_info(init_state))\n",
    "\n",
    "    start_time = time.time()  # Начало замера\n",
    "\n",
    "    for img_file, bbox in zip(img_files, gt_bboxes):\n",
    "            \n",
    "            # Читаем изображение\n",
    "            img = cv2.imread(img_file)\n",
    "            if img is None:\n",
    "                print(f\"Не удалось загрузить изображение: {img_file}\")\n",
    "                continue\n",
    "                        \n",
    "            out  = tracker.track(img)\n",
    "            state = [int(s) for s in out['target_bbox']]   \n",
    "                            \n",
    "            # Рисуем bounding box        \n",
    "            x, y, w, h = [int(x) for x in state]\n",
    "\n",
    "            cv2.rectangle(img, (x, y), (x + w, y + h), (0, 0, 200), 2)\n",
    "            \n",
    "            x1, y1, w1, h1 = map(int, bbox)\n",
    "            cv2.rectangle(img, (x1, y1), (x1+w1, y1+h1), (0, 200, 0), 2)\n",
    "            bbox_pred = x, y, w, h\n",
    "            \n",
    "            gt_bboxes.append(bbox)\n",
    "            pred_bboxes.append(bbox_pred)\n",
    "   \n",
    "            counter+=1\n",
    "\n",
    "            # Выход по нажатию 'q' или ESC\n",
    "            key = cv2.waitKey(1) & 0xFF\n",
    "            if key == ord('q') or key == 27:\n",
    "                break\n",
    "        \n",
    "            \n",
    "                    \n",
    "    end_time = time.time()    # Конец замера    \n",
    "    total_frames = counter       # Общее количество обработанных кадров\n",
    "    total_time = end_time - start_time\n",
    "    fps = round(total_frames / total_time)\n",
    "    ious = [iou(gt, pred) for gt, pred in zip(gt_bboxes, pred_bboxes)]\n",
    "    ao = np.mean(ious)\n",
    "    sr = np.mean([1 if val >= sr_thresh else 0 for val in ious])\n",
    "    precisions = [precision(gt, pred) for gt, pred in zip(gt_bboxes, pred_bboxes)]\n",
    "    prec = np.mean([1 if d <= prec_thresh else 0 for d in precisions])\n",
    "       \n",
    "    if metrics.empty:\n",
    "        metrics = pd.DataFrame(dict(zip(metrics.columns,\n",
    "        [folder, fps, sr, ao, prec])), index=[0])\n",
    "    else:\n",
    "        metrics = metrics._append(pd.Series(dict(zip(metrics.columns,\n",
    "        [folder, fps, sr, ao, prec]))), ignore_index=True)\n",
    "    print(f\"folder={folder}, fps={fps}, sr={sr}, ao={ao}, prec={prec}\")\n",
    "    # if counter_test == 5:\n",
    "    #     print(f\"{'*' * 20} Прервано на 5! {'*' * 20}\")\n",
    "    #     break\n",
    "\n",
    "metrics = metrics._append(pd.Series(dict(zip(metrics.columns,\n",
    "        [\"Average\", metrics['FPS'].mean(), metrics['Success Rate (SR@0.5)'].mean(), metrics['Average Overlap (AO)'].mean(), metrics['Precision @20px'].mean()]))), ignore_index=True)\n",
    "metrics.to_csv('metrics_base.csv', index=False)\n",
    "metrics"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "p310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
