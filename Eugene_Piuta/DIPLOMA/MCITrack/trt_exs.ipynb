{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' TRT_LOGGER = trt.Logger(trt.Logger.WARNING)\\n\\ndef load_engine(trt_runtime, engine_path):\\n    with open(engine_path, \"rb\") as f:\\n        engine_data = f.read()\\n    return trt_runtime.deserialize_cuda_engine(engine_data)\\n\\ntrt_runtime = trt.Runtime(TRT_LOGGER)\\nengine = load_engine(trt_runtime, \"MCITrack.trt\")\\nengine '"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorrt as trt\n",
    "import pycuda.driver as cuda\n",
    "import pycuda.autoinit  # автоматически инициализирует CUDA контекст\n",
    "import torch\n",
    "import cv2\n",
    "import sys\n",
    "import math\n",
    "import time\n",
    "import numpy as np\n",
    "import yaml\n",
    "import torch\n",
    "import numpy as np\n",
    "import onnx\n",
    "import onnxruntime as ort\n",
    "\n",
    "\n",
    "\"\"\" TRT_LOGGER = trt.Logger(trt.Logger.WARNING)\n",
    "\n",
    "def load_engine(trt_runtime, engine_path):\n",
    "    with open(engine_path, \"rb\") as f:\n",
    "        engine_data = f.read()\n",
    "    return trt_runtime.deserialize_cuda_engine(engine_data)\n",
    "\n",
    "trt_runtime = trt.Runtime(TRT_LOGGER)\n",
    "engine = load_engine(trt_runtime, \"MCITrack.trt\")\n",
    "engine \"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'10.9.0.34'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trt.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Входы модели:\n",
      "  template_list: [1, 3, 112, 112]\n",
      "  search_list: [1, 3, 112, 112]\n",
      "  template_anno_list: [1, 3, 112, 112]\n",
      "  onnx::Unsqueeze_3: [1, 3, 112, 112]\n",
      "  onnx::Unsqueeze_4: [1, 3, 112, 112]\n",
      "  onnx::Unsqueeze_5: [1, 3, 224, 224]\n",
      "  onnx::Unsqueeze_6: [1, 4]\n",
      "  onnx::Unsqueeze_7: [1, 4]\n",
      "  onnx::Unsqueeze_8: [1, 4]\n",
      "  onnx::Unsqueeze_9: [1, 4]\n",
      "  onnx::Unsqueeze_10: [1, 4]\n",
      "\n",
      "Выходы модели:\n",
      "  pred_boxes: [1, 1, 4]\n",
      "  score_map: [1, 1, 14, 14]\n",
      "  size_map: [1, 2, 14, 14]\n",
      "  offset_map: [1, 2, 14, 14]\n"
     ]
    }
   ],
   "source": [
    "import onnx\n",
    "\n",
    "# Загрузите модель\n",
    "model = onnx.load(\"MCITrack.onnx\")\n",
    "\n",
    "# Входы (inputs)\n",
    "print(\"Входы модели:\")\n",
    "for input in model.graph.input:\n",
    "    name = input.name\n",
    "    shape = []\n",
    "    for dim in input.type.tensor_type.shape.dim:\n",
    "        if dim.dim_param:\n",
    "            shape.append(dim.dim_param)\n",
    "        else:\n",
    "            shape.append(dim.dim_value)\n",
    "    print(f\"  {name}: {shape}\")\n",
    "\n",
    "# Выходы (outputs)\n",
    "print(\"\\nВыходы модели:\")\n",
    "for output in model.graph.output:\n",
    "    name = output.name\n",
    "    shape = []\n",
    "    for dim in output.type.tensor_type.shape.dim:\n",
    "        if dim.dim_param:\n",
    "            shape.append(dim.dim_param)\n",
    "        else:\n",
    "            shape.append(dim.dim_value)\n",
    "    print(f\"  {name}: {shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorrt as trt\n",
    "\n",
    "TRT_LOGGER = trt.Logger(trt.Logger.WARNING)\n",
    "\n",
    "# Инициализация TensorRT билдера и парсера ONNX\n",
    "with trt.Builder(TRT_LOGGER) as builder, builder.create_network(1) as network, trt.OnnxParser(network, TRT_LOGGER) as parser:\n",
    "    # Загрузка ONNX-модели и парсинг в TensorRT\n",
    "    with open(\"./MCITrack.onnx\", \"rb\") as model_file:\n",
    "        parser.parse(model_file.read())\n",
    "\n",
    "    builder_config = builder.create_builder_config()\n",
    "    #builder_config.set_memory_pool_limit(trt.MemoryPoolType.WORKSPACE, 1 << 32)\n",
    "    #builder_config.set_tactic_sources(1 << int(trt.TacticSource.CUBLAS))\n",
    "    #builder_config.set_flag(trt.BuilderFlag.FP16)\n",
    "       \n",
    "    serialized_network = builder.build_serialized_network(network, builder_config)\n",
    "    with open(\"MCITrack.trt\", \"wb\")  as f:\n",
    "        f.write(serialized_network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRT_LOGGER = trt.Logger(trt.Logger.WARNING)\n",
    "\n",
    "def load_trt_engine(engine_path: str):\n",
    "    with open(engine_path, 'rb') as file, trt.Runtime(TRT_LOGGER) as runtime:\n",
    "        engine = runtime.deserialize_cuda_engine(file.read())\n",
    "    return engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "ORT=\"MCITrack.trt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = load_trt_engine(ORT)\n",
    "context = engine.create_execution_context()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorrt.tensorrt.IExecutionContext at 0x2803bdd07f0>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_trt():\n",
    "    # Входы (пример для трех входов по 112x112 и одного по 224x224, плюс 5 входов по [1,4])\n",
    "    input_size_template_list = np.prod([1, 3, 112, 112]) * np.dtype(np.float32).itemsize\n",
    "    d_input_template_list = cuda.mem_alloc(int(input_size_template_list))\n",
    "    \n",
    "    input_size_search_list = np.prod([1, 3, 112, 112]) * np.dtype(np.float32).itemsize\n",
    "    d_input_search_list = cuda.mem_alloc(int(input_size_search_list))\n",
    "    \n",
    "    input_size_template_anno_list = np.prod([1, 3, 112, 112]) * np.dtype(np.float32).itemsize\n",
    "    d_input_template_anno_list = cuda.mem_alloc(int(input_size_template_anno_list))\n",
    "    \n",
    "    \n",
    "    input_size_unsqueeze_3 = np.prod([1, 3, 112, 112]) * np.dtype(np.float32).itemsize\n",
    "    d_input_unsqueeze_3 = cuda.mem_alloc(int(input_size_unsqueeze_3))\n",
    "    \n",
    "    \n",
    "    input_size_unsqueeze_4 = np.prod([1, 3, 112, 112]) * np.dtype(np.float32).itemsize\n",
    "    d_input_unsqueeze_4 = cuda.mem_alloc(int(input_size_unsqueeze_4))\n",
    "    \n",
    "    input_size_unsqueeze_5 = np.prod([1, 3, 224, 224]) * np.dtype(np.float32).itemsize\n",
    "    d_input_unsqueeze_5 = cuda.mem_alloc(int(input_size_unsqueeze_5))\n",
    "    \n",
    "    # Пять входов по [1,4]\n",
    "    input_size_unsqueeze_list = np.prod([1, 4]) * np.dtype(np.float32).itemsize\n",
    "    d_input_unsqueeze_6 = cuda.mem_alloc(int(input_size_unsqueeze_list))\n",
    "    d_input_unsqueeze_7 = cuda.mem_alloc(int(input_size_unsqueeze_list))\n",
    "    d_input_unsqueeze_8 = cuda.mem_alloc(int(input_size_unsqueeze_list))\n",
    "    d_input_unsqueeze_9 = cuda.mem_alloc(int(input_size_unsqueeze_list))\n",
    "    d_input_unsqueeze_10 = cuda.mem_alloc(int(input_size_unsqueeze_list))\n",
    "    \n",
    "    # Выходы\n",
    "    output_size_predboxes = np.prod([1, 1, 4]) * np.dtype(np.float32).itemsize\n",
    "    d_output_predboxes = cuda.mem_alloc(int(output_size_predboxes))\n",
    "\n",
    "    output_size_score = np.prod([1, 1, 14, 14]) * np.dtype(np.float32).itemsize\n",
    "    d_output_score = cuda.mem_alloc(int(output_size_score))\n",
    "\n",
    "    output_size_size = np.prod([1, 2, 14, 14]) * np.dtype(np.float32).itemsize\n",
    "    d_output_size = cuda.mem_alloc(int(output_size_size))\n",
    "\n",
    "    output_size_offset = np.prod([1, 2, 14, 14]) * np.dtype(np.float32).itemsize\n",
    "    d_output_offset = cuda.mem_alloc(int(output_size_offset))\n",
    "\n",
    "    # Вернуть всё в кортеже (в том порядке, как вам нужно)\n",
    "    return (\n",
    "        d_input_template_list,\n",
    "        d_input_search_list,\n",
    "        d_input_template_anno_list,\n",
    "        d_input_unsqueeze_3,\n",
    "        d_input_unsqueeze_4,\n",
    "        d_input_unsqueeze_5,\n",
    "        d_input_unsqueeze_6,\n",
    "        d_input_unsqueeze_7,\n",
    "        d_input_unsqueeze_8,\n",
    "        d_input_unsqueeze_9,\n",
    "        d_input_unsqueeze_10,\n",
    "        d_output_predboxes,\n",
    "        d_output_score,\n",
    "        d_output_size,\n",
    "        d_output_offset\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictV2_head(\n",
    "    context,\n",
    "    input_template_list,\n",
    "    input_search_list,\n",
    "    input_template_anno_list,\n",
    "    input_unsqueeze_3,\n",
    "    input_unsqueeze_4,\n",
    "    input_unsqueeze_5,\n",
    "    input_unsqueeze_6,\n",
    "    input_unsqueeze_7,\n",
    "    input_unsqueeze_8,\n",
    "    input_unsqueeze_9,\n",
    "    input_unsqueeze_10,\n",
    "    d_input_template_list,\n",
    "    d_input_search_list,\n",
    "    d_input_template_anno_list,\n",
    "    d_input_unsqueeze_3,\n",
    "    d_input_unsqueeze_4,\n",
    "    d_input_unsqueeze_5,\n",
    "    d_input_unsqueeze_6,\n",
    "    d_input_unsqueeze_7,\n",
    "    d_input_unsqueeze_8,\n",
    "    d_input_unsqueeze_9,\n",
    "    d_input_unsqueeze_10,\n",
    "    d_output_pred_boxes,\n",
    "    d_output_score_map,\n",
    "    d_output_size_map,\n",
    "    d_output_offset_map\n",
    "):\n",
    "    # Prepare all inputs\n",
    "    cuda.memcpy_htod(d_input_template_list, input_template_list.ravel())\n",
    "    cuda.memcpy_htod(d_input_search_list, input_search_list.ravel())\n",
    "    cuda.memcpy_htod(d_input_template_anno_list, input_template_anno_list.ravel())\n",
    "    cuda.memcpy_htod(d_input_unsqueeze_3, input_unsqueeze_3.ravel())\n",
    "    cuda.memcpy_htod(d_input_unsqueeze_4, input_unsqueeze_4.ravel())\n",
    "    cuda.memcpy_htod(d_input_unsqueeze_5, input_unsqueeze_5.ravel())\n",
    "    cuda.memcpy_htod(d_input_unsqueeze_6, input_unsqueeze_6.ravel())\n",
    "    cuda.memcpy_htod(d_input_unsqueeze_7, input_unsqueeze_7.ravel())\n",
    "    cuda.memcpy_htod(d_input_unsqueeze_8, input_unsqueeze_8.ravel())\n",
    "    cuda.memcpy_htod(d_input_unsqueeze_9, input_unsqueeze_9.ravel())\n",
    "    cuda.memcpy_htod(d_input_unsqueeze_10, input_unsqueeze_10.ravel())\n",
    "\n",
    "    # Execute model with all bindings in correct order\n",
    "    context.execute_v2(bindings=[\n",
    "        int(d_input_template_list),     # 0\n",
    "        int(d_input_search_list),       # 1\n",
    "        int(d_input_template_anno_list),# 2\n",
    "        int(d_input_unsqueeze_3),       # 3\n",
    "        int(d_input_unsqueeze_4),       # 4\n",
    "        int(d_input_unsqueeze_5),       # 5\n",
    "        int(d_input_unsqueeze_6),       # 6\n",
    "        int(d_input_unsqueeze_7),       # 7\n",
    "        int(d_input_unsqueeze_8),       # 8\n",
    "        int(d_input_unsqueeze_9),       # 9\n",
    "        int(d_input_unsqueeze_10),      # 10\n",
    "        int(d_output_pred_boxes),       # 11\n",
    "        int(d_output_score_map),        # 12\n",
    "        int(d_output_size_map),         # 13\n",
    "        int(d_output_offset_map)        # 14\n",
    "    ])\n",
    "\n",
    "    # Fetch output data with new shapes\n",
    "    output_pred_boxes = np.empty([1, 1, 4], dtype=np.float32)\n",
    "    cuda.memcpy_dtoh(output_pred_boxes, d_output_pred_boxes)\n",
    "\n",
    "    output_score_map = np.empty([1, 1, 14, 14], dtype=np.float32)\n",
    "    cuda.memcpy_dtoh(output_score_map, d_output_score_map)\n",
    "\n",
    "    output_size_map = np.empty([1, 2, 14, 14], dtype=np.float32)\n",
    "    cuda.memcpy_dtoh(output_size_map, d_output_size_map)\n",
    "\n",
    "    output_offset_map = np.empty([1, 2, 14, 14], dtype=np.float32)\n",
    "    cuda.memcpy_dtoh(output_offset_map, d_output_offset_map)\n",
    "\n",
    "    return output_pred_boxes, output_score_map, output_size_map, output_offset_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "data  = initialize_trt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<pycuda._driver.DeviceAllocation at 0x28048679fc0>,\n",
       " <pycuda._driver.DeviceAllocation at 0x28048f75840>,\n",
       " <pycuda._driver.DeviceAllocation at 0x28048f75a20>,\n",
       " <pycuda._driver.DeviceAllocation at 0x28048f75a80>,\n",
       " <pycuda._driver.DeviceAllocation at 0x28048f75ae0>,\n",
       " <pycuda._driver.DeviceAllocation at 0x28048f75b40>,\n",
       " <pycuda._driver.DeviceAllocation at 0x28048f75ba0>,\n",
       " <pycuda._driver.DeviceAllocation at 0x28048f757e0>,\n",
       " <pycuda._driver.DeviceAllocation at 0x28048f75c00>,\n",
       " <pycuda._driver.DeviceAllocation at 0x28048f75c60>,\n",
       " <pycuda._driver.DeviceAllocation at 0x28048f75cc0>,\n",
       " <pycuda._driver.DeviceAllocation at 0x28048f75d80>,\n",
       " <pycuda._driver.DeviceAllocation at 0x28048f75de0>,\n",
       " <pycuda._driver.DeviceAllocation at 0x28048f75ea0>,\n",
       " <pycuda._driver.DeviceAllocation at 0x28048f75f00>)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Входы с размерами [1, 3, 112, 112]\n",
    "template_list = np.random.rand(1, 3, 112, 112).astype(np.float32)\n",
    "search_list = np.random.rand(1, 3, 112, 112).astype(np.float32)\n",
    "template_anno_list = np.random.rand(1, 3, 112, 112).astype(np.float32)\n",
    "onnx_Unsqueeze_3 = np.random.rand(1, 3, 112, 112).astype(np.float32)\n",
    "onnx_Unsqueeze_4 = np.random.rand(1, 3, 112, 112).astype(np.float32)\n",
    "\n",
    "# Вход с размером [1, 3, 224, 224]\n",
    "onnx_Unsqueeze_5 = np.random.rand(1, 3, 224, 224).astype(np.float32)\n",
    "\n",
    "# Входы с размером [1, 4]\n",
    "onnx_Unsqueeze_6 = np.random.rand(1, 4).astype(np.float32)\n",
    "onnx_Unsqueeze_7 = np.random.rand(1, 4).astype(np.float32)\n",
    "onnx_Unsqueeze_8 = np.random.rand(1, 4).astype(np.float32)\n",
    "onnx_Unsqueeze_9 = np.random.rand(1, 4).astype(np.float32)\n",
    "onnx_Unsqueeze_10 = np.random.rand(1, 4).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[[0.61137617, 0.30011144, 0.61331606, 0.5224328 ]]], dtype=float32),\n",
       " array([[[[0.00200634, 0.00486906, 0.00525712, 0.00507968, 0.00560934,\n",
       "           0.00545395, 0.00511253, 0.00554725, 0.00594276, 0.00574282,\n",
       "           0.00530569, 0.00643427, 0.00829869, 0.0156656 ],\n",
       "          [0.00586623, 0.14317323, 0.1445024 , 0.14997768, 0.1711544 ,\n",
       "           0.1425818 , 0.13096015, 0.14212836, 0.16233288, 0.14584352,\n",
       "           0.134955  , 0.15879007, 0.1850622 , 0.21613029],\n",
       "          [0.00846663, 0.13219371, 0.13083975, 0.12932365, 0.14836118,\n",
       "           0.12070306, 0.11661218, 0.13038355, 0.1523124 , 0.13976036,\n",
       "           0.13045266, 0.14359589, 0.18131988, 0.2163243 ],\n",
       "          [0.007554  , 0.09691673, 0.09970979, 0.09621135, 0.10238244,\n",
       "           0.08856169, 0.08712081, 0.0983836 , 0.10861786, 0.10632068,\n",
       "           0.10184842, 0.109666  , 0.13287713, 0.15201056],\n",
       "          [0.00716   , 0.09172104, 0.09547081, 0.08911525, 0.09413879,\n",
       "           0.08257841, 0.08016594, 0.08533097, 0.08687597, 0.08791675,\n",
       "           0.08701592, 0.09517731, 0.10767998, 0.10916729],\n",
       "          [0.00756807, 0.09003738, 0.09543402, 0.08574843, 0.08908163,\n",
       "           0.07915061, 0.07543694, 0.07865293, 0.08029832, 0.08418664,\n",
       "           0.08436345, 0.09433885, 0.10362056, 0.09813991],\n",
       "          [0.00705099, 0.08243968, 0.08967133, 0.08385697, 0.0828781 ,\n",
       "           0.07466254, 0.0726347 , 0.07878992, 0.0808463 , 0.08221618,\n",
       "           0.08177949, 0.0899962 , 0.09594063, 0.08879652],\n",
       "          [0.00633992, 0.07249141, 0.07625641, 0.07388338, 0.0731147 ,\n",
       "           0.06836298, 0.06971415, 0.08079455, 0.08571634, 0.08316147,\n",
       "           0.08096271, 0.08690131, 0.09173735, 0.08594617],\n",
       "          [0.00588813, 0.06912939, 0.06971912, 0.06898843, 0.07187936,\n",
       "           0.06817013, 0.06834109, 0.07570365, 0.07932271, 0.0765902 ,\n",
       "           0.07601849, 0.08206829, 0.08808429, 0.08084907],\n",
       "          [0.00614939, 0.07803388, 0.07611864, 0.07249945, 0.07808096,\n",
       "           0.07454518, 0.07278612, 0.07531524, 0.07968888, 0.08075265,\n",
       "           0.08342006, 0.08904518, 0.09504456, 0.08792409],\n",
       "          [0.00640823, 0.1033885 , 0.09252808, 0.08222618, 0.09155361,\n",
       "           0.08875904, 0.08456693, 0.08210713, 0.08445647, 0.09101395,\n",
       "           0.09396876, 0.0979614 , 0.10530404, 0.10418057],\n",
       "          [0.00707879, 0.13013458, 0.10932676, 0.08964165, 0.09711232,\n",
       "           0.09721137, 0.09560355, 0.09551206, 0.09909761, 0.11011117,\n",
       "           0.11153898, 0.11541683, 0.12901169, 0.14415742],\n",
       "          [0.01092391, 0.14729711, 0.13443123, 0.10906203, 0.11235529,\n",
       "           0.11273313, 0.11432596, 0.11990599, 0.12758139, 0.13394754,\n",
       "           0.13019301, 0.13358381, 0.15237972, 0.18708082],\n",
       "          [0.02278993, 0.14260912, 0.13090079, 0.1082887 , 0.10667046,\n",
       "           0.106205  , 0.11245586, 0.12822768, 0.1478796 , 0.14142968,\n",
       "           0.1299385 , 0.13478824, 0.15567417, 0.18734206]]]],\n",
       "       dtype=float32),\n",
       " array([[[[0.50086206, 0.63200706, 0.5784665 , 0.5686894 , 0.56156373,\n",
       "           0.5604673 , 0.57440877, 0.5816776 , 0.5900571 , 0.59365946,\n",
       "           0.57876176, 0.5765513 , 0.5630986 , 0.5159303 ],\n",
       "          [0.58555055, 0.8020245 , 0.68616754, 0.6689855 , 0.66315144,\n",
       "           0.67908454, 0.7285462 , 0.7486441 , 0.7520842 , 0.76907194,\n",
       "           0.6956605 , 0.64993143, 0.6073556 , 0.57764935],\n",
       "          [0.5990722 , 0.770749  , 0.6477094 , 0.63885933, 0.6479011 ,\n",
       "           0.6824166 , 0.7374847 , 0.75536036, 0.7466902 , 0.7478725 ,\n",
       "           0.69338995, 0.671582  , 0.65973157, 0.61331606],\n",
       "          [0.63350093, 0.8011954 , 0.6526195 , 0.6278284 , 0.64282036,\n",
       "           0.67804736, 0.73462   , 0.74831986, 0.73042536, 0.7320872 ,\n",
       "           0.6830024 , 0.6878918 , 0.6981719 , 0.6462726 ],\n",
       "          [0.66317344, 0.8231083 , 0.648422  , 0.6131429 , 0.63158077,\n",
       "           0.6605861 , 0.7144798 , 0.7264912 , 0.70728695, 0.7133389 ,\n",
       "           0.6828417 , 0.702047  , 0.70418537, 0.666351  ],\n",
       "          [0.680209  , 0.83447146, 0.6369644 , 0.5919432 , 0.6076378 ,\n",
       "           0.6401209 , 0.688647  , 0.70062727, 0.6882928 , 0.69036126,\n",
       "           0.6730858 , 0.68493444, 0.6821494 , 0.6595387 ],\n",
       "          [0.68114   , 0.8353142 , 0.6261364 , 0.5802528 , 0.5952616 ,\n",
       "           0.629438  , 0.68277705, 0.68979657, 0.6810636 , 0.6737352 ,\n",
       "           0.668229  , 0.67981964, 0.672023  , 0.65856296],\n",
       "          [0.67642975, 0.8276144 , 0.6150742 , 0.57154804, 0.5925075 ,\n",
       "           0.6288822 , 0.6825871 , 0.68828917, 0.67672557, 0.6657468 ,\n",
       "           0.6664201 , 0.67895424, 0.67357194, 0.6678542 ],\n",
       "          [0.66815525, 0.8161578 , 0.61586016, 0.5793537 , 0.6060512 ,\n",
       "           0.6419814 , 0.69193697, 0.69409746, 0.67190695, 0.6500955 ,\n",
       "           0.6602494 , 0.6785728 , 0.6827953 , 0.67726827],\n",
       "          [0.6528682 , 0.80435854, 0.62917453, 0.6006626 , 0.62924343,\n",
       "           0.6623175 , 0.70905876, 0.70611525, 0.6737702 , 0.63552195,\n",
       "           0.6388715 , 0.6794642 , 0.69185835, 0.6779619 ],\n",
       "          [0.6344143 , 0.78952897, 0.6537601 , 0.62702006, 0.65400785,\n",
       "           0.68821764, 0.72572416, 0.7174803 , 0.67624986, 0.6289284 ,\n",
       "           0.6265128 , 0.68078184, 0.7067038 , 0.6746432 ],\n",
       "          [0.6229245 , 0.77114415, 0.67030925, 0.63836783, 0.6642288 ,\n",
       "           0.710598  , 0.7364879 , 0.7215968 , 0.67135066, 0.6328818 ,\n",
       "           0.63142943, 0.6820837 , 0.7200326 , 0.6650136 ],\n",
       "          [0.57451063, 0.7128028 , 0.64454293, 0.622189  , 0.6477273 ,\n",
       "           0.68731534, 0.6985584 , 0.6747461 , 0.62482107, 0.59183633,\n",
       "           0.5851485 , 0.6272498 , 0.66088134, 0.6041002 ],\n",
       "          [0.49302468, 0.56321573, 0.5405296 , 0.5395874 , 0.5589314 ,\n",
       "           0.5826393 , 0.59034514, 0.57542527, 0.54010105, 0.5113132 ,\n",
       "           0.49491295, 0.51032597, 0.53097504, 0.49796802]],\n",
       " \n",
       "         [[0.49860236, 0.63681483, 0.59366745, 0.6131338 , 0.6356584 ,\n",
       "           0.657443  , 0.68126   , 0.7068623 , 0.73646176, 0.77258223,\n",
       "           0.8172633 , 0.8342064 , 0.8288515 , 0.7193623 ],\n",
       "          [0.5351301 , 0.80275905, 0.6851832 , 0.6516599 , 0.6431849 ,\n",
       "           0.64511675, 0.6476652 , 0.65661055, 0.6491879 , 0.62658405,\n",
       "           0.60165   , 0.5841256 , 0.56458324, 0.49545324],\n",
       "          [0.5196152 , 0.745313  , 0.63012433, 0.60761625, 0.59546   ,\n",
       "           0.58872545, 0.6003527 , 0.61229247, 0.60308224, 0.5846241 ,\n",
       "           0.5706986 , 0.5681751 , 0.5739132 , 0.5224328 ],\n",
       "          [0.5255467 , 0.7696309 , 0.63224894, 0.5953869 , 0.5888737 ,\n",
       "           0.579539  , 0.58015054, 0.5855204 , 0.58196056, 0.57736766,\n",
       "           0.5769926 , 0.58448994, 0.60718447, 0.55322707],\n",
       "          [0.53929746, 0.81178844, 0.65685576, 0.62992144, 0.64178956,\n",
       "           0.6496039 , 0.65452516, 0.6594492 , 0.65913284, 0.65288746,\n",
       "           0.65205055, 0.66022515, 0.6773968 , 0.65178764],\n",
       "          [0.5518446 , 0.8376208 , 0.6872403 , 0.6407491 , 0.6600053 ,\n",
       "           0.68726104, 0.72490287, 0.7405788 , 0.7479186 , 0.74431044,\n",
       "           0.7508533 , 0.7532042 , 0.7650226 , 0.72278786],\n",
       "          [0.55365074, 0.8391314 , 0.6781844 , 0.6410517 , 0.6650434 ,\n",
       "           0.70155025, 0.76632226, 0.7964984 , 0.8136939 , 0.82126963,\n",
       "           0.8304174 , 0.8215896 , 0.807146  , 0.73919904],\n",
       "          [0.54898703, 0.8298954 , 0.64920974, 0.62713164, 0.6583808 ,\n",
       "           0.69930756, 0.7675214 , 0.79925776, 0.8148998 , 0.83257616,\n",
       "           0.8486819 , 0.8455418 , 0.8342917 , 0.7501668 ],\n",
       "          [0.54060286, 0.823815  , 0.645841  , 0.63061535, 0.6666295 ,\n",
       "           0.7116941 , 0.7694775 , 0.7899896 , 0.79478186, 0.8138987 ,\n",
       "           0.8368208 , 0.84620005, 0.846668  , 0.7602954 ],\n",
       "          [0.53456867, 0.81564456, 0.6466201 , 0.63365495, 0.6599484 ,\n",
       "           0.68710524, 0.70084715, 0.71200156, 0.7178628 , 0.72569066,\n",
       "           0.75673485, 0.7832799 , 0.8004233 , 0.72140783],\n",
       "          [0.5314925 , 0.810031  , 0.6509691 , 0.62950337, 0.6394145 ,\n",
       "           0.6430781 , 0.63625973, 0.6312494 , 0.6258033 , 0.62400645,\n",
       "           0.6302397 , 0.63769823, 0.64276135, 0.6045547 ],\n",
       "          [0.5242251 , 0.7977794 , 0.63804746, 0.60278445, 0.6008867 ,\n",
       "           0.59730476, 0.58900654, 0.5703906 , 0.5626159 , 0.5754746 ,\n",
       "           0.6046977 , 0.6254053 , 0.6356662 , 0.56880164],\n",
       "          [0.5039096 , 0.76154673, 0.6178393 , 0.5814543 , 0.57093847,\n",
       "           0.5707005 , 0.5671863 , 0.5496651 , 0.54047835, 0.5527785 ,\n",
       "           0.5818615 , 0.6142408 , 0.62425375, 0.5649284 ],\n",
       "          [0.44777003, 0.54893905, 0.5312614 , 0.52778774, 0.5262637 ,\n",
       "           0.52754456, 0.52419215, 0.51631194, 0.5145259 , 0.5255061 ,\n",
       "           0.5423986 , 0.56433356, 0.5739533 , 0.52606714]]]],\n",
       "       dtype=float32),\n",
       " array([[[[ 1.7130575e+00,  3.1238470e+00,  2.4205604e+00,\n",
       "            2.1047239e+00,  1.9820088e+00,  1.7337272e+00,\n",
       "            1.5443032e+00,  1.1363208e+00,  6.6334385e-01,\n",
       "            2.8169394e-02, -6.6712415e-01, -1.2974699e+00,\n",
       "           -2.0572586e+00, -2.7400210e+00],\n",
       "          [ 2.7912621e+00,  4.8463025e+00,  3.7939086e+00,\n",
       "            3.2523370e+00,  3.0046816e+00,  2.6400671e+00,\n",
       "            2.3878689e+00,  1.7718618e+00,  9.8931211e-01,\n",
       "           -6.0320199e-02, -1.2259402e+00, -2.2702186e+00,\n",
       "           -3.4056225e+00, -3.8509831e+00],\n",
       "          [ 2.7926424e+00,  5.5520115e+00,  4.4049854e+00,\n",
       "            3.8417211e+00,  3.5584328e+00,  3.1839514e+00,\n",
       "            2.8592987e+00,  2.1257756e+00,  1.2447257e+00,\n",
       "            6.4032078e-03, -1.4496515e+00, -2.8884397e+00,\n",
       "           -4.1426249e+00, -4.4407339e+00],\n",
       "          [ 2.5843062e+00,  5.6533947e+00,  4.4041214e+00,\n",
       "            3.9031372e+00,  3.6471965e+00,  3.2202611e+00,\n",
       "            2.8994327e+00,  2.1674919e+00,  1.2345833e+00,\n",
       "           -8.7186098e-03, -1.6209600e+00, -3.2692533e+00,\n",
       "           -4.4837289e+00, -4.7450747e+00],\n",
       "          [ 2.2190225e+00,  5.3832769e+00,  4.0075874e+00,\n",
       "            3.4601951e+00,  3.3582804e+00,  3.0871463e+00,\n",
       "            2.7742131e+00,  2.1467476e+00,  1.1835290e+00,\n",
       "           -1.3740128e-01, -1.9503249e+00, -3.4475436e+00,\n",
       "           -4.6545310e+00, -4.8340044e+00],\n",
       "          [ 1.8992409e+00,  5.2240691e+00,  3.6341069e+00,\n",
       "            2.7841966e+00,  2.8813047e+00,  2.9749384e+00,\n",
       "            2.7216027e+00,  2.1978920e+00,  1.0581787e+00,\n",
       "           -3.0875951e-01, -2.0714309e+00, -3.6386361e+00,\n",
       "           -4.6440434e+00, -4.6779485e+00],\n",
       "          [ 1.8151320e+00,  5.3047504e+00,  3.4801812e+00,\n",
       "            2.2965317e+00,  2.4407978e+00,  2.6462898e+00,\n",
       "            2.5319128e+00,  2.2122283e+00,  1.0489802e+00,\n",
       "           -2.8953204e-01, -2.1127727e+00, -3.7322781e+00,\n",
       "           -4.6161051e+00, -4.5097094e+00],\n",
       "          [ 1.8923969e+00,  5.5035210e+00,  3.5462306e+00,\n",
       "            2.1514254e+00,  2.3239937e+00,  2.5212276e+00,\n",
       "            2.5162888e+00,  2.3146033e+00,  1.2468449e+00,\n",
       "           -6.8253636e-02, -2.0137315e+00, -3.7107043e+00,\n",
       "           -4.6490326e+00, -4.4808211e+00],\n",
       "          [ 2.0395749e+00,  5.7660933e+00,  3.8317289e+00,\n",
       "            2.4535394e+00,  2.6161098e+00,  2.7359285e+00,\n",
       "            2.7486453e+00,  2.5616555e+00,  1.6869276e+00,\n",
       "            3.5637316e-01, -1.6676309e+00, -3.6280389e+00,\n",
       "           -4.7488475e+00, -4.6178002e+00],\n",
       "          [ 2.2198715e+00,  6.0307570e+00,  4.2530460e+00,\n",
       "            3.0632827e+00,  3.2098432e+00,  3.1856785e+00,\n",
       "            3.0754504e+00,  2.8367181e+00,  2.0974936e+00,\n",
       "            7.5311667e-01, -1.1662220e+00, -3.4561176e+00,\n",
       "           -4.8779941e+00, -4.9075580e+00],\n",
       "          [ 2.4203515e+00,  6.2119017e+00,  4.5781646e+00,\n",
       "            3.6196907e+00,  3.6451657e+00,  3.3710120e+00,\n",
       "            3.0861559e+00,  2.9167609e+00,  2.2809255e+00,\n",
       "            8.7251776e-01, -7.0057452e-01, -3.1580391e+00,\n",
       "           -4.9865360e+00, -5.1847649e+00],\n",
       "          [ 2.4928703e+00,  6.1882868e+00,  4.6636248e+00,\n",
       "            3.7604542e+00,  3.7084284e+00,  3.3823917e+00,\n",
       "            2.9563589e+00,  2.7833033e+00,  2.2026656e+00,\n",
       "            1.0163790e+00, -7.3658371e-01, -2.9075050e+00,\n",
       "           -4.9672976e+00, -5.2683721e+00],\n",
       "          [ 2.2041979e+00,  5.7807670e+00,  4.3808746e+00,\n",
       "            3.2369990e+00,  3.2115920e+00,  3.0285969e+00,\n",
       "            2.7027733e+00,  2.4828527e+00,  1.8594549e+00,\n",
       "            6.0798204e-01, -9.3585730e-01, -2.7948642e+00,\n",
       "           -4.6742635e+00, -4.8965082e+00],\n",
       "          [ 1.3682239e+00,  3.9513280e+00,  2.6548860e+00,\n",
       "            1.9585853e+00,  2.0215676e+00,  2.0194123e+00,\n",
       "            1.8386476e+00,  1.6102620e+00,  1.0630336e+00,\n",
       "            2.2139414e-01, -7.9738235e-01, -2.0052824e+00,\n",
       "           -3.4335232e+00, -3.7391605e+00]],\n",
       " \n",
       "         [[ 5.1217955e-01,  2.3801703e+00,  3.2288084e+00,\n",
       "            3.7927725e+00,  4.0061221e+00,  4.1261067e+00,\n",
       "            4.2700572e+00,  4.3761735e+00,  4.3572435e+00,\n",
       "            4.2931247e+00,  4.2390647e+00,  4.1856098e+00,\n",
       "            4.0071468e+00,  3.1086621e+00],\n",
       "          [ 6.1891913e-02,  2.0414596e+00,  2.8060465e+00,\n",
       "            3.2782745e+00,  3.4248705e+00,  3.4813917e+00,\n",
       "            3.6043057e+00,  3.7122045e+00,  3.6898260e+00,\n",
       "            3.6578093e+00,  3.6516995e+00,  3.6525197e+00,\n",
       "            3.5605330e+00,  2.9990718e+00],\n",
       "          [-1.0821455e+00,  1.0320086e+00,  2.0006261e+00,\n",
       "            2.4321322e+00,  2.5065756e+00,  2.4743443e+00,\n",
       "            2.5141542e+00,  2.5244815e+00,  2.4419241e+00,\n",
       "            2.4592531e+00,  2.5962427e+00,  2.6955063e+00,\n",
       "            2.5945613e+00,  2.2015600e+00],\n",
       "          [-2.0924339e+00, -2.2543377e-01,  2.1643996e-01,\n",
       "            8.2203978e-01,  8.3372164e-01,  9.1265464e-01,\n",
       "            1.0016975e+00,  9.7021735e-01,  8.9424223e-01,\n",
       "            8.8833761e-01,  9.3070793e-01,  8.4818518e-01,\n",
       "            7.5897872e-01,  7.2680962e-01],\n",
       "          [-2.7489498e+00, -1.1223633e+00, -9.7024494e-01,\n",
       "           -6.3042456e-01, -5.7189626e-01, -3.1055140e-01,\n",
       "           -2.3177844e-01, -2.4329093e-01, -3.3246717e-01,\n",
       "           -2.9607841e-01, -3.4700009e-01, -4.0041122e-01,\n",
       "           -7.0072621e-01, -5.0401843e-01],\n",
       "          [-3.1887696e+00, -1.5890001e+00, -1.4554757e+00,\n",
       "           -1.1110790e+00, -1.0786302e+00, -9.2183810e-01,\n",
       "           -8.3673519e-01, -7.1176398e-01, -7.8001463e-01,\n",
       "           -8.1653214e-01, -7.9838604e-01, -9.6699774e-01,\n",
       "           -1.3675674e+00, -1.0317942e+00],\n",
       "          [-3.4056761e+00, -1.6534338e+00, -1.3484477e+00,\n",
       "           -8.1793618e-01, -6.6295767e-01, -4.5977306e-01,\n",
       "           -2.9346648e-01, -2.1202415e-02, -2.5974303e-02,\n",
       "           -3.5014208e-02, -1.3508412e-01, -4.2487130e-01,\n",
       "           -8.9843905e-01, -6.7225981e-01],\n",
       "          [-3.5178938e+00, -1.6232148e+00, -1.1278851e+00,\n",
       "           -3.2989243e-01,  1.5049112e-01,  5.8134532e-01,\n",
       "            9.0130860e-01,  1.2030944e+00,  1.2525558e+00,\n",
       "            1.3772782e+00,  1.2972550e+00,  1.0444609e+00,\n",
       "            4.1362506e-01,  2.2581804e-01],\n",
       "          [-3.5631344e+00, -1.6141800e+00, -1.0227563e+00,\n",
       "            1.6903818e-02,  8.1292415e-01,  1.5084060e+00,\n",
       "            1.9374616e+00,  2.1382067e+00,  2.1415462e+00,\n",
       "            2.1386127e+00,  2.1502969e+00,  1.9702166e+00,\n",
       "            1.5695564e+00,  1.1539522e+00],\n",
       "          [-3.5990295e+00, -1.7592758e+00, -1.2229424e+00,\n",
       "           -2.6550016e-01,  4.7884586e-01,  1.1139977e+00,\n",
       "            1.4835026e+00,  1.5875793e+00,  1.5103866e+00,\n",
       "            1.4179091e+00,  1.4579515e+00,  1.5677354e+00,\n",
       "            1.5239631e+00,  1.3565297e+00],\n",
       "          [-3.6638675e+00, -2.0678058e+00, -1.7360799e+00,\n",
       "           -1.0869222e+00, -6.3284934e-01, -2.6186800e-01,\n",
       "            1.4667690e-02,  5.2458301e-02, -7.3820591e-02,\n",
       "           -1.3447507e-01, -1.0709000e-01,  1.9135713e-03,\n",
       "            1.4832664e-01,  5.3701925e-01],\n",
       "          [-3.8283181e+00, -2.6489272e+00, -2.6190515e+00,\n",
       "           -2.3160357e+00, -2.0930610e+00, -1.8159795e+00,\n",
       "           -1.5688320e+00, -1.3926234e+00, -1.2884705e+00,\n",
       "           -1.2459304e+00, -1.3164577e+00, -1.5651436e+00,\n",
       "           -1.7446661e+00, -1.0434251e+00],\n",
       "          [-4.0433912e+00, -3.4958124e+00, -3.6311984e+00,\n",
       "           -3.5971408e+00, -3.5048199e+00, -3.3161030e+00,\n",
       "           -3.0393467e+00, -2.8102465e+00, -2.7643394e+00,\n",
       "           -2.8128190e+00, -2.8850136e+00, -3.0333991e+00,\n",
       "           -3.2194333e+00, -2.4420447e+00],\n",
       "          [-3.2218637e+00, -3.1150751e+00, -3.3620913e+00,\n",
       "           -3.3325815e+00, -3.3030553e+00, -3.2599778e+00,\n",
       "           -3.1875405e+00, -3.1495948e+00, -3.2105873e+00,\n",
       "           -3.3123407e+00, -3.4577243e+00, -3.6380281e+00,\n",
       "           -3.7520866e+00, -3.0305843e+00]]]], dtype=float32))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictV2_head(context,template_list,search_list,template_anno_list,onnx_Unsqueeze_3,onnx_Unsqueeze_4,onnx_Unsqueeze_5,onnx_Unsqueeze_6,onnx_Unsqueeze_7,onnx_Unsqueeze_8,onnx_Unsqueeze_9,onnx_Unsqueeze_10,\n",
    "               data[0],data[1],data[2],data[3],data[4],data[5],data[6],data[7],data[8],data[9],data[10],data[11],data[12],data[13],data[14])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node 'Reshape_113' найден.\n",
      "  inputs: ['onnx::Reshape_567', 'onnx::Reshape_4767']\n",
      "  outputs: ['z']\n",
      "  Вход 0: onnx::Reshape_567 -> [1, 5, 3, 112, 112]\n",
      "  Вход 1: onnx::Reshape_4767 -> None\n",
      "  Выход 0: z -> [5, 3, 112, 112]\n",
      "Node 'Reshape_113' найден.\n",
      "  inputs: ['onnx::Reshape_567', 'onnx::Reshape_4767']\n",
      "  outputs: ['z']\n",
      "  Вход 0: onnx::Reshape_567 -> None\n",
      "  Вход 1: onnx::Reshape_4767 -> None\n",
      "  Выход 0: z -> None\n"
     ]
    }
   ],
   "source": [
    "import onnx\n",
    "\n",
    "# Загрузите модель\n",
    "model = onnx.load(\"MCITrack.onnx\")\n",
    "\n",
    "\n",
    "\n",
    "# Примените инференс формы\n",
    "inferred_model = onnx.shape_inference.infer_shapes(model)\n",
    "\n",
    "# Найдите нужную ноду\n",
    "node_name = \"Reshape_113\"\n",
    "node = None\n",
    "for n in inferred_model.graph.node:\n",
    "    if n.name == node_name:\n",
    "        node = n\n",
    "        break\n",
    "\n",
    "def get_tensor_shape(graph, name):\n",
    "    for v in list(graph.value_info) + list(graph.input) + list(graph.output):\n",
    "        if v.name == name:\n",
    "            return [d.dim_param if d.dim_param else d.dim_value for d in v.type.tensor_type.shape.dim]\n",
    "    return None\n",
    "\n",
    "if node is None:\n",
    "    print(f\"Node {node_name} not found!\")\n",
    "else:\n",
    "    print(f\"Node '{node_name}' найден.\")\n",
    "    print(\"  inputs:\", node.input)\n",
    "    print(\"  outputs:\", node.output)\n",
    "\n",
    "    for i, inp in enumerate(node.input):\n",
    "        shape = get_tensor_shape(inferred_model.graph, inp)\n",
    "        print(f\"  Вход {i}: {inp} -> {shape}\")\n",
    "\n",
    "    for i, out in enumerate(node.output):\n",
    "        shape = get_tensor_shape(inferred_model.graph, out)\n",
    "        print(f\"  Выход {i}: {out} -> {shape}\")\n",
    "# Найдите нужную ноду\n",
    "node_name = \"Reshape_113\"\n",
    "node = None\n",
    "for n in model.graph.node:\n",
    "    if n.name == node_name:\n",
    "        node = n\n",
    "        break\n",
    "\n",
    "if node is None:\n",
    "    print(f\"Node {node_name} not found!\")\n",
    "else:\n",
    "    print(f\"Node '{node_name}' найден.\")\n",
    "    print(\"  inputs:\", node.input)\n",
    "    print(\"  outputs:\", node.output)\n",
    "\n",
    "    # Функция для получения размеров по имени tensor'a\n",
    "    def get_tensor_shape(name):\n",
    "        for v in model.graph.value_info:\n",
    "            if v.name == name:\n",
    "                return [d.dim_param if d.dim_param else d.dim_value\n",
    "                        for d in v.type.tensor_type.shape.dim]\n",
    "        for v in model.graph.input:\n",
    "            if v.name == name:\n",
    "                return [d.dim_param if d.dim_param else d.dim_value\n",
    "                        for d in v.type.tensor_type.shape.dim]\n",
    "        for v in model.graph.output:\n",
    "            if v.name == name:\n",
    "                return [d.dim_param if d.dim_param else d.dim_value\n",
    "                        for d in v.type.tensor_type.shape.dim]\n",
    "        return None\n",
    "\n",
    "    for i, inp in enumerate(node.input):\n",
    "        shape = get_tensor_shape(inp)\n",
    "        print(f\"  Вход {i}: {inp} -> {shape}\")\n",
    "\n",
    "    for i, out in enumerate(node.output):\n",
    "        shape = get_tensor_shape(out)\n",
    "        print(f\"  Выход {i}: {out} -> {shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_bbox(score_map_ctr, size_map, offset_map, return_score=True):\n",
    "    \n",
    "    # 2. Получаем размеры feature map\n",
    "    feat_h, feat_w = score_map_ctr.shape[-2], score_map_ctr.shape[-1]\n",
    "    \n",
    "    # 3. Находим позицию с максимальным score (современный способ)\n",
    "    max_score, flat_idx = torch.max(score_map_ctr.flatten(1), dim=1)\n",
    "    idx = flat_idx.unsqueeze(1)\n",
    "    idx_y = torch.div(flat_idx, feat_w, rounding_mode='floor')\n",
    "    idx_x = flat_idx % feat_w\n",
    "    \n",
    "    # 4. Подготовка индексов для gather\n",
    "    gather_idx = idx.unsqueeze(1).expand(-1, 2, -1)\n",
    "    \n",
    "    # 5. Обработка size_map (расширяем если 1 канал)\n",
    "    if size_map.size(1) == 1:\n",
    "        size_map = size_map.expand(-1, 2, -1, -1)\n",
    "    \n",
    "    # 6. Получаем размеры и смещения\n",
    "    try:\n",
    "        size = size_map.flatten(2).gather(2, gather_idx)\n",
    "        offset = offset_map.flatten(2).gather(2, gather_idx).squeeze(-1)\n",
    "    except RuntimeError as e:\n",
    "        print(\"Ошибка размерностей:\")\n",
    "        print(f\"score_map_ctr: {score_map_ctr.shape}\")\n",
    "        print(f\"size_map: {size_map.shape}\")\n",
    "        print(f\"offset_map: {offset_map.shape}\")\n",
    "        print(f\"gather_idx: {gather_idx.shape}\")\n",
    "        raise\n",
    "    \n",
    "    # 7. Формируем bbox (cx, cy, w, h)\n",
    "    bbox = torch.cat([\n",
    "        (idx_x.to(torch.float) + offset[:, 0:1]) / feat_w,\n",
    "        (idx_y.to(torch.float) + offset[:, 1:2]) / feat_h,\n",
    "        size.squeeze(-1)\n",
    "    ], dim=1)\n",
    "    \n",
    "    return (bbox, max_score) if return_score else bbox\n",
    "\n",
    "\"\"\" def cal_bbox(score_map_ctr, size_map, offset_map, return_score=True):\n",
    "        feat_sz = 14\n",
    "        max_score, idx = torch.max(score_map_ctr.flatten(1), dim=1, keepdim=True) # score_map_ctr.flatten(1): torch.Size([32, 256]) idx: torch.Size([32, 1]) max_score: torch.Size([32, 1])\n",
    "        idx_y = torch.div(idx, feat_sz, rounding_mode='floor')\n",
    "        idx_x = idx % feat_sz\n",
    "       \n",
    "        \n",
    "\n",
    "        idx = idx.unsqueeze(1).expand(idx.shape[0], 2, 1)\n",
    "        size = size_map.flatten(2).gather(dim=2, index=idx) # size_map: torch.Size([32, 2, 16, 16])  size_map.flatten(2): torch.Size([32, 2, 256])\n",
    "        offset = offset_map.flatten(2).gather(dim=2, index=idx).squeeze(-1)\n",
    "\n",
    "        # bbox = torch.cat([idx_x - size[:, 0] / 2, idx_y - size[:, 1] / 2,\n",
    "        #                   idx_x + size[:, 0] / 2, idx_y + size[:, 1] / 2], dim=1) / self.feat_sz\n",
    "        # cx, cy, w, h\n",
    "        bbox = torch.cat([(idx_x.to(torch.float) + offset[:, :1]) / feat_sz,\n",
    "                          (idx_y.to(torch.float) + offset[:, 1:]) / feat_sz,\n",
    "                          size.squeeze(-1)], dim=1)\n",
    "\n",
    "        if return_score:\n",
    "            return bbox, max_score\n",
    "        return (bbox, max_score) if return_score else bbox \"\"\"\n",
    "        \n",
    "class Preprocessor(object):\n",
    "    def __init__(self):\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        self.mean = torch.tensor([0.485, 0.456, 0.406]).view((1, 3, 1, 1)).to(self.device)\n",
    "        self.std = torch.tensor([0.229, 0.224, 0.225]).view((1, 3, 1, 1)).to(self.device)\n",
    "        self.mm_mean = torch.tensor([0.485, 0.456, 0.406, 0.485, 0.456, 0.406]).view((1, 6, 1, 1)).to(self.device)\n",
    "        self.mm_std = torch.tensor([0.229, 0.224, 0.225, 0.229, 0.224, 0.225]).view((1, 6, 1, 1)).to(self.device)\n",
    "\n",
    "    def process(self, img_arr: np.ndarray):\n",
    "        if img_arr.shape[-1] == 6:\n",
    "            mean = self.mm_mean\n",
    "            std = self.mm_std\n",
    "        else:\n",
    "            mean = self.mean\n",
    "            std = self.std\n",
    "        # Deal with the image patch\n",
    "        img_tensor = torch.tensor(img_arr).to(self.device).float().permute((2,0,1)).unsqueeze(dim=0)        \n",
    "        img_tensor_norm = ((img_tensor / 255.0) - mean) / std  # (1,3,H,W)\n",
    "        return img_tensor_norm\n",
    "    \n",
    "def hann1d(sz: int, centered = True) -> torch.Tensor:\n",
    "    \"\"\"1D cosine window.\"\"\"\n",
    "    if centered:\n",
    "        return 0.5 * (1 - torch.cos((2 * math.pi / (sz + 1)) * torch.arange(1, sz + 1).float()))\n",
    "    w = 0.5 * (1 + torch.cos((2 * math.pi / (sz + 2)) * torch.arange(0, sz//2 + 1).float()))\n",
    "    return torch.cat([w, w[1:sz-sz//2].flip((0,))])\n",
    "    \n",
    "def hann2d(sz: torch.Tensor, centered = True) -> torch.Tensor:\n",
    "    \"\"\"2D cosine window.\"\"\"\n",
    "    return hann1d(sz[0].item(), centered).reshape(1, 1, -1, 1) * hann1d(sz[1].item(), centered).reshape(1, 1, 1, -1)    \n",
    "\n",
    "def sample_target(im, target_bb, search_area_factor, output_sz=None):\n",
    "   \n",
    "    if not isinstance(target_bb, list):\n",
    "        x, y, w, h = target_bb.tolist()\n",
    "    else:\n",
    "        x, y, w, h = target_bb\n",
    "    # Crop image\n",
    "    crop_sz = math.ceil(math.sqrt(w * h) * search_area_factor)\n",
    "\n",
    "    if crop_sz < 1:\n",
    "        raise Exception('Too small bounding box.')\n",
    "\n",
    "    x1 = round(x + 0.5 * w - crop_sz * 0.5)\n",
    "    x2 = x1 + crop_sz\n",
    "\n",
    "    y1 = round(y + 0.5 * h - crop_sz * 0.5)\n",
    "    y2 = y1 + crop_sz\n",
    "\n",
    "    x1_pad = max(0, -x1)\n",
    "    x2_pad = max(x2 - im.shape[1] + 1, 0)\n",
    "\n",
    "    y1_pad = max(0, -y1)\n",
    "    y2_pad = max(y2 - im.shape[0] + 1, 0)\n",
    "\n",
    "    # Crop target\n",
    "    im_crop = im[y1 + y1_pad:y2 - y2_pad, x1 + x1_pad:x2 - x2_pad, :]\n",
    "\n",
    "    # Pad\n",
    "    im_crop_padded = cv2.copyMakeBorder(im_crop, y1_pad, y2_pad, x1_pad, x2_pad, cv2.BORDER_CONSTANT)\n",
    "    # deal with attention mask\n",
    "    H, W, _ = im_crop_padded.shape\n",
    "\n",
    "    if output_sz is not None:\n",
    "        resize_factor = output_sz / crop_sz\n",
    "        im_crop_padded = cv2.resize(im_crop_padded, (output_sz, output_sz))\n",
    "\n",
    "        return im_crop_padded, resize_factor\n",
    "\n",
    "    else:\n",
    "        return im_crop_padded, 1.0\n",
    "def transform_image_to_crop(box_in: torch.Tensor, box_extract: torch.Tensor, resize_factor: float,\n",
    "                            crop_sz: torch.Tensor, normalize=False) -> torch.Tensor:\n",
    "   \n",
    "    box_extract_center = box_extract[0:2] + 0.5 * box_extract[2:4]\n",
    "\n",
    "    box_in_center = box_in[0:2] + 0.5 * box_in[2:4]\n",
    "\n",
    "    box_out_center = (crop_sz - 1) / 2 + (box_in_center - box_extract_center) * resize_factor\n",
    "    box_out_wh = box_in[2:4] * resize_factor\n",
    "\n",
    "    box_out = torch.cat((box_out_center - 0.5 * box_out_wh, box_out_wh))\n",
    "    if normalize:\n",
    "        return box_out / (crop_sz[0]-1)\n",
    "    else:\n",
    "        return box_out\n",
    "def clip_box(box: list, H, W, margin=0):\n",
    "    x1, y1, w, h = box\n",
    "    x2, y2 = x1 + w, y1 + h\n",
    "    x1 = min(max(0, x1), W-margin)\n",
    "    x2 = min(max(margin, x2), W)\n",
    "    y1 = min(max(0, y1), H-margin)\n",
    "    y2 = min(max(margin, y2), H)\n",
    "    w = max(margin, x2-x1)\n",
    "    h = max(margin, y2-y1)\n",
    "    return [x1, y1, w, h]\n",
    "\n",
    "class BaseTracker():\n",
    "    \"\"\"Base class for all trackers.\"\"\"\n",
    "\n",
    "    def __init__(self, params):\n",
    "        self.params = params\n",
    "        self.visdom = None\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    def predicts_segmentation_mask(self):\n",
    "        return False\n",
    "\n",
    "    def initialize(self, image, info: dict) -> dict:\n",
    "        \"\"\"Overload this function in your tracker. This should initialize the model.\"\"\"\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def track(self, image, info: dict = None) -> dict:\n",
    "        \"\"\"Overload this function in your tracker. This should track in the frame and update the model.\"\"\"\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def visdom_draw_tracking(self, image, box, segmentation=None):\n",
    "        # Упрощенная обработка box без OrderedDict\n",
    "        if isinstance(box, dict):  # Проверяем на обычный dict вместо OrderedDict\n",
    "            box = list(box.values())  # Берем только значения\n",
    "        elif not isinstance(box, (list, tuple)):  # Если не коллекция\n",
    "            box = (box,)  # Превращаем в кортеж\n",
    "        \n",
    "        # Визуализация\n",
    "        if segmentation is None:\n",
    "            self.visdom.register((image, *box), 'Tracking', 1, 'Tracking')\n",
    "        else:\n",
    "            self.visdom.register((image, *box, segmentation), 'Tracking', 1, 'Tracking')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = {}\n",
    "\n",
    "# MODEL\n",
    "cfg[\"MODEL\"] = {}\n",
    "\n",
    "# MODEL.ENCODER\n",
    "cfg[\"MODEL\"][\"ENCODER\"] = {\n",
    "    \"TYPE\": \"dinov2_vitb14\",  # encoder model\n",
    "    \"DROP_PATH\": 0,\n",
    "    \"PRETRAIN_TYPE\": \"mae\",  # mae, default, or scratch. This parameter is not activated for dinov2.\n",
    "    \"USE_CHECKPOINT\": False,  # to save the memory.\n",
    "    \"STRIDE\": 14,\n",
    "    \"POS_TYPE\": 'interpolate',  # type of loading the positional encoding. \"interpolate\" or \"index\".\n",
    "    \"TOKEN_TYPE_INDICATE\": False,  # add a token_type_embedding to indicate the search, template_foreground, template_background\n",
    "    \"INTERACTION_INDEXES\": [[0, 6], [6, 12], [12, 18], [18, 24]],\n",
    "    \"GRAD_CKPT\": False\n",
    "}\n",
    "\n",
    "# MODEL.NECK\n",
    "cfg[\"MODEL\"][\"NECK\"] = {\n",
    "    \"N_LAYERS\": 4,\n",
    "    \"D_MODEL\": 512,\n",
    "    \"D_STATE\": 16  # MAMABA_HIDDEN_STATE\n",
    "}\n",
    "\n",
    "# MODEL.DECODER\n",
    "cfg[\"MODEL\"][\"DECODER\"] = {\n",
    "    \"TYPE\": \"CENTER\",  # MLP, CORNER, CENTER\n",
    "    \"NUM_CHANNELS\": 256\n",
    "}\n",
    "\n",
    "# TRAIN\n",
    "cfg[\"TRAIN\"] = {\n",
    "    \"LR\": 0.0001,\n",
    "    \"WEIGHT_DECAY\": 0.0001,\n",
    "    \"EPOCH\": 500,\n",
    "    \"LR_DROP_EPOCH\": 400,\n",
    "    \"BATCH_SIZE\": 8,\n",
    "    \"NUM_WORKER\": 8,\n",
    "    \"OPTIMIZER\": \"ADAMW\",\n",
    "    \"ENCODER_MULTIPLIER\": 0.1,  # encoder's LR = this factor * LR\n",
    "    \"FREEZE_ENCODER\": False,  # for freezing the parameters of encoder\n",
    "    \"ENCODER_OPEN\": [],  # only for debug, open some layers of encoder when FREEZE_ENCODER is True\n",
    "    \"CE_WEIGHT\": 1.0,  # weight for cross-entropy loss\n",
    "    \"GIOU_WEIGHT\": 2.0,\n",
    "    \"L1_WEIGHT\": 5.0,\n",
    "    \"PRINT_INTERVAL\": 50,  # interval to print the training log\n",
    "    \"GRAD_CLIP_NORM\": 0.1,\n",
    "    \"FIX_BN\": False,\n",
    "    \"ENCODER_W\": \"\",\n",
    "    \"TYPE\": \"normal\",  # normal, peft or fft\n",
    "    \"PRETRAINED_PATH\": None\n",
    "}\n",
    "\n",
    "# TRAIN.SCHEDULER\n",
    "cfg[\"TRAIN\"][\"SCHEDULER\"] = {\n",
    "    \"TYPE\": \"step\",\n",
    "    \"DECAY_RATE\": 0.1\n",
    "}\n",
    "\n",
    "# DATA\n",
    "cfg[\"DATA\"] = {\n",
    "    \"MEAN\": [0.485, 0.456, 0.406],\n",
    "    \"STD\": [0.229, 0.224, 0.225],\n",
    "    \"MAX_SAMPLE_INTERVAL\": 200,\n",
    "    \"SAMPLER_MODE\": \"order\",\n",
    "    \"LOADER\": \"tracking\"\n",
    "}\n",
    "\n",
    "# DATA.TRAIN\n",
    "cfg[\"DATA\"][\"TRAIN\"] = {\n",
    "    \"DATASETS_NAME\": [\"LASOT\", \"GOT10K_vottrain\"],\n",
    "    \"DATASETS_RATIO\": [1, 1],\n",
    "    \"SAMPLE_PER_EPOCH\": 60000\n",
    "}\n",
    "\n",
    "# DATA.SEARCH\n",
    "cfg[\"DATA\"][\"SEARCH\"] = {\n",
    "    \"NUMBER\": 1,  # number of search region, only support 1 for now.\n",
    "    \"SIZE\": 256,\n",
    "    \"FACTOR\": 4.0,\n",
    "    \"CENTER_JITTER\": 3.5,\n",
    "    \"SCALE_JITTER\": 0.5\n",
    "}\n",
    "\n",
    "# DATA.TEMPLATE\n",
    "cfg[\"DATA\"][\"TEMPLATE\"] = {\n",
    "    \"NUMBER\": 1,\n",
    "    \"SIZE\": 128,\n",
    "    \"FACTOR\": 2.0,\n",
    "    \"CENTER_JITTER\": 0,\n",
    "    \"SCALE_JITTER\": 0\n",
    "}\n",
    "\n",
    "# TEST\n",
    "cfg[\"TEST\"] = {\n",
    "    \"TEMPLATE_FACTOR\": 4.0,\n",
    "    \"TEMPLATE_SIZE\": 256,\n",
    "    \"SEARCH_FACTOR\": 2.0,\n",
    "    \"SEARCH_SIZE\": 128,\n",
    "    \"EPOCH\": 500,\n",
    "    \"WINDOW\": False,  # window penalty\n",
    "    \"NUM_TEMPLATES\": 1\n",
    "}\n",
    "\n",
    "# TEST.UPT\n",
    "cfg[\"TEST\"][\"UPT\"] = {\n",
    "    \"DEFAULT\": 1,\n",
    "    \"LASOT\": 0,\n",
    "    \"LASOT_EXTENSION_SUBSET\": 0,\n",
    "    \"TRACKINGNET\": 0,\n",
    "    \"TNL2K\": 0,\n",
    "    \"NFS\": 0,\n",
    "    \"UAV\": 0,\n",
    "    \"VOT20\": 0,\n",
    "    \"GOT10K_TEST\": 0\n",
    "}\n",
    "\n",
    "# TEST.UPH\n",
    "cfg[\"TEST\"][\"UPH\"] = {\n",
    "    \"DEFAULT\": 1,\n",
    "    \"LASOT\": 0,\n",
    "    \"LASOT_EXTENSION_SUBSET\": 0,\n",
    "    \"TRACKINGNET\": 0,\n",
    "    \"TNL2K\": 0,\n",
    "    \"NFS\": 0,\n",
    "    \"UAV\": 0,\n",
    "    \"VOT20\": 0,\n",
    "    \"GOT10K_TEST\": 0\n",
    "}\n",
    "\n",
    "# TEST.INTER\n",
    "cfg[\"TEST\"][\"INTER\"] = {\n",
    "    \"DEFAULT\": 999999,\n",
    "    \"LASOT\": 0,\n",
    "    \"LASOT_EXTENSION_SUBSET\": 0,\n",
    "    \"TRACKINGNET\": 0,\n",
    "    \"TNL2K\": 0,\n",
    "    \"NFS\": 0,\n",
    "    \"UAV\": 0,\n",
    "    \"VOT20\": 0,\n",
    "    \"GOT10K_TEST\": 0\n",
    "}\n",
    "\n",
    "# TEST.MB\n",
    "cfg[\"TEST\"][\"MB\"] = {\n",
    "    \"DEFAULT\": 500,\n",
    "    \"LASOT\": 0,\n",
    "    \"LASOT_EXTENSION_SUBSET\": 0,\n",
    "    \"TRACKINGNET\": 0,\n",
    "    \"TNL2K\": 0,\n",
    "    \"NFS\": 0,\n",
    "    \"UAV\": 0,\n",
    "    \"VOT20\": 0,\n",
    "    \"GOT10K_TEST\": 0\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test config:  {'MODEL': {'ENCODER': {'TYPE': 'fastitpnt', 'DROP_PATH': 0.1, 'PRETRAIN_TYPE': './fast_itpn_tiny_1600e_1k.pt', 'USE_CHECKPOINT': False, 'STRIDE': 16, 'POS_TYPE': 'index', 'TOKEN_TYPE_INDICATE': True, 'INTERACTION_INDEXES': [[4, 7], [7, 10], [10, 13], [13, 16]], 'GRAD_CKPT': False}, 'NECK': {'N_LAYERS': 4, 'D_MODEL': 384, 'D_STATE': 16}, 'DECODER': {'TYPE': 'CENTER', 'NUM_CHANNELS': 256}}, 'TRAIN': {'LR': 0.0004, 'WEIGHT_DECAY': 0.0001, 'EPOCH': 300, 'LR_DROP_EPOCH': 240, 'BATCH_SIZE': 64, 'NUM_WORKER': 10, 'OPTIMIZER': 'ADAMW', 'ENCODER_MULTIPLIER': 0.1, 'FREEZE_ENCODER': False, 'ENCODER_OPEN': [], 'CE_WEIGHT': 1.0, 'GIOU_WEIGHT': 2.0, 'L1_WEIGHT': 5.0, 'PRINT_INTERVAL': 50, 'GRAD_CLIP_NORM': 0.1, 'FIX_BN': False, 'ENCODER_W': '', 'TYPE': 'normal', 'PRETRAINED_PATH': None, 'SCHEDULER': {'TYPE': 'step', 'DECAY_RATE': 0.1}}, 'DATA': {'MEAN': [0.485, 0.456, 0.406], 'STD': [0.229, 0.224, 0.225], 'MAX_SAMPLE_INTERVAL': 400, 'SAMPLER_MODE': 'order', 'LOADER': 'tracking', 'TRAIN': {'DATASETS_NAME': ['LASOT', 'GOT10K_vottrain', 'COCO17', 'TRACKINGNET', 'VASTTRACK'], 'DATASETS_RATIO': [1, 1, 1, 1, 1], 'SAMPLE_PER_EPOCH': 60000}, 'SEARCH': {'NUMBER': 2, 'SIZE': 224, 'FACTOR': 4.0, 'CENTER_JITTER': 3.5, 'SCALE_JITTER': 0.5}, 'TEMPLATE': {'NUMBER': 5, 'SIZE': 112, 'FACTOR': 2.0, 'CENTER_JITTER': 0, 'SCALE_JITTER': 0}}, 'TEST': {'TEMPLATE_FACTOR': 2.0, 'TEMPLATE_SIZE': 112, 'SEARCH_FACTOR': 4.0, 'SEARCH_SIZE': 224, 'EPOCH': 300, 'WINDOW': True, 'NUM_TEMPLATES': 5, 'UPT': {'DEFAULT': 1, 'LASOT': 0.8, 'LASOT_EXTENSION_SUBSET': 0.85, 'TRACKINGNET': 0.5, 'TNL2K': 0.5, 'NFS': 0.8, 'UAV': 0.2, 'VOT20': 0.4, 'GOT10K_TEST': 0}, 'UPH': {'DEFAULT': 1, 'LASOT': 0.88, 'LASOT_EXTENSION_SUBSET': 0.97, 'TRACKINGNET': 0.9, 'TNL2K': 0.9, 'NFS': 0.92, 'UAV': 0.91, 'VOT20': 0.94, 'GOT10K_TEST': 0}, 'INTER': {'DEFAULT': 999999, 'LASOT': 70, 'LASOT_EXTENSION_SUBSET': 50, 'TRACKINGNET': 20, 'TNL2K': 20, 'NFS': 90, 'UAV': 1, 'VOT20': 1, 'GOT10K_TEST': 0}, 'MB': {'DEFAULT': 500, 'LASOT': 500, 'LASOT_EXTENSION_SUBSET': 500, 'TRACKINGNET': 200, 'TNL2K': 500, 'NFS': 500, 'UAV': 400, 'VOT20': 500, 'GOT10K_TEST': 0}}}\n"
     ]
    }
   ],
   "source": [
    "#Params\n",
    "class TrackerParams:\n",
    "    \"\"\"Class for tracker parameters.\"\"\"\n",
    "    def set_default_values(self, default_vals: dict):\n",
    "        for name, val in default_vals.items():\n",
    "            if not hasattr(self, name):\n",
    "                setattr(self, name, val)\n",
    "\n",
    "    def get(self, name: str, *default):\n",
    "        \"\"\"Get a parameter value with the given name. If it does not exists, it return the default value given as a\n",
    "        second argument or returns an error if no default value is given.\"\"\"\n",
    "        if len(default) > 1:\n",
    "            raise ValueError('Can only give one default value.')\n",
    "\n",
    "        if not default:\n",
    "            return getattr(self, name)\n",
    "\n",
    "        return getattr(self, name, default[0])\n",
    "\n",
    "    def has(self, name: str):\n",
    "        \"\"\"Check if there exist a parameter with the given name.\"\"\"\n",
    "        return hasattr(self, name)\n",
    "\n",
    "def _update_config(base_cfg, exp_cfg):\n",
    "    if isinstance(base_cfg, dict) and isinstance(exp_cfg, dict):\n",
    "        for k, v in exp_cfg.items():\n",
    "            if k in base_cfg:\n",
    "                if not isinstance(v, dict):\n",
    "                    base_cfg[k] = v\n",
    "                else:\n",
    "                    _update_config(base_cfg[k], v)\n",
    "            else:\n",
    "                raise ValueError(\"{} not exist in config.py\".format(k))\n",
    "    else:\n",
    "        return\n",
    "\n",
    "def update_config_from_file(filename):\n",
    "    exp_config = None\n",
    "    with open(filename) as f:\n",
    "        exp_config = yaml.safe_load(f)\n",
    "        _update_config(cfg, exp_config)\n",
    "    \n",
    "def parameters(yaml_name: str):\n",
    "    params = TrackerParams()\n",
    "\n",
    "    yaml_file = \"mcitrack_t224.yaml\"\n",
    "    update_config_from_file(yaml_file)\n",
    "    params.cfg = cfg\n",
    "    print(\"test config: \", cfg)\n",
    "\n",
    "    params.yaml_name = yaml_name\n",
    "    # template and search region\n",
    "    params.template_factor = cfg[\"TEST\"][\"TEMPLATE_FACTOR\"]\n",
    "    params.template_size = cfg[\"TEST\"][\"TEMPLATE_SIZE\"]\n",
    "    params.search_factor = cfg[\"TEST\"][\"SEARCH_FACTOR\"]\n",
    "    params.search_size = cfg[\"TEST\"][\"SEARCH_SIZE\"]\n",
    "\n",
    "    # Network checkpoint path\n",
    "    params.checkpoint = \"MCITrack.trt\"\n",
    "    # whether to save boxes from all queries\n",
    "    params.save_all_boxes = False\n",
    "\n",
    "    return params\n",
    "\n",
    "params = parameters(\"./mcitrack_t224.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRT_LOGGER = trt.Logger(trt.Logger.WARNING)\n",
    "\n",
    "class MCITRACK(BaseTracker):\n",
    "    def __init__(self, params):\n",
    "        super(MCITRACK, self).__init__(params)\n",
    "        self.cfg = params.cfg\n",
    "\n",
    "        # Загружаем engine\n",
    "        self.engine = self.load_engine(\"MCITrack.trt\")\n",
    "        if not self.engine:\n",
    "            raise RuntimeError(\"Не удалось загрузить TensorRT engine.\")\n",
    "        \n",
    "        # Создаем execution context\n",
    "        self.context = self.engine.create_execution_context()\n",
    "\n",
    "        # Инициализируем память для ввода/вывода\n",
    "        self.d_input_z, self.d_input_x, self.d_input_anno, self.d_output_cls = self.initialize_memory()\n",
    "\n",
    "        self.preprocessor = Preprocessor()\n",
    "        self.state = None\n",
    "        self.frame_id = 0\n",
    "        self.save_all_boxes = params.save_all_boxes\n",
    "        self.z_dict1 = {}\n",
    "\n",
    "    def load_engine(self, engine_path):\n",
    "        with open(engine_path, \"rb\") as engine_file, trt.Runtime(TRT_LOGGER) as runtime:\n",
    "            engine = runtime.deserialize_cuda_engine(engine_file.read())\n",
    "        return engine\n",
    "\n",
    "    def initialize_memory(self):\n",
    "        # Выделяем память\n",
    "        self.d_input_z = cuda.mem_alloc(1 * 3 * 112 * 112 * np.dtype(np.float32).itemsize)\n",
    "        self.d_input_x = cuda.mem_alloc(1 * 3 * 224 * 224 * np.dtype(np.float32).itemsize)\n",
    "        self.d_input_anno = cuda.mem_alloc(1 * 4 * np.dtype(np.float32).itemsize)\n",
    "        self.d_output_cls = cuda.mem_alloc(1 * 4 * np.dtype(np.float32).itemsize)\n",
    "\n",
    "        print(\"Allocated memory addresses:\")\n",
    "        print(\"d_input_z:\", int(self.d_input_z))\n",
    "        print(\"d_input_x:\", int(self.d_input_x))\n",
    "        print(\"d_input_anno:\", int(self.d_input_anno))\n",
    "        print(\"d_output_cls:\", int(self.d_output_cls))\n",
    "\n",
    "        return self.d_input_z, self.d_input_x, self.d_input_anno, self.d_output_cls\n",
    "\n",
    "\n",
    "\n",
    "        return d_input_z, d_input_x, d_input_anno, d_output_cls\n",
    "\n",
    "    def predict(self, input_x, input_z, input_anno):\n",
    "        cuda.memcpy_htod(self.d_input_z, input_z.ravel())\n",
    "        cuda.memcpy_htod(self.d_input_x, input_x.ravel())\n",
    "        cuda.memcpy_htod(self.d_input_anno, input_anno.ravel())\n",
    "\n",
    "        bindings = [int(self.d_input_z), int(self.d_input_x), int(self.d_input_anno), int(self.d_output_cls)]\n",
    "        print(\"Bindings:\", bindings)\n",
    "        self.context.execute_v2(bindings=bindings)\n",
    "\n",
    "        output_data = np.empty([1, 4], dtype=np.float32)\n",
    "        cuda.memcpy_dtoh(output_data, self.d_output_cls)\n",
    "\n",
    "        return output_data\n",
    "    def initialize(self, image, info: dict):\n",
    "        z_patch_arr, _ = sample_target(image, info['init_bbox'], self.params.template_factor,\n",
    "                                    output_sz=self.params.template_size)\n",
    "        self.template = self.preprocessor.process(z_patch_arr)\n",
    "        self.template_anno = torch.tensor(info['init_bbox'], dtype=torch.float32)  \n",
    "        self.state = info['init_bbox']\n",
    "        self.frame_id = 0\n",
    "\n",
    "\n",
    "    def track(self, image, info: dict = None):\n",
    "        H, W, _ = image.shape\n",
    "        self.frame_id += 1\n",
    "\n",
    "        x_patch_arr, resize_factor = sample_target(image, self.state, self.params.search_factor,\n",
    "                                                   output_sz=self.params.search_size)\n",
    "        search = self.preprocessor.process(x_patch_arr)\n",
    "\n",
    "        search_np = search.cpu().numpy().astype(np.float32)\n",
    "        template_np = self.template.cpu().numpy().astype(np.float32)\n",
    "        template_anno_np = self.template_anno.cpu().numpy().astype(np.float32)\n",
    "\n",
    "        outputs = self.predict(search_np, template_np, template_anno_np)\n",
    "\n",
    "        pred_boxes = torch.from_numpy(outputs).view(-1, 4)\n",
    "        pred_box = (pred_boxes.mean(dim=0) * self.params.search_size / resize_factor).tolist()\n",
    "        \n",
    "        self.state = clip_box(self.map_box_back(pred_box, resize_factor), H, W, margin=10)\n",
    "\n",
    "        return {\"target_bbox\": self.state, \"confidence\": 0}\n",
    "    \n",
    "    def map_box_back(self, pred_box: list, resize_factor: float):\n",
    "        cx_prev, cy_prev = self.state[0] + 0.5 * self.state[2], self.state[1] + 0.5 * self.state[3]\n",
    "        cx, cy, w, h = pred_box\n",
    "        half_side = 0.5 * self.params.search_size / resize_factor\n",
    "        cx_real = cx + (cx_prev - half_side)\n",
    "        cy_real = cy + (cy_prev - half_side)\n",
    "        return [cx_real - 0.5 * w, cy_real - 0.5 * h, w, h]\n",
    "\n",
    "    def map_box_back_batch(self, pred_box: torch.Tensor, resize_factor: float):\n",
    "        cx_prev, cy_prev = self.state[0] + 0.5 * self.state[2], self.state[1] + 0.5 * self.state[3]\n",
    "        cx, cy, w, h = pred_box.unbind(-1)\n",
    "        half_side = 0.5 * self.params.search_size / resize_factor\n",
    "        cx_real = cx + (cx_prev - half_side)\n",
    "        cy_real = cy + (cy_prev - half_side)\n",
    "        return torch.stack([cx_real - 0.5 * w, cy_real - 0.5 * h, w, h], dim=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Диагностика\n",
    "import numpy as np\n",
    "import torch\n",
    "import cv2\n",
    "\n",
    "def create_test_image():\n",
    "    \"\"\"Создает тестовое изображение размером 640x480 с случайными цветами\"\"\"\n",
    "    image = np.random.randint(0, 255, (480, 640, 3), dtype=np.uint8)\n",
    "    return image\n",
    "\n",
    "def create_test_info():\n",
    "    \"\"\"Создает тестовый bounding box\"\"\"\n",
    "    init_bbox = [200, 150, 100, 100]  # [x, y, width, height]\n",
    "    return {'init_bbox': init_bbox}\n",
    "\n",
    "def diagnose_tracker(tracker):\n",
    "    print(\"Запуск диагностики...\")\n",
    "\n",
    "    # Создание тестовых данных\n",
    "    image = create_test_image()\n",
    "    info = create_test_info()\n",
    "\n",
    "    # Проверка инициализации трекера\n",
    "    print(\"Проверка инициализации трекера...\")\n",
    "    tracker.initialize(image, info)\n",
    "    assert tracker.state is not None, \"Ошибка: tracker.state не инициализирован!\"\n",
    "\n",
    "    # Проверка входных данных\n",
    "    print(\"Проверка входных данных...\")\n",
    "    x_patch_arr, resize_factor = sample_target(image, tracker.state, tracker.params.search_factor,\n",
    "                                               output_sz=tracker.params.search_size)\n",
    "    search = tracker.preprocessor.process(x_patch_arr)\n",
    "\n",
    "    search_np = search.cpu().numpy().astype(np.float32)\n",
    "    template_np = tracker.template.cpu().numpy().astype(np.float32)\n",
    "    template_anno_np = tracker.template_anno.cpu().numpy().astype(np.float32)\n",
    "\n",
    "    assert search_np is not None, \"Ошибка: search_np = None!\"\n",
    "    assert template_np is not None, \"Ошибка: template_np = None!\"\n",
    "    assert template_anno_np is not None, \"Ошибка: template_anno_np = None!\"\n",
    "\n",
    "    print(\"Диапазон входных данных:\")\n",
    "    print(f\"search_np: min={search_np.min()}, max={search_np.max()}\")\n",
    "    print(f\"template_np: min={template_np.min()}, max={template_np.max()}\")\n",
    "    print(f\"template_anno_np: min={template_anno_np.min()}, max={template_anno_np.max()}\")\n",
    "\n",
    "    # Проверка предсказания\n",
    "    print(\"Запуск модели...\")\n",
    "    outputs = tracker.predict(search_np, template_np, template_anno_np)\n",
    "\n",
    "    print(\"Диапазон выходных данных:\")\n",
    "    print(f\"outputs: min={outputs.min()}, max={outputs.max()}\")\n",
    "\n",
    "    assert outputs is not None, \"Ошибка: outputs = None!\"\n",
    "    assert np.any(outputs), \"Ошибка: Все значения outputs равны нулю!\"\n",
    "\n",
    "    print(\"Диагностика завершена успешно!\")\n",
    "\n",
    "# Пример вызова:\n",
    "# tracker = MCITRACK(params)  # Создай объект трекера перед вызовом диагностики\n",
    "# diagnose_tracker(tracker)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Allocated memory addresses:\n",
      "d_input_z: 47326617600\n",
      "d_input_x: 47326768128\n",
      "d_input_anno: 47327370240\n",
      "d_output_cls: 47327370752\n"
     ]
    }
   ],
   "source": [
    "treacker = MCITRACK(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Запуск диагностики...\n",
      "Проверка инициализации трекера...\n",
      "Проверка входных данных...\n",
      "Диапазон входных данных:\n",
      "search_np: min=-2.0665297508239746, max=2.605142116546631\n",
      "template_np: min=-2.0494048595428467, max=2.517995834350586\n",
      "template_anno_np: min=100.0, max=200.0\n",
      "Запуск модели...\n",
      "Bindings: [47326617600, 47326768128, 47327370240, 47327370752]\n",
      "Диапазон выходных данных:\n",
      "outputs: min=0.0, max=0.0\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "Ошибка: Все значения outputs равны нулю!",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mdiagnose_tracker\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtreacker\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[7], line 55\u001b[0m, in \u001b[0;36mdiagnose_tracker\u001b[1;34m(tracker)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutputs: min=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutputs\u001b[38;5;241m.\u001b[39mmin()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, max=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutputs\u001b[38;5;241m.\u001b[39mmax()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     54\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m outputs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mОшибка: outputs = None!\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m---> 55\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m np\u001b[38;5;241m.\u001b[39many(outputs), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mОшибка: Все значения outputs равны нулю!\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mДиагностика завершена успешно!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mAssertionError\u001b[0m: Ошибка: Все значения outputs равны нулю!"
     ]
    }
   ],
   "source": [
    "diagnose_tracker(treacker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bindings: [47413542912, 47413693440, 47414295552, 47414296064]\n"
     ]
    },
    {
     "ename": "LogicError",
     "evalue": "cuMemcpyDtoH failed: an illegal memory access was encountered",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mLogicError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 27\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;66;03m# Трекинг\u001b[39;00m\n\u001b[0;32m     26\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m---> 27\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mtreacker\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtracker_image\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     28\u001b[0m state \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mint\u001b[39m(s) \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m out[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtarget_bbox\u001b[39m\u001b[38;5;124m'\u001b[39m]]\n\u001b[0;32m     29\u001b[0m \u001b[38;5;66;03m#best_score = out[\"best_score\"]\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[17], line 89\u001b[0m, in \u001b[0;36mMCITRACK.track\u001b[1;34m(self, image, info)\u001b[0m\n\u001b[0;32m     86\u001b[0m template_np \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtemplate\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[0;32m     87\u001b[0m template_anno_np \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtemplate_anno\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[1;32m---> 89\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43msearch_np\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemplate_np\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemplate_anno_np\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     91\u001b[0m pred_boxes \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfrom_numpy(outputs)\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m4\u001b[39m)\n\u001b[0;32m     92\u001b[0m pred_box \u001b[38;5;241m=\u001b[39m (pred_boxes\u001b[38;5;241m.\u001b[39mmean(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m) \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams\u001b[38;5;241m.\u001b[39msearch_size \u001b[38;5;241m/\u001b[39m resize_factor)\u001b[38;5;241m.\u001b[39mtolist()\n",
      "Cell \u001b[1;32mIn[17], line 65\u001b[0m, in \u001b[0;36mMCITRACK.predict\u001b[1;34m(self, input_x, input_z, input_anno)\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontext\u001b[38;5;241m.\u001b[39mexecute_v2(bindings\u001b[38;5;241m=\u001b[39mbindings)\n\u001b[0;32m     64\u001b[0m output_data \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mempty([\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m4\u001b[39m], dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[1;32m---> 65\u001b[0m \u001b[43mcuda\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmemcpy_dtoh\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43md_output_cls\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     67\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output_data\n",
      "\u001b[1;31mLogicError\u001b[0m: cuMemcpyDtoH failed: an illegal memory access was encountered"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Трекинг по видео\n",
    "file = \"0516.mp4\"\n",
    "video = cv2.VideoCapture(file)\n",
    "ok, image = video.read()\n",
    "if not video.isOpened():\n",
    "    print(\"Could not open video\")\n",
    "    sys.exit()\n",
    "    \n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "x, y, w, h = cv2.selectROI( image, fromCenter=False)\n",
    "init_state = [x, y, w, h]\n",
    "def _build_init_info(box):\n",
    "            return {'init_bbox': box}\n",
    "treacker.initialize(image, _build_init_info(init_state))\n",
    "counter = 0\n",
    "while True:\n",
    "    ok, image = video.read()\n",
    "    if not ok:\n",
    "        break\n",
    "\n",
    "    # Конвертация для трекера\n",
    "    tracker_image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # Трекинг\n",
    "    start_time = time.time()\n",
    "    out = treacker.track(tracker_image)\n",
    "    state = [int(s) for s in out['target_bbox']]\n",
    "    #best_score = out[\"best_score\"]\n",
    "    best_score = 1\n",
    "    fps = 1 / (time.time() - start_time + 1e-6)\n",
    "\n",
    "    # Визуализация\n",
    "    display_image = image.copy()\n",
    "    x, y, w, h = state\n",
    "    \n",
    "    # Динамический цвет рамки в зависимости от уверенности\n",
    "    color = (0, 255, 0) if best_score > 0.7 else (0, 255, 255) if best_score > 0.4 else (0, 0, 255)\n",
    "    thickness = 3 if best_score > 0.7 else 2\n",
    "    \n",
    "    # Рисуем bounding box с увеличенными размерами\n",
    "    cv2.rectangle(display_image, (x, y), (x + w, y + h), color, thickness)\n",
    "    \n",
    "    # Добавляем информационный текст\n",
    "    cv2.putText(display_image, f\"Score: {best_score:.2f}\", (x, y-10), \n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.7, color, 2)\n",
    "    cv2.putText(display_image, f\"FPS: {fps:.1f}\", (20, 40), \n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 255, 255), 2)\n",
    "    \n",
    "    cv2.imshow(\"tracking\", display_image)\n",
    "    \n",
    "    # Обработка клавиш\n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "    if key == 32:  # SPACE - переинициализация\n",
    "        x, y, w, h = cv2.selectROI(\"Select ROI\", image, fromCenter=False)\n",
    "        if w > 10 and h > 10:  # Минимальный размер ROI\n",
    "            init_state = [x, y, w, h]\n",
    "            print(\"Переинициализация...\")\n",
    "            treacker.initialize(tracker_image, _build_init_info(init_state))\n",
    "    elif key == 27:  # ESC - выход\n",
    "        break\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
